[{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/","title":"Báo cáo thực tập","tags":[],"description":"","content":"Báo cáo thực tập Thông tin sinh viên: Họ và tên: Lê Vũ Phương Hòa\nSố điện thoại: 0327 030 024\nEmail: danielleee241@gmail.com\nTrường: Đại học FPT TP.HCM\nNgành: Công nghệ thông tin\nLớp: SE181951\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 12/08/2025 đến ngày 12/11/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":"Tăng tốc phát triển Generative AI với MLflow 3.0 được quản lý hoàn toàn trên Amazon SageMaker AI Bởi Ram Vittal, Amit Modi, Rahul Easwar, and Sandeep Raveesh-Babu on 10 JUL 2025 in Amazon SageMaker AI, Announcements, Technical How-to\nAmazon SageMaker hiện cung cấp hỗ trợ MLflow 3.0 được quản lý hoàn toàn, giúp đơn giản hóa quá trình thử nghiệm AI và tăng tốc hành trình Generative AI của bạn từ ý tưởng đến triển khai sản xuất. Bản phát hành này biến managed MLflow từ công cụ theo dõi thí nghiệm thành giải pháp end-to-end observability, rút ngắn thời gian đưa Generative AI ra thị trường.\nKhi khách hàng ở nhiều ngành khác nhau tăng tốc phát triển Generative AI, họ cần khả năng theo dõi thí nghiệm, quan sát hành vi và đánh giá hiệu suất của models và AI applications. Các data scientists và developers gặp khó khăn trong việc phân tích hiệu quả của models và AI applications từ giai đoạn thử nghiệm đến sản xuất, gây khó khăn trong việc tìm nguyên nhân và khắc phục sự cố. Các nhóm dành nhiều thời gian tích hợp công cụ thay vì nâng cao chất lượng của models hoặc generative AI applications.\nVới việc ra mắt fully managed MLflow 3.0 trên Amazon SageMaker AI, bạn có thể tăng tốc phát triển Generative AI bằng cách dễ dàng theo dõi thí nghiệm và quan sát hành vi của models và AI applications chỉ bằng một công cụ duy nhất. Tracing capabilities trong MLflow 3.0 cho phép khách hàng ghi lại inputs, outputs, metadata ở mọi bước trong ứng dụng Generative AI, giúp developers nhanh chóng xác định nguồn gốc của lỗi hoặc hành vi bất thường. Bằng cách duy trì lịch sử của từng phiên bản model và ứng dụng, MLflow 3.0 cung cấp khả năng traceability, giúp kết nối phản hồi AI với các thành phần gốc. Điều này cho phép developers nhanh chóng truy vết sự cố trực tiếp đến code, data, hoặc parameters đã tạo ra nó.\nVới các khả năng này, khách hàng sử dụng Amazon SageMaker HyperPod để train và deploy foundation models (FMs) giờ đây có thể dùng managed MLflow để theo dõi thí nghiệm, giám sát quá trình training, có insight sâu hơn về hành vi models và AI applications, và quản lý ML lifecycle ở quy mô lớn. Điều này giảm thời gian khắc phục sự cố và giúp các nhóm tập trung nhiều hơn vào đổi mới.\nBài viết này sẽ giới thiệu các khái niệm cốt lõi của fully managed MLflow 3.0 trên SageMaker và cung cấp hướng dẫn kỹ thuật để bạn khai thác các tính năng mới, giúp tăng tốc phát triển ứng dụng Generative AI tiếp theo.\nBắt đầu Bạn có thể bắt đầu với MLflow 3.0 được quản lý hoàn toàn trên Amazon SageMaker để theo dõi thí nghiệm, quản lý models, và tối ưu hóa vòng đời Generative AI/ML thông qua AWS Management Console, AWS CLI, hoặc API.\nĐiều kiện cần thiết Để bắt đầu, bạn cần:\nMột AWS account đã bật billing\nMột Amazon SageMaker Studio AI domain (xem hướng dẫn: Guide to getting set up with Amazon SageMaker AI)\nCấu hình môi trường của bạn để sử dụng Máy chủ theo dõi MLflow do SageMaker quản lý Các bước cấu hình: 1. Trong SageMaker Studio UI, ở bảng Applications, chọn MLflow → Create.\n2. Nhập tên duy nhất cho tracking server và chỉ định Amazon S3 URI nơi lưu trữ experiment artifacts. Chọn Create. (Mặc định SageMaker sẽ chọn MLflow v3.0).\n3. Tuỳ chọn: chọn Update để điều chỉnh cài đặt như server size, tags, IAM role.\nMáy chủ sẽ được cấp phát và khởi động tự động, thường mất khoảng 25 phút. Sau khi thiết lập xong, bạn có thể khởi chạy MLflow UI từ SageMaker Studio để bắt đầu tracking các thí nghiệm ML và Generative AI. Để biết thêm chi tiết về cấu hình tracking server, tham khảo Machine learning experiments using Amazon SageMaker AI with MLflow trong SageMaker Developer Guide.\nĐể bắt đầu tracking các thí nghiệm của bạn với SageMaker managed MLflow tracking server vừa tạo, bạn cần cài đặt cả MLflow và gói AWS SageMaker MLflow Python trong môi trường của bạn. Bạn có thể sử dụng SageMaker Studio managed Jupyter Lab, SageMaker Studio Code Editor, một môi trường phát triển tích hợp (IDE) cục bộ, hoặc môi trường khác có hỗ trợ AI workloads để tracking với SageMaker managed MLflow tracking server.\nĐể cài đặt cả hai gói Python bằng lệnh pip:\npip install mlflow==3.0 sagemaker-mlflow==0.1.0\nĐể kết nối và bắt đầu ghi log các thí nghiệm AI, tham số, và mô hình của bạn trực tiếp lên managed MLflow trên SageMaker, hãy thay thế Amazon Resource Name (ARN) của SageMaker MLflow tracking server của bạn:\nimport mlflow # SageMaker MLflow ARN tracking_server_arn = \u0026#34;arn:aws:sagemaker:\u0026lt;Region\u0026gt;:\u0026lt;Account_id\u0026gt;:mlflow-tracking-server/\u0026lt;Name\u0026gt;\u0026#34; # Enter ARN mlflow.set_tracking_uri(tracking_server_arn) mlflow.set_experiment(\u0026#34;customer_support_genai_app\u0026#34;) Bây giờ môi trường của bạn đã được cấu hình và sẵn sàng để tracking các thí nghiệm với SageMaker Managed MLflow tracking server.\nTriển khai tracing và version tracking cho ứng dụng Generative AI Các ứng dụng Generative AI có nhiều thành phần, bao gồm code, cấu hình và dữ liệu, điều này có thể trở nên khó quản lý nếu không có versioning một cách hệ thống. Một thực thể LoggedModel trong managed MLflow 3.0 đại diện cho mô hình AI, agent, hoặc ứng dụng Generative AI của bạn trong một experiment. Nó cung cấp khả năng tracking thống nhất các model artifacts, execution traces, evaluation metrics và metadata trong suốt vòng đời phát triển. Một trace là bản ghi log của input, output và các bước trung gian từ một lần thực thi ứng dụng. Traces mang lại cái nhìn sâu về hiệu suất ứng dụng, luồng thực thi, và chất lượng phản hồi, giúp debugging và đánh giá. Với LoggedModel, bạn có thể tracking và so sánh các phiên bản khác nhau của ứng dụng, giúp dễ dàng xác định vấn đề, triển khai phiên bản tốt nhất, và duy trì hồ sơ rõ ràng về những gì đã được triển khai và khi nào.\nĐể triển khai version tracking và tracing với managed MLflow 3.0 trên SageMaker, bạn có thể thiết lập một danh tính model có version bằng cách sử dụng Git commit hash, đặt nó làm active model context để tất cả các trace sau đó sẽ tự động liên kết với phiên bản cụ thể này, bật tính năng automatic logging cho các tương tác với Amazon Bedrock, và sau đó thực hiện một API call tới Claude 3.5 Sonnet của Anthropic, lệnh gọi này sẽ được tracing đầy đủ với input, output và metadata được tự động ghi lại trong model context đã thiết lập. Managed MLflow 3.0 tracing đã được tích hợp sẵn với nhiều thư viện Generative AI khác nhau và cung cấp trải nghiệm tracing tự động chỉ với một dòng lệnh cho tất cả các thư viện được hỗ trợ. Để biết thêm thông tin về các thư viện được hỗ trợ, hãy tham khảo Supported Integrations trong MLflow documentation.\n# 1. Define your application version using the git commit logged_model= \u0026#34;customer_support_agent\u0026#34; logged_model_name = f\u0026#34;{logged_model}-{git_commit}\u0026#34; # 2.Set the active model context - traces will be linked to this mlflow.set_active_model(name=logged_model_name) # 3.Set auto logging for your model provider mlflow.bedrock.autolog() # 4. Chat with your LLM provider # Ensure that your boto3 client has the necessary auth information bedrock = boto3.client( service_name=\u0026#34;bedrock-runtime\u0026#34;, region_name=\u0026#34;\u0026lt;REPLACE_WITH_YOUR_AWS_REGION\u0026gt;\u0026#34;, ) model = \u0026#34;anthropic.claude-3-5-sonnet-20241022-v2:0\u0026#34; messages = [{ \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: [{\u0026#34;text\u0026#34;: \u0026#34;Hello!\u0026#34;}]}] # All intermediate executions within the chat session will be logged bedrock.converse(modelId=model, messages=messages) Sau khi ghi lại thông tin này, bạn có thể theo dõi các thí nghiệm Generative AI và LoggedModel cho agent trong Managed MLflow 3.0 tracking server UI, như minh họa trong ảnh chụp màn hình sau.\nBên cạnh chức năng one-line auto tracing, MLflow cung cấp Python SDK để bạn có thể thủ công instrument code và thao tác với các trace. Tham khảo notebook mẫu sagemaker_mlflow_strands.ipynb trong kho aws-samples GitHub repository, nơi chúng tôi sử dụng MLflow manual instrumentation để trace Strands Agents. Với khả năng tracing trong fully managed MLflow 3.0, bạn có thể ghi lại inputs, outputs, và metadata liên quan đến từng bước trung gian của một request, từ đó dễ dàng xác định nguồn gốc của lỗi và các hành vi bất ngờ.\nNhững khả năng này mang lại observability cho workload AI của bạn bằng cách thu thập thông tin chi tiết về quá trình thực thi của các workload services, nodes, và tools, và bạn có thể quan sát dưới tab Traces.\nBạn có thể kiểm tra từng trace, như minh họa trong hình dưới đây, bằng cách chọn request ID trong tab traces cho trace mà bạn muốn xem.\nMLflow 3.0 được quản lý toàn diện trên Amazon SageMaker cũng giới thiệu khả năng gắn thẻ cho traces. Tags là các cặp khóa-giá trị có thể thay đổi mà bạn có thể gắn vào traces để bổ sung metadata và ngữ cảnh giá trị. Trace tags giúp việc tổ chức, tìm kiếm, và lọc traces trở nên đơn giản dựa trên các tiêu chí như phiên người dùng, môi trường, phiên bản mô hình, hoặc đặc tính hiệu năng. Bạn có thể thêm, cập nhật, hoặc xóa tags ở bất kỳ giai đoạn nào—trong khi thực thi trace bằng cách sử dụng mlflow.update_current_trace() hoặc sau khi một trace đã được ghi log thông qua MLflow APIs hoặc UI.\nManaged MLflow 3.0 làm cho việc tìm kiếm và phân tích traces trở nên liền mạch, giúp các nhóm nhanh chóng xác định vấn đề, so sánh hành vi của agent, và tối ưu hóa hiệu năng. Giao diện người dùng tracing và Python API đều hỗ trợ tính năng lọc mạnh mẽ, vì vậy bạn có thể đi sâu vào traces dựa trên các thuộc tính như trạng thái, tags, người dùng, môi trường, hoặc thời gian thực thi như được minh họa trong ảnh chụp màn hình bên dưới.\nVí dụ, bạn có thể ngay lập tức tìm tất cả traces có lỗi, lọc theo môi trường production, hoặc tìm traces từ một request cụ thể. Khả năng này rất quan trọng cho việc gỡ lỗi, phân tích chi phí, và cải tiến liên tục của các ứng dụng Generative AI.\nẢnh chụp màn hình sau đây hiển thị các dấu vết được trả về khi tìm kiếm thẻ ‘Production’.\nĐoạn mã sau đây cho thấy cách bạn có thể sử dụng chức năng tìm kiếm tất cả traces trong môi trường production với trạng thái thành công:\n# Search for traces in production environment with successful status\ntraces = mlflow.search_traces( filter_string=\u0026ldquo;attributes.status = \u0026lsquo;OK\u0026rsquo; AND tags.environment = \u0026lsquo;production\u0026rsquo;\u0026rdquo;)\nHướng dẫn sử dụng AI tạo sinh với tính năng theo dõi MLflow Việc xây dựng và triển khai các generative AI agents như chat-based assistants, code generators hoặc customer support assistants đòi hỏi khả năng quan sát sâu về cách các agent này tương tác với large language models (LLMs) và các công cụ bên ngoài. Trong một quy trình agentic workflow điển hình, agent sẽ lặp qua các bước reasoning, gọi LLMs và sử dụng các công cụ hoặc hệ thống con như search APIs hoặc Model Context Protocol (MCP) servers cho đến khi hoàn thành tác vụ của người dùng. Những tương tác phức tạp, nhiều bước này khiến việc debugging, tối ưu hóa và theo dõi chi phí trở nên đặc biệt thách thức.\nCác công cụ observability truyền thống trở nên thiếu hiệu quả trong generative AI vì các quyết định của agent, các lệnh gọi tool, và phản hồi từ LLM đều mang tính động và phụ thuộc vào ngữ cảnh. Managed MLflow 3.0 tracing cung cấp khả năng quan sát toàn diện bằng cách ghi lại mọi lần gọi LLM, tool invocation, và decision point trong workflow của agent. Bạn có thể sử dụng dữ liệu trace end-to-end này để:\nDebug agent behavior – Xác định chính xác nơi reasoning của agent bị lệch hướng hoặc lý do tại sao nó tạo ra output bất ngờ.\nMonitor tool usage – Khám phá cách và thời điểm các external tools được gọi, đồng thời phân tích tác động của chúng đến chất lượng và chi phí.\nTrack performance and cost – Đo lường latency, token usage và chi phí API ở mỗi bước của agentic loop.\nAudit and govern – Duy trì logs chi tiết để phục vụ compliance và phân tích.\nHãy tưởng tượng một kịch bản thực tế sử dụng managed MLflow 3.0 tracing UI cho một finance customer support agent mẫu, được trang bị một công cụ để truy xuất dữ liệu tài chính từ datastore. Trong khi bạn đang phát triển một generative AI customer support agent hoặc phân tích hành vi của agent trong production, bạn có thể quan sát cách phản hồi của agent và việc thực thi có thể (hoặc không) gọi đến product database tool để đưa ra khuyến nghị chính xác hơn.\nVí dụ minh họa: trace đầu tiên (hiển thị trong screenshot bên dưới) cho thấy agent xử lý một user query mà không gọi bất kỳ tool nào. Trace ghi lại prompt, agent response và các decision points của agent. Phản hồi của agent thiếu chi tiết cụ thể về sản phẩm. Trace cho thấy rõ ràng rằng không có external tool nào được gọi, và bạn nhanh chóng nhận ra hành vi này trong reasoning chain của agent.\nTrace thứ hai (hiển thị trong screenshot bên dưới) ghi lại cùng một agent, nhưng lần này agent quyết định gọi product database tool. Trace này log lại tool invocation, dữ liệu sản phẩm được trả về, và cách agent tích hợp thông tin này vào phản hồi cuối cùng. Tại đây, bạn có thể quan sát thấy chất lượng câu trả lời được cải thiện, độ trễ (latency) tăng nhẹ, và chi phí API bổ sung do mức sử dụng token cao hơn.\nBằng cách so sánh các trace này song song, bạn có thể debug lý do vì sao agent đôi khi bỏ qua việc sử dụng tool, tối ưu hóa thời điểm và cách thức gọi tool, đồng thời cân bằng giữa chất lượng với latency và chi phí. Tracing UI của MLflow giúp các agentic loops trở nên minh bạch, dễ hành động, và liền mạch để phân tích ở quy mô lớn. Agent mẫu trong bài viết này cùng với toàn bộ mã nguồn cần thiết đều có sẵn trên aws-samples GitHub repository, nơi bạn có thể tái tạo và điều chỉnh cho các ứng dụng của riêng mình.\nDọn dẹp tài nguyên Sau khi được tạo, một SageMaker managed MLflow tracking server sẽ phát sinh chi phí cho đến khi bạn xóa hoặc dừng nó. Việc tính phí cho tracking server dựa trên thời gian máy chủ chạy, kích thước được chọn, và lượng dữ liệu được log vào tracking server. Bạn có thể dừng tracking server khi không sử dụng để tiết kiệm chi phí, hoặc có thể xóa chúng bằng API hoặc SageMaker Studio UI. Để biết thêm chi tiết về giá, hãy tham khảo Amazon SageMaker pricing.\nKết luận Fully managed MLflow 3.0 on Amazon SageMaker AI hiện đã khả dụng. Hãy bắt đầu với sample code trong aws-samples GitHub repository. Chúng tôi mời bạn khám phá tính năng mới này và trải nghiệm sự hiệu quả cũng như khả năng kiểm soát nâng cao mà nó mang lại cho các dự án ML của bạn. Để tìm hiểu thêm, hãy truy cập Machine Learning Experiments using Amazon SageMaker with MLflow.\nĐể biết thêm thông tin, hãy tham khảo SageMaker Developer Guide và gửi phản hồi đến AWS re:Post for SageMaker hoặc thông qua kênh AWS Support thông thường của bạn.\nThông tin về các tác giả Ram Vittal Ram Vittal là Kiến trúc sư Giải pháp ML Chính (Principal ML Solutions Architect) tại AWS. Ông có hơn 3 thập kỷ kinh nghiệm trong việc kiến trúc và xây dựng các ứng dụng phân tán, lai (hybrid) và đám mây. Ông đam mê xây dựng các giải pháp AI/ML và dữ liệu lớn an toàn, có khả năng mở rộng và đáng tin cậy để giúp các khách hàng doanh nghiệp trong hành trình áp dụng và tối ưu hóa đám mây nhằm cải thiện kết quả kinh doanh. Trong thời gian rảnh, ông lái xe mô tô và đi dạo cùng chú chó sheep-a-doodle ba tuổi của mình! Sandeep Raveesh Sandeep Raveesh là Kiến trúc sư Giải pháp Chuyên gia GenAI (GenAI Specialist Solutions Architect) tại AWS. Anh làm việc với khách hàng trong suốt hành trình AIOps của họ, bao gồm đào tạo mô hình, Tạo sinh Tăng cường Truy xuất (RAG), Tác tử GenAI (GenAI Agents) và mở rộng quy mô các trường hợp sử dụng GenAI. Anh cũng tập trung vào các chiến lược Go-To-Market giúp AWS xây dựng và điều chỉnh các sản phẩm để giải quyết các thách thức của ngành trong lĩnh vực Trí tuệ Nhân tạo Tạo sinh (Generative AI). Bạn có thể tìm thấy Sandeep trên LinkedIn. Amit Modi Amit Modi là Trưởng bộ phận Sản phẩm cho SageMaker AIOps và Quản trị (Governance), cùng với AI có trách nhiệm (Responsible AI) tại AWS. Với hơn một thập kỷ kinh nghiệm trong lĩnh vực B2B, ông đã xây dựng các sản phẩm và đội ngũ có khả năng mở rộng, thúc đẩy đổi mới và mang lại giá trị cho khách hàng trên toàn cầu. Rahul Easwar Rahul Easwar là Giám đốc Sản phẩm Cấp cao (Senior Product Manager) tại AWS, dẫn dắt mảng MLflow được quản lý và Ứng dụng AI Đối tác (Partner AI Apps) trong nhóm SageMaker AIOps. Với hơn 15 năm kinh nghiệm từ các công ty khởi nghiệp đến công nghệ doanh nghiệp, anh tận dụng nền tảng khởi nghiệp và bằng MBA từ Chicago Booth để xây dựng các nền tảng ML có khả năng mở rộng, giúp đơn giản hóa việc áp dụng AI cho các tổ chức trên toàn thế giới. Kết nối với Rahul trên LinkedIn để tìm hiểu thêm về công việc của anh trong lĩnh vực nền tảng ML và các giải pháp AI cho doanh nghiệp. "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/3-blogstranslated/3.2-blog2/","title":"Blog 2","tags":[],"description":"","content":"Ánh xạ Cơ sở hạ tầng Dưới lòng đất được Cải tiến bằng AI trên AWS Bởi: Santi Adavani, Jacques Guigne, Ryan Qi, Souvik Mukherjee, Srinivas Tadepalli, và Vidyasagar Ananthan, 13/05/2025, AWS Batch, AWS ParallelCluster, Customer Solutions, High Performance Computing, Thought Leadership\nSubsurface infrastructure mapping là quá trình xác định và trực quan hóa các cấu trúc bị chôn vùi như đường ống, cáp, bồn chứa, và nền móng tồn tại bên dưới bề mặt mà không cần khai quật. Công nghệ này rất quan trọng trong quy hoạch đô thị, bảo trì tiện ích, vận hành dầu khí, an toàn xây dựng và bảo vệ môi trường. Không có bản đồ hạ tầng ngầm chính xác, các dự án xây dựng có nguy cơ bị trì hoãn tốn kém, va chạm nguy hiểm với tiện ích, và gây hại môi trường. Ví dụ, khi bão Ivan làm hỏng một giàn khoan dầu ngoài khơi năm 2004, nó để lại hạ tầng quan trọng bị chôn dưới 35–45 mét trầm tích, tạo ra mối nguy vô hình mà các kỹ thuật bản đồ truyền thống không thể phát hiện đầy đủ.\nNhờ sự hợp tác giữa S2 Labs, Empact AI và Kraken Robotics, một bước đột phá trong subsurface infrastructure mapping đã xuất hiện trên AWS. Cách tiếp cận này kết hợp magnetic imaging tiên tiến với physics-informed AI, mang lại hình ảnh rõ nét chưa từng có về các cấu trúc ngầm – đặc biệt trong điều kiện mà phương pháp truyền thống thất bại. Sự kết hợp sức mạnh cloud computing và AI đang thay đổi cách ngành công nghiệp hình dung và hiểu về hạ tầng ngầm quan trọng.\nPhương pháp phát hiện dưới bề mặt và những hạn chế Hình ảnh dưới bề mặt truyền thống sử dụng nhiều kỹ thuật địa vật lý khác nhau, mỗi kỹ thuật phù hợp với những loại vật liệu và điều kiện cụ thể. Ví dụ, electromagnetic methods phát hiện các đường ống kim loại và cáp thông qua độ dẫn điện của chúng, trong khi magnetometers đo sự biến thiên của từ trường Trái Đất để xác định các vật liệu có từ tính như ống thép. Ground-penetrating radar (GPR) đặc biệt hiệu quả trong việc tạo ảnh các công trình bê tông và các cấu trúc địa chất, và các tần số chuyên dụng có thể phát hiện các đường ống nhựa hoặc tài sản chứa nước nhờ vào đặc tính điện môi của chúng.\nViệc diễn giải thủ công dữ liệu hình ảnh thường chỉ bao gồm phân tích tín hiệu địa vật lý 2D và tính toán độ sâu cơ bản – nhanh nhưng chỉ mang tính xấp xỉ. Có hai thách thức chính: Thứ nhất, đôi khi những cách sắp xếp khác nhau của các vật thể ngầm có thể tạo ra kết quả giống hệt nhau trên các công cụ phát hiện, khiến chúng ta không thể biết được cấu hình nào đúng nếu không có dữ liệu bổ sung. Thứ hai, môi trường thực tế có nhiều loại đất, mức độ ẩm và mật độ vật liệu thay đổi trong phạm vi ngắn, tạo ra các tín hiệu phức tạp mà các thuật toán truyền thống khó xử lý chính xác.\nQuan sát kết quả khảo sát từ tính, chúng ta thấy các phép đo bề mặt cho thấy cường độ từ trường thay đổi trong một khu vực rộng 50 mét, như minh họa trong Hình 1(a). Khi xử lý dữ liệu này bằng phương pháp truyền thống, chúng ta thu được hình ảnh sơ bộ về một cấu trúc giống như đường ống kéo dài xuống khoảng 5 mét, nhưng hình ảnh mờ và thiếu chi tiết (Hình 1(b)). Đây chính là nơi phương pháp dựa trên AI cho thấy ưu thế – nó mang lại hình ảnh rõ ràng hơn nhiều, hiển thị một cấu trúc giống đường ống nằm ở độ sâu từ 1 đến 1,5 mét dưới bề mặt (Hình 1(c)). Nhờ vậy, phương pháp AI xác định vị trí chính xác hơn nhiều, đồng thời vẫn duy trì tính nhất quán với các phép đo từ tính ban đầu.\nHình 1. (a) Chế độ xem bản đồ trên một phần khảo sát rộng 50m. (b) Phương pháp đảo ngược bình phương nhỏ thông thường. (c) Phương pháp đảo ngược dựa trên học sâu.\nGiải pháp deep learning dựa trên vật lý S2 Labs ứng dụng physics-informed AI và AWS high performance computing (HPC) để giải quyết các bài toán kỹ thuật phức tạp trong các lĩnh vực dầu khí, sản xuất, chăm sóc sức khỏe và công nghệ sinh học, mang lại các giải pháp vừa đảm bảo tính chính xác khoa học vừa rút ngắn thời gian tính toán. S2 Labs đã hợp tác với hai đối tác chuyên biệt: Empact AI, cung cấp bản đồ đường ống ngầm 3D, và Kraken Robotics, đóng góp hình ảnh dưới nước độ phân giải cao thông qua hệ thống Synthetic Aperture Sonar. Sự hợp tác này tích hợp công nghệ sonar tiên tiến, phân tích dưới bề mặt 3D và nhận dạng mẫu dựa trên AI thông qua AWS Cloud để xác định và định vị nguồn rò rỉ đường ống với độ chính xác và tốc độ cao hơn.\nPhương pháp AI của chúng tôi kết hợp vật lý của từ trường với deep learning để hiểu rõ hơn những gì nằm dưới lòng đất. Bằng cách huấn luyện AI với dữ liệu mô phỏng dựa trên các cấu trúc thực tế như bồn chứa và đường ống, chúng tôi có thể dạy nó “đọc” các phép đo từ trường như đọc một bản đồ. Sử dụng một loại neural network đặc biệt gọi là U-Net, AI học cách chuyển đổi các tín hiệu từ trường này thành hình ảnh rõ nét của các cấu trúc ngầm, cho chúng ta biết không chỉ vị trí mà còn cả thành phần và hình dạng của chúng. Nếu bạn quan tâm đến chi tiết kỹ thuật, hãy xem bài báo khoa học gần đây do S2 Labs công bố.\nModel training Mô hình physics-informed deep learning được huấn luyện trên AWS bằng cách kết hợp các tài nguyên high performance computing, hệ thống lưu trữ dữ liệu, và các dịch vụ xử lý song song, như minh họa trong sơ đồ kiến trúc ở Hình 2.\nSử dụng Amazon EC2 instances, chúng tôi đã tạo ra 202.000 mô hình 3D susceptibility (mỗi mô hình gồm 226.000 cells) đại diện cho nhiều kịch bản dưới lòng đất khác nhau – bao gồm đường ống với nhiều hướng khác nhau, các cấu hình nhiều đường ống, và bồn chứa.\nCác mô hình sau đó được tham số hóa dựa trên kiến thức chuyên ngành và lưu trữ dưới dạng file NumPy trong Amazon S3 buckets. Ứng dụng magnetostatic solver độc quyền của S2 Labs được container hóa và lưu trữ trong Amazon ECR để triển khai đồng nhất trên các tài nguyên tính toán. Solver này xử lý tuần tự các mô hình từ S3, rồi lưu kết quả phản hồi trở lại S3.\nChúng tôi cũng triển khai distributed computing bằng AWS Batch để sinh dữ liệu, sử dụng Spot Instances nhằm tối ưu chi phí. Chúng tôi dùng P4d instances, mỗi instance cung cấp tám NVIDIA A100 GPUs để tính toán phản hồi từ trường tại 1.800 điểm đo với khoảng cách 2 mét. Pipeline đồng bộ dữ liệu giữa Amazon S3 và bộ nhớ cục bộ, huấn luyện kiến trúc 2D U-Net (500 triệu tham số) trong 110 epochs, đạt training loss 0.0018 và validation loss 0.0019. Toàn bộ tính toán yêu cầu 100.000 CPU hours.\nHình 2. Sơ đồ kiến ​​trúc để tạo dữ liệu tổng hợp và đào tạo mô hình trên AWS.\nQuy trình làm việc để suy luận các cuộc khảo sát từ trường quy mô lớn Pipeline xử lý khảo sát từ tính của chúng tôi áp dụng một quy trình bốn giai đoạn có hệ thống để xử lý các khảo sát quy mô lớn một cách hiệu quả, đồng thời vẫn duy trì khả năng tái tạo chất lượng cao các cấu trúc hạ tầng ngầm, minh họa trong Hình 3.\nStage 1 – Data Acquisition: Việc thu thập dữ liệu hiện trường bắt đầu bằng các hệ thống magnetometer được tùy chỉnh theo môi trường khảo sát – gắn trên drone cho khảo sát trên không, hệ thống mặt đất cho khảo sát trên đất liền, hoặc hệ thống dưới nước cho ứng dụng biển. Các khảo sát tuân theo lưới mẫu có hệ thống với độ cao cảm biến và khoảng cách đường khảo sát nhất quán để đảm bảo vùng mục tiêu được bao phủ đồng đều.\nStage 2 – Survey Domain Preparation: Thay vì xử lý toàn bộ khu vực khảo sát cùng lúc, chúng tôi áp dụng phương pháp mô-đun bằng cách chia miền khảo sát thành các ô nhỏ hơn, phù hợp với kích thước huấn luyện của mô hình AI. Các ô liền kề có vùng chồng lấn, rất quan trọng để đảm bảo sự chuyển tiếp mượt mà trong tái tạo cuối cùng và tránh hiện tượng nhiễu ở rìa.\nStage 3 – Parallel Processing Architecture: Quy trình tận dụng parallel computing để xử lý đồng thời nhiều ô, từ đó giảm đáng kể thời gian tính toán trong khi vẫn đảm bảo tính nhất quán với các tham số của mô hình đã huấn luyện. Cách tiếp cận phân tán này giúp sử dụng hiệu quả tài nguyên tính toán thông qua xử lý ô độc lập. Ví dụ, triển khai của chúng tôi có thể xử lý dữ liệu khảo sát kích thước 400 m x 400 m x 60 m trong chưa đến 5 giây.\nStage 4 – AI-Based Inference: Mô hình AI đã huấn luyện thực hiện inference trên từng ô một cách độc lập, tái tạo phân bố magnetic susceptibility dưới bề mặt từ các phép đo từ trường. Các bản tái tạo sau đó được kết hợp liền mạch bằng phương pháp weighted blending tại các vùng chồng lấn, đảm bảo sự chuyển tiếp mượt mà giữa các ô liền kề để tạo ra kết quả cuối cùng thống nhất. Quy trình mô-đun này cho phép khả năng mở rộng cho khảo sát ở mọi kích thước, đồng thời duy trì độ phân giải nhất quán và tối ưu hóa việc sử dụng bộ nhớ nhờ xử lý song song hiệu quả, khiến nó trở nên khả thi trong các ứng dụng thực tế từ bản đồ hạ tầng ngầm đến khảo sát địa chất.\nHình 3. Quy trình xử lý mô-đun cho các cuộc khảo sát từ tính quy mô lớn.\nNghiên cứu điển hình: phát hiện đường ống dẫn dầu khí dưới nước ở Vịnh Mexico Cơn bão Hurricane Ivan (2004) đã làm hư hại một giàn khoan dầu ngoài khơi ở Vịnh Mexico, chôn vùi các well conductors dưới lớp trầm tích dày 35–45 mét. Hình ảnh acoustic imaging ban đầu vào năm 2022, dù có phần thành công, nhưng vẫn bị hạn chế do trầm tích chứa khí che khuất các khu vực quan trọng. Một mảng magnetometer độ phân giải cao được triển khai cách đáy biển 3,5 mét để phát hiện các conductors giàu sắt xuyên qua lớp trầm tích bão hòa hydrocarbon.\nMô hình mà chúng tôi đã mô tả ở các phần trước đã lập bản đồ thành công các conductors bị chôn vùi ở độ sâu 35–45 mét, hé lộ một bó conductor chính và một đoạn mảnh vỡ thứ cấp nằm cách well bay 40 mét về phía đông bắc (như minh họa trong Hình 4). Kết quả cho thấy khả năng phân biệt vượt trội các magnetic signatures trong trường hợp có nhiều mảnh vỡ phức tạp, được xác minh qua các điểm khoan và hình ảnh acoustic khi có thể. Điều này chứng minh hiệu quả của deep learning trong những trường hợp mà các phương pháp acoustic truyền thống thất bại.\nHình 4. Hình chiếu bằng (a) và hình chiếu xiên (b) của phân bố độ nhạy tương đối.\nKết luận Công trình của chúng tôi cho thấy cách AI-enhanced magnetic imaging đang thay đổi lĩnh vực subsurface infrastructure mapping trên nhiều ngành, từ các tiện ích nông trên đất liền đến các offshore well conductors sâu dưới biển. Mô hình physics-informed deep learning được huấn luyện trên AWS bằng cách kết hợp các tài nguyên high performance computing, hệ thống lưu trữ dữ liệu và các dịch vụ xử lý song song.\nThông qua các case study thực tế, chúng tôi đã chứng minh rằng deep learning có thể vượt qua những hạn chế của việc diễn giải dữ liệu từ tính truyền thống, lập bản đồ thành công các cấu trúc ở độ sâu 40 mét dưới đáy biển – những cấu trúc vốn đã “vô hình” với phương pháp acoustic suốt 18 năm.\nTác động của công nghệ này trải dài từ oil \u0026amp; gas decommissioning, urban utility mapping, environmental protection cho đến marine operations. Dù kết quả rất hứa hẹn, vẫn còn nhiều cơ hội phát triển, bao gồm multi-physics integration, xử lý dữ liệu real-time, và nâng cao khả năng phân giải.\nĐể hợp tác hoặc tìm hiểu thêm về việc triển khai, vui lòng liên hệ với chúng tôi qua email: santi@s2labs.co hoặc ryanqi@amazon.com.\nThông tin về các tác giả Santi Adavani Tiến sĩ Santi Adavani là người sáng lập và CEO của S2 Labs, một startup công nghệ chuyên sâu (deep tech) xây dựng các sản phẩm AI nhằm thúc đẩy khám phá khoa học. Trước S2 Labs, Santi là người sáng lập và CTO của RocketML, nơi ông đã xây dựng một nền tảng MLOps được hỗ trợ bởi HPC (Điện toán Hiệu năng Cao). Ông cũng từng là Trưởng bộ phận Sản phẩm và AI tại PostgresML, nơi ông lãnh đạo phát triển một cơ sở dữ liệu vector trong bộ nhớ dựa trên Postgres, và trước đó là Giám đốc Sản phẩm Cấp cao tại Intel. Santi có bằng Tiến sĩ về Khoa học và Kỹ thuật Tính toán từ Đại học Pennsylvania. Jacques Guigné Giáo sư Jacques Yves Guigné là Cố vấn Cấp cao cho Kraken Robotics ở Newfoundland, Canada. Ông giữ chức vụ Giám đốc Khoa học (CSO) của Subsea Micropiles Ltd., công ty hoạt động tại Ireland và Vương quốc Anh. Ông cũng là Giám đốc Điều hành của Acoustic Zoom Inc., một công ty nghiên cứu địa vật lý hàng đầu. Jacques mang đến kinh nghiệm phong phú về hình ảnh âm học và đã đóng góp đáng kể vào việc lập bản đồ đáy biển phức tạp. Những thành tựu khoa học của ông bao gồm hơn 80 bằng sáng chế và 70 ấn phẩm đã nhận được số lượng trích dẫn ấn tượng trên ResearchGate. Ông đã được vinh danh trong lĩnh vực vật lý với các Huy chương Deryck Chesterman và Rayleigh, phản ánh những đóng góp của ông cho địa vật lý, minh chứng bằng bằng DSc và Tiến sĩ của mình. Ngoài ra, ông còn được công nhận là Thành viên của Geoscience Canada và là Giám đốc của PEGNL (Kỹ sư Chuyên nghiệp và Nhà Khoa học Địa chất Newfoundland và Labrador). Ryan Qi Ryan có 19 năm kinh nghiệm trong lĩnh vực mô hình hóa và mô phỏng Đa Vật lý (Multiphysics), chiến lược và phát triển kinh doanh trên cả mảng công nghiệp và kỹ thuật số. Tại AWS, Ryan là Trưởng nhóm BD/GTM Toàn cầu Chính (Principal Worldwide BD/GTM Leader), tập trung vào các công nghệ mô phỏng và hệ thống tự hành. Souvik Mukherjee Tiến sĩ Souvik Mukherjee là thành viên sáng lập của EmPact-AI và là Cố vấn Kỹ thuật Chính. Sự nghiệp hơn 15 năm của ông trải dài qua nhiều lĩnh vực trong ngành năng lượng và công nghệ với vai trò là một nhà địa vật lý, nhà khoa học dữ liệu và người dẫn dắt sản phẩm nổi tiếng. Ông đã được công nhận với nhiều giải thưởng uy tín trong ngành như giải thưởng Shell GameChanger (2015), giải bài báo xuất sắc nhất và đổi mới URTeC 2019, cùng nhiều giải thưởng khác. Ông cũng được công nhận về khả năng quản lý, thực hiện và cung cấp thành công nhiều dự án có giá trị hàng triệu đô la, bao gồm việc thương mại hóa thành công công nghệ phân định vết nứt thủy lực có chống đỡ từng đoạt giải thưởng, QUANTUM cho Carbo Ceramics, và việc thực hiện Nghiên cứu Thăm dò Tiên phong Shell (Shell Frontier Exploration Study), điều phối một đội ngũ gồm 15 chuyên gia kỹ thuật thuộc nhiều chuyên môn và phòng ban, vốn đã có tác động tích cực mạnh mẽ đến chiến lược mua lại hợp đồng thuê trị giá 100 triệu đô la của Shell. Srinivas Tadepalli Srinivas là trưởng bộ phận đưa HPC ra thị trường (go-to-market) toàn cầu tại AWS, chịu trách nhiệm xây dựng một chiến lược GTM toàn diện cho nhiều khối lượng công việc HPC và điện toán tăng tốc (Accelerated computing) cho cả khách hàng thương mại và công khu vực công. Trước đây, ông làm việc tại Dassault Systems và có bằng Tiến sĩ về kỹ thuật y sinh. Vidyasagar Ananthan Vidyasagar chuyên sâu về điện toán hiệu năng cao (high performance computing), mô phỏng số (numerical simulations), kỹ thuật tối ưu hóa và phát triển phần mềm trong cả môi trường công nghiệp và học thuật. Tại AWS, Vidyasagar là Kiến trúc sư Giải pháp Cấp cao (Senior Solutions Architect), phát triển các mô hình dự đoán và công nghệ mô phỏng. "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":"Khai mở toàn bộ tiềm năng của Amazon Connect Bởi Puneet Badlani và Eliza Taylor – ngày 12 tháng 5 năm 2025, chuyên mục Amazon Connect, Best Practices, Foundational (100), Thought Leadership\nNgày nay, người tiêu dùng có kỳ vọng rất cao – và khách hàng của bạn cũng không ngoại lệ. Mọi doanh nghiệp đều đang chạy đua để bắt kịp những đổi mới công nghệ mới nhất có thể cải thiện dịch vụ, giảm chi phí và hỗ trợ tăng trưởng chiến lược. Amazon Connect là một trong những giải pháp đó – được vận hành bởi sức mạnh của AWS và AI, đây là một giải pháp hiện đại và có khả năng mở rộng. Tuy nhiên, nếu bạn cắt giảm trong khâu triển khai, bạn có thể làm ảnh hưởng đến lợi ích tiềm năng.\nChúng ta sẽ cùng xem xét cách mà các thực tiễn quản trị thay đổi có thể không chỉ bảo vệ mà còn tăng tốc cho khoản đầu tư – những rủi ro cần chú ý, những chỉ số nào thực sự tạo khác biệt, và cách tận dụng tối đa thời gian và nguồn lực hạn chế để mang lại những thay đổi có tác động lớn.\nĐừng “vấp ngã” vì các bên liên quan “Các bên liên quan” (stakeholders) thường bị hiểu sai. Nhiều tổ chức hoặc tập trung quá nhiều vào bên trong hoặc bên ngoài. Trong một dự án chuyển đổi công nghệ và quy trình dịch vụ khách hàng, điều quan trọng là tập trung vào các bên liên quan bên ngoài, vì họ có ảnh hưởng trực tiếp.\nCác bên liên quan bên ngoài là khách hàng, đối tác và nhà cung cấp – những người liên hệ với trung tâm chăm sóc khách hàng. Khả năng của họ trong việc tiếp nhận thông tin, giải quyết vấn đề và cảm thấy được lắng nghe có ý nghĩa rất lớn đến thành công của chương trình, cũng như việc họ có tiếp tục gắn bó lâu dài với bạn hay không.\nỞ nội bộ, với các dự án lớn, cần có sự phối hợp toàn tổ chức. Một nhà tài trợ cấp cao (executive sponsor) có thể điều phối nguồn lực và đảm bảo thành công. Ngoài CNTT, vận hành dịch vụ khách hàng và marketing, bạn cũng cần có sự tham gia của tài chính, nhân sự và các bộ phận khác. Cuối cùng, không phải mọi bên liên quan đều bình đẳng – mức độ tham gia và giám sát sẽ phụ thuộc vào vai trò và tầm ảnh hưởng.\nHiểu rõ bạn thực sự cần gì Amazon Connect là một giải pháp mạnh mẽ và có thể tùy biến, hỗ trợ nhiều nhóm – từ liên hệ đa kênh (omnichannel), tự động hóa tương tác, hỗ trợ tác nhân bằng AI sinh, báo cáo động, đánh giá tự động, và nhiều hơn nữa.\nTuy nhiên, nếu không hiểu rõ quy trình hiện tại, điểm đau và yêu cầu kinh doanh, bạn có nguy cơ làm lệch phạm vi (scope) và mất đi lợi ích. Bạn có cần một IVR thông minh để giảm số lượng cuộc gọi và tiết kiệm thời gian chuyển tiếp tác nhân? Bạn có cần Connect tích hợp với hệ thống CRM cũ? Bạn có bị trễ SLA do khối lượng cuộc gọi tăng đột biến hoặc vấn đề lập lịch?\nXác định những yếu tố này từ sớm, lộ trình triển khai sẽ tự hình thành, đi kèm cơ sở kinh doanh rõ ràng. Bạn sẽ có một câu chuyện thuyết phục với các metrics chứng minh ROI và mục tiêu rõ ràng cho đội ngũ. Đây cũng là thế mạnh của AWS Partner – CloudInteract, tận dụng AI để khai mở insight và mang lại độ chính xác cao cho kế hoạch cải tiến.\nĐảm bảo có nhà tài trợ cấp lãnh đạo Một executive sponsor nhiệt huyết đóng vai trò quan trọng trong việc tạo động lực và nâng cao nhận thức trong tổ chức cho bất kỳ chương trình chuyển đổi nào. Họ cần có một tầm nhìn thuyết phục và bằng việc chủ động quảng bá dự án, họ sẽ giúp phát hiện và xử lý các rủi ro tiềm ẩn.\nCách tiếp cận này đảm bảo rào cản được giải quyết sớm, đồng thời thúc đẩy môi trường hợp tác, nơi các bên liên quan đều cảm thấy được khuyến khích đóng góp. Nhờ vậy, tổ chức quản lý dự án tốt hơn và đưa ra quyết định kịp thời. Sự hiện diện và hỗ trợ của executive sponsor cũng xây dựng niềm tin và uy tín – yếu tố thiết yếu để triển khai thành công.\nXây dựng “đại sứ thay đổi” Sai lầm lớn nhất trong chuyển đổi công nghệ là nghĩ rằng không cần “kể câu chuyện” về thay đổi – rằng vài email liệt kê lợi ích kỹ thuật và một khóa đào tạo là đủ.\nBạn cần chạy một chiến dịch truyền thông nội bộ cho sự thay đổi. Nếu đầu tư vào các kênh giao tiếp hai chiều (email được giám sát, buổi chia sẻ, diễn đàn cộng đồng, phiên hỏi đáp sau townhall), bạn sẽ vừa tạo được thiện chí, vừa thu thập insight từ chuyên gia nghiệp vụ.\nHãy mở rộng tầm ảnh hưởng bằng cách tuyển chọn và hỗ trợ champions – những nhân sự có khả năng lan tỏa thay đổi. Họ thường là những người dùng sớm (early adopters), tester. Bạn có thể khuyến khích bằng cách đưa các hoạt động này vào mục tiêu hằng năm, từ đó mở rộng tác động đến các nhóm bị ảnh hưởng.\nĐào tạo hiệu quả hơn với ít nguồn lực hơn Khi dự án đi qua nhiều giai đoạn, các nhóm khác nhau sẽ cần đào tạo khác nhau. Ban đầu, nhóm CNTT cần làm quen với môi trường mới, cách thiết lập và quản lý. Tiếp theo, nhóm vận hành phải đào tạo tác nhân và giám sát viên để sử dụng hằng ngày. Tất cả bắt đầu từ đánh giá tác động thay đổi (change impact assessment).\nTrong đánh giá này, cần xác định nhóm nào bị ảnh hưởng nhiều nhất và quan trọng nhất. Nếu nguồn lực hạn chế và không thể đào tạo trực tiếp cho tất cả, hãy tập trung vào các nhóm “business-breakers” – những nhóm giữ vai trò sống còn. Với các nhóm khác, có thể thay thế bằng đào tạo từ xa hoặc tự học.\nĐo lường những gì thực sự quan trọng Đừng để metrics chỉ là khẩu hiệu. Việc báo cáo tỉ lệ mở email có thực sự cho thấy nhân viên đã hiểu thay đổi chưa? Một email được mở không đồng nghĩa với nhận thức. Một cách đo lường tốt hơn có thể là số lượng buổi họp do quản lý chủ trì – dựa trên bộ công cụ bạn cung cấp.\nSai lầm là chỉ đo lường số liệu dự án. Thực sự, bạn cần chứng minh cải tiến dài hạn: tỉ lệ giảm chuyển cuộc gọi, thời gian xử lý, CSAT, hay so sánh với thời gian cho các công việc thủ công trước đây như lập lịch ca, đánh giá hiệu suất, hoặc báo cáo.\nBáo cáo tiến độ dự án là quan trọng nhưng chỉ mang tính tạm thời – những metrics thực sự quan trọng là từ business case. Hãy bắt đầu theo dõi chúng càng sớm càng tốt, đặc biệt trong triển khai theo giai đoạn, để kịp thời nhận ra lỗ hổng trong đào tạo và mức độ tiếp nhận.\nTóm lại… Có một vài yếu tố then chốt giúp quá trình triển khai Amazon Connect trở nên hiệu quả và khai mở toàn bộ lợi ích. Hãy lập kế hoạch trước, đưa tổ chức đồng hành, triển khai cẩn trọng, và giải pháp contact center được hỗ trợ bởi AI này sẽ vượt xa kỳ vọng – từ đa kênh, tác nhân, tự động hóa đến phân tích.\nHãy liên hệ với AWS và CloudInteract để được hỗ trợ thêm trong việc khai thác tối đa sức mạnh của Amazon Connect (tạm dịch: khai mở các siêu năng lực của Amazon Connect).\n"},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/3-blogstranslated/3.4-blog4/","title":"Blog 4","tags":[],"description":"","content":"Bắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/3-blogstranslated/3.5-blog5/","title":"Blog 5","tags":[],"description":"","content":"Bắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/3-blogstranslated/3.6-blog6/","title":"Blog 6","tags":[],"description":"","content":"Bắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/5-workshop/5.4-s3-onprem/5.4.1-prepare/","title":"Chuẩn bị tài nguyên","tags":[],"description":"","content":"Để chuẩn bị cho phần này của workshop, bạn sẽ cần phải:\nTriển khai CloudFormation stack Sửa đổi bảng định tuyến VPC. Các thành phần này hoạt động cùng nhau để mô phỏng DNS forwarding và name resolution.\nTriển khai CloudFormation stack Mẫu CloudFormation sẽ tạo các dịch vụ bổ sung để hỗ trợ mô phỏng môi trường truyền thống:\nMột Route 53 Private Hosted Zone lưu trữ các bản ghi Bí danh (Alias records) cho điểm cuối PrivateLink S3 Một Route 53 Inbound Resolver endpoint cho phép \u0026ldquo;VPC Cloud\u0026rdquo; giải quyết các yêu cầu resolve DNS gửi đến Private Hosted Zone Một Route 53 Outbound Resolver endpoint cho phép \u0026ldquo;VPC On-prem\u0026rdquo; chuyển tiếp các yêu cầu DNS cho S3 sang \u0026ldquo;VPC Cloud\u0026rdquo; Click link sau để mở AWS CloudFormation console. Mẫu yêu cầu sẽ được tải sẵn vào menu. Chấp nhận tất cả mặc định và nhấp vào Tạo stack. Có thể mất vài phút để triển khai stack hoàn tất. Bạn có thể tiếp tục với bước tiếp theo mà không cần đợi quá trình triển khai kết thúc.\nCập nhật bảng định tuyến private on-premise Workshop này sử dụng StrongSwan VPN chạy trên EC2 instance để mô phỏng khả năng kết nối giữa trung tâm dữ liệu truyền thống và môi trường cloud AWS. Hầu hết các thành phần bắt buộc đều được cung cấp trước khi bạn bắt đầu. Để hoàn tất cấu hình VPN, bạn sẽ sửa đổi bảng định tuyến \u0026ldquo;VPC on-prem\u0026rdquo; để hướng lưu lượng đến cloud đi qua StrongSwan VPN instance.\nMở Amazon EC2 console\nChọn instance tên infra-vpngw-test. Từ Details tab, copy Instance ID và paste vào text editor của bạn để sử dụng ở những bước tiếp theo\nĐi đến VPC menu bằng cách gõ \u0026ldquo;VPC\u0026rdquo; vào Search box\nClick vào Route Tables, chọn RT Private On-prem route table, chọn Routes tab, và click Edit Routes.\nClick Add route. Destination: CIDR block của Cloud VPC Target: ID của infra-vpngw-test instance (bạn đã lưu lại ở bước trên) Click Save changes "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/4-eventparticipated/4.1-event1/","title":"Event 1","tags":[],"description":"","content":"Bài thu hoạch “Vietnam Cloud Day 2025: Ho Chi Minh City Connect Edition for Builders (Track 1: GenAI \u0026amp; Data)” Mục Đích Của Sự Kiện Tìm hiểu bảo mật trong GenAI và AI Agent để tăng cường an toàn cho doanh nghiệp Khám phá AI-Driven Development Lifecycle (AI-DLC) và ứng dụng vào quy trình phát triển phần mềm Xây dựng nền tảng dữ liệu hợp nhất nhằm tối ưu cho phân tích và trí tuệ nhân tạo Cập nhật chiến lược và xu hướng GenAI mới nhất trên AWS Danh Sách Diễn Giả Jun Kai Loke – AI/ML Specialist SA, AWS Kien Nguyen – Solutions Architect, AWS Tamelly Lim – Storage Specialist SA, AWS Binh Tran – Senior Solutions Architect, AWS Taiki Dang – Solutions Architect, AWS Michael Armentano – Principal WW GTM Specialist, AWS Nội Dung Nổi Bật Nội dung chính Nền tảng dữ liệu thống nhất trên AWS cho AI \u0026amp; Analytics\nXây dựng data platform end-to-end: ingestion → lưu trữ → xử lý → truy cập → quản trị. Xóa silo dữ liệu, con người, quy trình; hỗ trợ self-service \u0026amp; chuẩn hóa governance. Dịch vụ tiêu biểu: S3, Glue, Redshift, Lake Formation, OpenSearch, Kinesis/MSK. Chiến lược GenAI trên AWS\nTầm nhìn, xu hướng và lộ trình áp dụng GenAI. Amazon Bedrock: chọn model, RAG, guardrails, tối ưu chi phí/độ trễ. AgentCore \u0026amp; Amazon Nova hỗ trợ tích hợp công cụ và frameworks (CrewAI, LangGraph, LlamaIndex\u0026hellip;). Bảo mật ứng dụng GenAI\nRủi ro OWASP LLM; bảo mật nhiều lớp: hạ tầng → mô hình → ứng dụng. 5 trụ cột: Compliance, Privacy, Controls, Risk Management, Resilience. Công cụ: Bedrock Guardrails, Human-in-the-loop, Observability (OpenTelemetry). AI Agents – Tăng cường năng suất\nTừ assistant đến multi-agent systems, tự động hóa và giảm giám sát. Ứng dụng: CSKH, BI với Amazon Q (QuickSight), tự động hóa quy trình. Độ tin cậy \u0026amp; tính đúng đắn của GenAI\nGiảm hallucination bằng Prompt Engineering, RAG, Fine-tuning. RAG workflow: input → embedding → context → LLM → output. AI-Driven Development Lifecycle (AI-DLC)\nVòng đời: Inception → Construction → Operation. Tiến hóa: AI-Assisted → AI-Driven → AI-Managed. Triển khai với IaC, test tự động, giám sát \u0026amp; quản trị rủi ro. Amazon SageMaker – Unified Studio\nNền tảng hợp nhất cho data, analytics \u0026amp; AI. Hỗ trợ Lakehouse, governance, Zero-ETL integration (S3 ↔ Redshift, Aurora, DynamoDB, RDS…). MLOps đầy đủ: pipelines, registry, deployment, monitoring. Tích hợp Bedrock \u0026amp; JumpStart để tăng tốc phát triển ứng dụng GenAI. Những Gì Học Được Tư duy thiết kế\nThiết kế hệ thống dữ liệu \u0026amp; AI theo hướng end-to-end, loại bỏ silo. Ứng dụng nguyên tắc self-service và governance ngay từ đầu. Kiến trúc kỹ thuật\nTích hợp dịch vụ AWS (S3, Glue, Redshift, SageMaker, Bedrock…) thành nền tảng thống nhất. Áp dụng Zero-ETL, Lakehouse, MLOps để đảm bảo tính mở rộng, quản trị và vận hành bền vững. Tận dụng AI Agents và GenAI frameworks để tự động hóa quy trình \u0026amp; tăng năng suất. Chiến lược\nXác định lộ trình áp dụng GenAI trong doanh nghiệp, cân bằng giữa tốc độ đổi mới và chi phí. Chú trọng bảo mật nhiều lớp: hạ tầng, mô hình, ứng dụng; kết hợp guardrails \u0026amp; human-in-the-loop. Ưu tiên độ tin cậy và tính đúng đắn của AI qua RAG, prompt engineering, fine-tuning. Tư duy phát triển phần mềm\nTiến hóa từ AI-Assisted → AI-Driven → AI-Managed. AI-DLC (AI-Driven Development Lifecycle) giúp chuẩn hóa quy trình phát triển với AI tham gia ở mọi giai đoạn. Ứng Dụng Vào Công Việc Trong dự án:\nThử AI Agent cho đăng ký/đăng nhập và hỗ trợ khách hàng. Dùng validation/guardrails để tích hợp GenAI an toàn. Trong học tập \u0026amp; team project:\nÁp dụng AI-DLC để chia việc: AI hỗ trợ tạo code/tài liệu, team review \u0026amp; approve. Biết khi nào dùng Lambda (serverless) và khi nào dùng container (ECS/Fargate). Trong vai trò học việc:\nHọc cách tiếp cận business-first khi viết tài liệu, thu thập yêu cầu. Nhận ra data foundation là yếu tố cốt lõi để GenAI mang lại giá trị. Trải nghiệm trong event Tham gia workshop “GenAI-powered App-DB Modernization” là một trải nghiệm rất bổ ích, giúp tôi có cái nhìn toàn diện về cách hiện đại hóa ứng dụng và cơ sở dữ liệu bằng các phương pháp và công cụ hiện đại. Một số trải nghiệm nổi bật:\nHọc hỏi từ các chuyên gia Các chuyên gia AWS chia sẻ xu hướng mới về GenAI, Data Foundation và Security. Hiểu rõ hơn cách xây dựng nền tảng dữ liệu thống nhất để phục vụ AI \u0026amp; Analytics. Ấn tượng với tầm nhìn AI Agents và tiềm năng nâng cao năng suất trong doanh nghiệp. Trải nghiệm kỹ thuật thực tế Học cách thiết kế pipeline dữ liệu end-to-end: ingestion → lưu trữ → xử lý → truy cập → governance. Tiếp cận các công cụ như Amazon Bedrock, AgentCore, SageMaker Unified Studio. Trải nghiệm các giải pháp giảm hallucination (Prompt Engineering, RAG). Hiểu cách áp dụng AI-DLC để phân chia task giữa AI và con người trong quá trình phát triển phần mềm. Ứng dụng công cụ và phương pháp Tìm hiểu Bedrock Guardrails để đảm bảo tính an toàn khi triển khai GenAI. Thấy rõ giá trị của serverless (AWS Lambda) và khi nào nên dùng containerization (ECS/Fargate). Biết cách tận dụng Amazon Q cho BI (QuickSight) và hỗ trợ customer support. Kết nối \u0026amp; trao đổi Event là cơ hội để trao đổi với chuyên gia AWS và học hỏi từ case study thực tế. Nhận ra tầm quan trọng của business-first approach trong mọi quyết định công nghệ. Bài học rút ra GenAI không chỉ là công cụ, mà cần chiến lược \u0026amp; kiến trúc kỹ thuật đúng đắn để tạo giá trị. Dữ liệu và bảo mật là nền tảng, không có thì AI khó phát huy hiệu quả. AI Agents và AI-DLC hứa hẹn thay đổi cách chúng ta thiết kế và vận hành hệ thống. Một số hình ảnh khi tham gia sự kiện "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/4-eventparticipated/4.2-event2/","title":"Event 2","tags":[],"description":"","content":"Bài thu hoạch “Vòng đời phát triển theo hướng AI: Tái định hình kỹ thuật phần mềm” Mục Đích Của Sự Kiện Hiểu rõ cách AI có thể tự động hóa và tối ưu hóa từng giai đoạn trong vòng đời phát triển phần mềm (Software Development Lifecycle – SDLC). Nắm bắt được triết lý AI hỗ trợ con người thay vì thay thế con người trong quá trình xây dựng ứng dụng. Trực tiếp quan sát cách Amazon Q và các công cụ AI khác hỗ trợ lập trình viên từ giai đoạn khởi tạo ý tưởng, viết mã, đến triển khai hạ tầng (IaC – Infrastructure as Code). Nhận thức được xu hướng “AI-first development” – nơi AI trở thành một phần tự nhiên của quy trình phát triển phần mềm tương lai. Danh Sách Diễn Giả Toan Huynh My Nguyen Nội Dung Nổi Bật Thử thách khi lập trình với AI Phần mở đầu trình bày những hạn chế và thách thức khi đưa AI vào lập trình:\nAI chưa thể xử lý các project có logic phức tạp, đòi hỏi hiểu biết sâu về ngữ cảnh nghiệp vụ. Lập trình viên khó kiểm soát chi tiết trong mã sinh ra nếu không mô tả rõ ràng mục tiêu và phạm vi. Chất lượng code phụ thuộc nhiều vào prompt và context mà người dùng cung cấp. Đây chính là lý do AI-DLC ra đời: tạo ra một quy trình có cấu trúc, giúp AI và con người phối hợp hiệu quả hơn.\nAI in Development – How AI is Changing Software Phần này phân tích cách AI đang thay đổi ngành phần mềm:\nAI hỗ trợ sinh code, tạo tài liệu kỹ thuật, thiết kế API, và kiểm thử tự động. Developer chuyển vai trò từ “code writer” sang “AI orchestrator” — người điều phối, định hướng và đánh giá đầu ra. Các công cụ như Amazon Q, GitHub Copilot, ChatGPT for Developers trở thành công cụ trung tâm trong workflow của team dev hiện đại. 🔹 Giới thiệu về AI-DLC là gì AI-Driven Development Lifecycle (AI-DLC) là phương pháp tiếp cận phát triển phần mềm có sự đồng hành của AI, nơi mỗi bước được thiết kế để cung cấp cho AI ngữ cảnh và mục tiêu cụ thể nhằm tạo ra kết quả chính xác hơn.\n🟧 Inception\nBuild Context on Existing Codes – AI được “nuôi” bằng mã nguồn hiện tại để hiểu cấu trúc dự án. Elaborate Intent with User Stories – Developer mô tả yêu cầu thông qua user story, làm rõ mục tiêu. Plan with Units of Work – Phân tách công việc thành các đơn vị nhỏ để AI có thể thực thi và sinh code từng phần. 🟦 Construction\nDomain Model (Component Model) – Xây dựng mô hình miền hoặc sơ đồ kiến trúc logic. Generate Code \u0026amp; Test – AI sinh code và test tự động dựa trên thông tin đã lên kế hoạch. Add Architectural Components – Bổ sung các thành phần kiến trúc như API, data layer, logging, security. Deploy with IaC \u0026amp; Tests – Tự động triển khai hệ thống với Infrastructure as Code và test tích hợp. 🔁 Mỗi bước đều cung cấp thêm “rich context” cho bước kế tiếp, giúp AI hiểu sâu hơn về hệ thống và sinh ra kết quả ngày càng chính xác.\nCORE CONCEPTS – Ba nguyên lý cốt lõi Context Awareness – AI cần có ngữ cảnh rõ ràng về mã, yêu cầu và domain để hoạt động hiệu quả. Collaborative Generation – Con người và AI hợp tác: AI sinh code, con người định hướng và kiểm duyệt. Continuous Refinement – Quy trình lặp lại liên tục để tinh chỉnh đầu ra và cải thiện chất lượng. Mob Elaboration Mob Elaboration là phương pháp mở rộng yêu cầu (intent elaboration) theo hình thức cộng tác nhóm:\nNhiều thành viên cùng nhau mô tả yêu cầu, đặt câu hỏi, và bổ sung thông tin cho AI. Giúp AI hiểu sâu hơn về nghiệp vụ, mục tiêu và logic phức tạp của dự án. Cách tiếp cận này giúp giảm rủi ro hiểu sai yêu cầu, đặc biệt trong các team lớn hoặc đa miền. 5-Stage Sequential Process của AI-DLC AI-DLC được thực hiện qua 5 giai đoạn:\nInception – Hiểu yêu cầu, phân tích hệ thống. Construction – Tạo mô hình miền và cấu trúc ban đầu. Generation – Sinh mã tự động. Testing – Tự động hóa kiểm thử đơn vị và tích hợp. Deployment – Triển khai ứng dụng với IaC và CI/CD pipelines. Mỗi vòng lặp giúp AI học thêm và cải thiện chất lượng đầu ra.\nDemo 1 – Trải nghiệm trực quan AI DLC với Amazon Q Buổi demo minh họa cách áp dụng AI-DLC trong thực tế thông qua một dự án nhỏ:\nBắt đầu từ ý tưởng đơn giản → chuyển thành user story mô tả yêu cầu nghiệp vụ. AI hỗ trợ phân chia công việc (Units of Work) và lập kế hoạch chi tiết cho từng module. Người tham dự có thể điều khiển AI thông qua câu hỏi, checkbox và điều kiện logic, giúp AI hiểu rõ phạm vi công việc. AI tiếp tục sinh code, viết test, tạo cấu trúc dự án và triển khai thử nghiệm tự động. Demo thể hiện rõ cách AI và con người phối hợp nhịp nhàng: AI làm việc lặp đi lặp lại, con người định hướng và ra quyết định chiến lược. Giới Thiệu Về Kiro Triết Lý Của Kiro\nPhần tiếp theo của workshop giới thiệu Kiro, một môi trường phát triển thông minh được thiết kế xoay quanh triết lý “AI-native development” – nơi AI là một phần cốt lõi, không phải chỉ là công cụ hỗ trợ.\nTriết lý của Kiro tập trung vào ba yếu tố chính:\nTích hợp sâu với quy trình phát triển – AI không chỉ hỗ trợ viết code, mà còn tham gia lập kế hoạch, quản lý context, và phân tích tác động thay đổi. Hiểu ngữ cảnh dự án toàn diện – Kiro duy trì trạng thái hiểu biết liên tục về cấu trúc hệ thống, cho phép AI tương tác với toàn bộ project thay vì từng file riêng lẻ. Kiểm soát \u0026amp; cộng tác thông minh – Lập trình viên có thể hướng dẫn AI thông qua contextual commands, giúp đảm bảo rằng mỗi thay đổi đều có mục đích rõ ràng và nhất quán với hệ thống. Cấu Trúc Project Trong Kiro\nKhác với các text editor truyền thống như VSCode hay JetBrains, Kiro không chỉ là môi trường viết mã — nó là AI workspace có nhận thức cấu trúc.\nCấu trúc project trong Kiro bao gồm:\nContext Layer – Lưu trữ ngữ cảnh, domain model, và quan hệ giữa các module. Task Layer – Quản lý các đơn vị công việc (Units of Work) được AI theo dõi và hoàn thành dần. AI Agent Layer – Mỗi tác vụ (code, test, refactor, deploy) có agent riêng đảm nhận, tạo ra mô hình phát triển đa agent – hợp tác – song song. Human-in-the-Loop Control – Lập trình viên có thể can thiệp ở mọi bước: xác nhận, sửa đổi hoặc từ chối đầu ra của AI. Điều này giúp Kiro không chỉ là công cụ sinh code mà trở thành một hệ sinh thái phát triển hợp tác giữa người và AI.\nDemo 2: Kiro – Áp Dụng AI-DLC Trong phần trình diễn, diễn giả minh họa cách Kiro vận hành AI-DLC một cách liền mạch:\nNgười dùng nhập một yêu cầu nghiệp vụ cơ bản, ví dụ “xây dựng hệ thống quản lý sự kiện”. Kiro tự động phân tích intent, tạo domain model và chia nhỏ thành các user story. AI trong Kiro sinh ra các module, component và test case tương ứng. Developer có thể tương tác qua bảng kiểm (checkbox-based task control) để xác nhận từng phần việc. Cuối cùng, Kiro triển khai hệ thống hoàn chỉnh với IaC và kiểm thử tự động. Buổi demo cho thấy AI-DLC không chỉ là lý thuyết, mà có thể được triển khai thực tế ngay trong môi trường Kiro — nơi AI, con người, và quy trình phát triển hòa quyện thành một hệ thống thống nhất.\nTrải nghiệm trong event Tham gia buổi workshop “AI DLC x Kiro: Reinventing Developer Experience with AI” là một trải nghiệm vô cùng bổ ích, giúp tôi hiểu rõ hơn về cách AI được tích hợp sâu vào môi trường phát triển phần mềm và cách mà triết lý thiết kế của Kiro mang lại hướng tiếp cận mới cho developer.\nHọc hỏi từ các diễn giả có chuyên môn cao Các diễn giả đã chia sẻ về AI DLC – một nền tảng hỗ trợ phát triển phần mềm dựa trên AI, giúp tự động hóa nhiều quy trình trong SDLC. Ngoài ra, phần giới thiệu về Kiro Editor mang lại cái nhìn sâu sắc về cách xây dựng một text editor theo hướng AI-native thay vì chỉ “thêm plugin AI” vào môi trường cũ. Tôi đặc biệt ấn tượng với triết lý của Kiro: tối giản, hiệu năng cao, tập trung vào trải nghiệm người dùng và khả năng mở rộng theo module. Trải nghiệm kỹ thuật thực tế Buổi demo minh họa cách sử dụng AI DLC kết hợp với Kiro để tạo, chỉnh sửa và tối ưu mã nguồn một cách thông minh. Tôi được chứng kiến một project nhỏ được khởi tạo và quản lý ngay trong Kiro, với khả năng AI tự động đề xuất refactor, viết test case và phân tích logic code. So với các text editor phổ biến như VSCode hay Sublime, Kiro thể hiện sự khác biệt nhờ kiến trúc AI-first và plugin architecture nhẹ, cho phép tích hợp AI mà không làm giảm hiệu suất. Ứng dụng công cụ hiện đại Việc trải nghiệm AI DLC trên Kiro giúp tôi hiểu rõ hơn về khả năng tự động hóa quy trình phát triển, đặc biệt là ở các bước như code generation, documentation và debugging. Tôi nhận ra tiềm năng của việc xây dựng công cụ học tập và làm việc cá nhân có khả năng gợi ý thông minh, giúp rút ngắn thời gian phát triển và nâng cao chất lượng sản phẩm. Các khái niệm về modular design của Kiro cũng gợi ý cho tôi hướng đi trong việc thiết kế hệ thống linh hoạt, dễ mở rộng và dễ bảo trì. Kết nối và trao đổi Workshop tạo cơ hội để tôi giao lưu với các developer, nhà nghiên cứu AI và product designer, từ đó hiểu thêm về xu hướng AI-augmented development. Qua các cuộc thảo luận, tôi học được nhiều về cách AI có thể đóng vai trò cộng tác viên sáng tạo, giúp developer tập trung hơn vào logic và tư duy hệ thống thay vì những thao tác lặp lại. Bài học rút ra AI DLC kết hợp Kiro là ví dụ điển hình cho thế hệ công cụ phát triển mới — AI-first IDE, nơi AI không chỉ hỗ trợ mà còn đồng hành cùng lập trình viên trong mọi giai đoạn phát triển. Triết lý “less is more” của Kiro nhấn mạnh rằng sự tối giản và hiệu suất có thể tạo ra trải nghiệm mạnh mẽ hơn bất kỳ hệ thống phức tạp nào. Tôi học được rằng việc áp dụng AI hiệu quả không chỉ nằm ở công nghệ, mà còn ở cách tích hợp và triết lý thiết kế, điều này có thể được mang vào các dự án học tập hoặc phát triển phần mềm thực tế của tôi. Một số hình ảnh khi tham gia sự kiện "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/4-eventparticipated/4.3-event3/","title":"Event 3","tags":[],"description":"","content":"Bài thu hoạch “WORKSHOP KHOA HỌC DỮ LIỆU TRÊN AWS” Mục Đích Của Sự Kiện Chia sẻ các dịch vụ AI trên AWS Hướng dẫn triển khai mô hình AI thông qua Amazon SageMaker Chia sẻ cách deploy mô hình AI và truy cập thông qua API Danh Sách Diễn Giả Văn Hoàng Kha - Cloud Solutions Architec AWS User Group Leader Bạch Doãn Vương - Cloud Develops Engineer AWS Community Builder Nội Dung Nổi Bật Giới thiệu \u0026amp; Tầm quan trọng của Cloud trong Data Science Trình bày vai trò của điện toán đám mây (Cloud Computing) trong việc hỗ trợ xử lý dữ liệu, huấn luyện và triển khai mô hình AI quy mô lớn.\nSo sánh Cloud vs. On-premise:\nCloud: khả năng mở rộng linh hoạt, triển khai nhanh, tiết kiệm chi phí vận hành, dễ dàng tích hợp. On-premise: tốn kém chi phí đầu tư ban đầu, khó mở rộng, bảo trì phức tạp. Cloud (đặc biệt là AWS) mang lại nền tảng mạnh mẽ cho Data Science pipeline — từ thu thập, lưu trữ, xử lý dữ liệu, huấn luyện, cho đến triển khai mô hình AI.\nCác Layer AI Trên AWS AWS chia hệ sinh thái AI thành 3 tầng (layers), giúp người dùng lựa chọn mức độ quản lý phù hợp với năng lực và mục tiêu của mình:\n1. AI Services (Fully Managed Layer)\nDành cho người dùng muốn ứng dụng AI mà không cần kiến thức chuyên sâu về Machine Learning.\nCác dịch vụ AI sẵn có, đã được huấn luyện bởi AWS.\nNgười dùng chỉ cần gọi API là có thể sử dụng ngay trong ứng dụng.\nVí dụ:\nAmazon Comprehend: Phân tích ngôn ngữ tự nhiên (NLP) Amazon Translate: Dịch máy học đa ngôn ngữ Amazon Textract: Trích xuất dữ liệu từ tài liệu, hóa đơn Amazon Rekognition: Nhận diện hình ảnh và video Amazon Polly: Chuyển văn bản thành giọng nói Amazon Bedrock: Truy cập các mô hình nền tảng (Foundation Models) như Claude, Titan, Mistral\u0026hellip; 👉 Lợi ích: Triển khai nhanh, không cần huấn luyện mô hình, chi phí linh hoạt theo nhu cầu sử dụng.\n2. ML Services (Semi-managed Layer)\nDành cho Data Scientist, ML Engineer muốn xây dựng, huấn luyện và triển khai mô hình ML một cách tùy chỉnh hơn.\nAmazon SageMaker là trung tâm của tầng này: cung cấp bộ công cụ đầy đủ để build – train – deploy mô hình Machine Learning.\nCác tính năng nổi bật:\nData Wrangler: Làm sạch và xử lý dữ liệu trực quan. Feature Store: Quản lý đặc trưng (features) dùng cho nhiều mô hình. AutoML (SageMaker Autopilot): Tự động huấn luyện mô hình. Model Registry \u0026amp; Monitoring: Theo dõi và quản lý mô hình sau khi deploy. 👉 Lợi ích: Toàn quyền kiểm soát pipeline ML, có thể tùy chỉnh thuật toán, môi trường huấn luyện, và quy trình triển khai.\n3. AI Infrastructure (Self-managed Layer)\nDành cho tổ chức hoặc chuyên gia muốn tự quản lý toàn bộ hạ tầng AI/ML để tối ưu chi phí hoặc hiệu năng.\nNgười dùng có thể xây dựng môi trường huấn luyện bằng cách kết hợp các dịch vụ hạ tầng cơ bản của AWS:\nAmazon EC2 / EC2 GPU Instances (P5, G6, Inferentia): Huấn luyện mô hình tùy chỉnh quy mô lớn. Amazon EKS / ECS: Chạy các workload ML trong container hoặc Kubernetes. AWS Lambda: Xử lý dữ liệu hoặc inference nhỏ gọn, serverless. Amazon S3 / EFS: Lưu trữ dữ liệu và mô hình. 👉 Lợi ích: Linh hoạt tối đa, kiểm soát toàn bộ quá trình huấn luyện, nhưng yêu cầu kiến thức kỹ thuật cao hơn.\nCác Dịch Vụ AI Phổ Biến Của AWS Hỗ Trợ Sinh Viên Trong Quá Trình Train Model 1. Amazon SageMaker\nMôi trường phát triển tích hợp (SageMaker Studio) cho toàn bộ quy trình ML:\nChuẩn bị dữ liệu Huấn luyện mô hình Theo dõi kết quả Triển khai endpoint phục vụ API inference Hỗ trợ AutoML, GPU training, model monitoring và CI/CD cho mô hình AI.\n2. Amazon Comprehend\nDịch vụ NLP giúp phân tích, hiểu và phân loại ngôn ngữ tự nhiên.\nChức năng chính:\nPhân tích cảm xúc (Sentiment Analysis) Nhận dạng thực thể (Entity Recognition) Phân loại văn bản (Text Classification) Gắn nhãn dữ liệu tự động Phát hiện ngôn ngữ Trường hợp sử dụng thực tế:\nXử lý tài liệu thông minh Phân tích mail hàng loạt để phát hiện phản hồi tích cực/tiêu cực Phân tích cảm xúc và tâm lý khách hàng Hỗ trợ trung tâm liên lạc (Contact Center Analytics) Xác thực và trích xuất thông tin cá nhân 3. Amazon Translate\nDịch vụ dịch máy học (Neural Machine Translation).\nHỗ trợ hơn 75 ngôn ngữ với độ chính xác cao và dễ tích hợp.\nỨng dụng:\nLàm website đa ngôn ngữ Dịch nội dung tự động trong ứng dụng Hỗ trợ chatbot và phân tích dữ liệu đa ngôn ngữ 4. Amazon Textract\nTự động trích xuất văn bản và dữ liệu có cấu trúc từ hình ảnh, tài liệu, hoặc biểu mẫu. Ứng dụng trong các quy trình như: số hóa hồ sơ, xử lý hóa đơn, tự động nhập dữ liệu vào hệ thống. Tổng Quan Data Science Pipeline Trên AWS Thu thập \u0026amp; lưu trữ dữ liệu: Amazon S3, AWS Data Exchange Tiền xử lý dữ liệu: AWS Glue, Lambda, Athena Huấn luyện mô hình: SageMaker (train, tune, evaluate) Triển khai mô hình: SageMaker Endpoint / Lambda + API Gateway Giám sát \u0026amp; tối ưu: CloudWatch, Model Monitor Demo 1: Thiết kế Workflow AI Training bằng Giao Diện Kéo - Thả (No-Code/Low-Code) Mục tiêu: Giới thiệu cách xây dựng quy trình huấn luyện mô hình AI mà không cần viết nhiều code.\nCông cụ sử dụng: Amazon SageMaker Studio / SageMaker Canvas\nNội dung trình diễn:\nChuẩn bị dataset và tải lên Amazon S3.\nDùng giao diện kéo-thả của SageMaker để:\nChọn nguồn dữ liệu, thuật toán huấn luyện và tham số. Thiết kế toàn bộ pipeline gồm bước làm sạch dữ liệu, training, validation và deployment. Quan sát trực quan tiến trình training và kết quả mô hình (accuracy, confusion matrix, metrics, v.v.).\nThông điệp chính: Sinh viên, nhà phát triển có thể nhanh chóng tạo workflow AI mà không cần viết code phức tạp — giúp rút ngắn thời gian nghiên cứu và thử nghiệm mô hình.\nDemo 2: Triển khai AI Service và Truy Cập Qua API/Website Mục tiêu: Giới thiệu cách deploy mô hình AI để người dùng có thể truy cập và sử dụng thực tế.\nCông cụ sử dụng: Amazon SageMaker Endpoint, API Gateway, và Lambda.\nNội dung trình diễn:\nDeploy mô hình AI đã huấn luyện lên SageMaker Endpoint. Tích hợp endpoint với API Gateway để tạo REST API công khai. Tạo đường dẫn web hoặc API URL để người dùng có thể gửi yêu cầu (ví dụ: nhập câu văn để phân tích cảm xúc hoặc dịch ngôn ngữ). Minh họa cách hiển thị kết quả trực quan (UI demo hoặc Postman/API test). Thông điệp chính: Cho thấy cách AWS hỗ trợ triển khai mô hình AI từ giai đoạn nghiên cứu đến ứng dụng thực tế — dễ dàng chia sẻ, mở rộng, và thương mại hóa.\nThảo Luận: Hiệu Năng \u0026amp; Chi Phí (Cloud vs. On-premise) Tiêu chí Cloud (AWS) On-premise Khả năng mở rộng Dễ dàng mở rộng tài nguyên theo nhu cầu Giới hạn phần cứng cố định Chi phí Trả theo mức sử dụng (Pay-as-you-go) Chi phí đầu tư ban đầu cao Triển khai Tự động, nhanh chóng Thủ công, tốn thời gian Bảo trì AWS quản lý Người dùng tự chịu trách nhiệm Thích hợp cho sinh viên ✅ Có Free Tier, dễ học và thử nghiệm ❌ Khó tiếp cận, tốn kém Kết Luận AWS cung cấp hệ sinh thái AI toàn diện từ tầng hạ tầng đến tầng ứng dụng, phù hợp với mọi đối tượng — từ sinh viên mới học AI đến doanh nghiệp triển khai quy mô lớn. Trải nghiệm trong event Tham gia workshop “AI Services on AWS for Data Science” là một trải nghiệm rất bổ ích, giúp tôi hiểu rõ hơn về vai trò của Cloud trong Data Science và cách AWS hỗ trợ huấn luyện, triển khai, và truy cập mô hình AI.\nHọc hỏi từ các diễn giả có chuyên môn cao Diễn giả giới thiệu tầm quan trọng của Cloud trong xử lý dữ liệu và huấn luyện mô hình. Hiểu rõ 3 layer AI trên AWS: AI-managed services, ML services (SageMaker), và AI frameworks. Trải nghiệm kỹ thuật thực tế Demo 1: Thiết kế workflow AI bằng cách kéo thả trong SageMaker Canvas để train model mà không cần code. Demo 2: Triển khai mô hình AI thành service có thể truy cập qua API hoặc liên kết thực tế. Ứng dụng công cụ hiện đại Tìm hiểu các dịch vụ AI nổi bật: Amazon Comprehend, Translate, và Textract. Hiểu cách các dịch vụ này hỗ trợ NLP, dịch tự động, và trích xuất dữ liệu thông minh trong nhiều ngữ cảnh. Kết nối và trao đổi Giao lưu với chuyên gia và sinh viên cùng quan tâm đến AI \u0026amp; Cloud. Trao đổi về chi phí, hiệu năng (Cloud vs On-premise) và cách tối ưu sử dụng SageMaker. Bài học rút ra Cloud là nền tảng trọng yếu trong quy trình Data Science hiện đại. AWS cung cấp đầy đủ công cụ cho mọi cấp độ AI — từ không code đến tự triển khai. Hiểu rõ hơn cách đưa mô hình AI vào sản phẩm thực tế qua các dịch vụ AWS. Một số hình ảnh khi tham gia sự kiện "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/5-workshop/5.1-workshop-overview/","title":"Giới thiệu","tags":[],"description":"","content":"Giới thiệu về VPC Endpoint Điểm cuối VPC (endpoint) là thiết bị ảo. Chúng là các thành phần VPC có thể mở rộng theo chiều ngang, dự phòng và có tính sẵn sàng cao. Chúng cho phép giao tiếp giữa tài nguyên điện toán của bạn và dịch vụ AWS mà không gây ra rủi ro về tính sẵn sàng. Tài nguyên điện toán đang chạy trong VPC có thể truy cập Amazon S3 bằng cách sử dụng điểm cuối Gateway. Interface Endpoint PrivateLink có thể được sử dụng bởi tài nguyên chạy trong VPC hoặc tại TTDL. Tổng quan về workshop Trong workshop này, bạn sẽ sử dụng hai VPC.\n\u0026ldquo;VPC Cloud\u0026rdquo; dành cho các tài nguyên cloud như Gateway endpoint và EC2 instance để kiểm tra. \u0026ldquo;VPC On-Prem\u0026rdquo; mô phỏng môi trường truyền thống như nhà máy hoặc trung tâm dữ liệu của công ty. Một EC2 Instance chạy phần mềm StrongSwan VPN đã được triển khai trong \u0026ldquo;VPC On-prem\u0026rdquo; và được cấu hình tự động để thiết lập đường hầm VPN Site-to-Site với AWS Transit Gateway. VPN này mô phỏng kết nối từ một vị trí tại TTDL (on-prem) với AWS cloud. Để giảm thiểu chi phí, chỉ một phiên bản VPN được cung cấp để hỗ trợ workshop này. Khi lập kế hoạch kết nối VPN cho production workloads của bạn, AWS khuyên bạn nên sử dụng nhiều thiết bị VPN để có tính sẵn sàng cao. "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/1-worklog/","title":"Nhật ký công việc","tags":[],"description":"","content":"Trong trang này bạn sẽ cần giới thiệu worklog của bạn như thế nào? Bạn hoàn thành chương trình trong vòng bao nhiêu tuần? Bạn đã làm gì trong các tuần đó?\nThông thường và cũng là tiêu chuẩn, một worklog được thực hiện trong khoảng 3 tháng (trong suốt thời gian thực tập) với nội dung các tuần như sau:\nTuần 1: Làm quen với các nền tảng AWS, Mạng VPC, Bảo mật và Thực hành Labs\nTuần 2: Thực hành AWS EC2, Auto Scaling, CloudWatch, Backup, S3, FSx, Storage Gateway\nTuần 3: Dịch vụ Bảo mật \u0026amp; Cơ sở dữ liệu trên AWS (IAM, Cognito, KMS, RDS, Aurora, Redshift, ElastiCache)\nTuần 4: Kỹ thuật dữ liệu AWS, Cơ sở dữ liệu NoSQL và Quy trình phát triển AI\nTuần 5: Dịch vụ Phân tích dữ liệu AWS, Cơ sở dữ liệu, Quy trình phát triển AI \u0026amp; Thực hành dịch thuật kỹ thuật\nTuần 6: Dịch vụ Phân tích dữ liệu AWS, Cơ sở dữ liệu, Quy trình phát triển AI \u0026amp; Thực hành dịch thuật kỹ thuật\nTuần 7: Ôn tập lại các dịch vụ AWS cơ bản và luyện tập các câu trắc nghiệm\nTuần 8: Làm công việc H\u0026hellip;\nTuần 9: Làm công việc I\u0026hellip;\nTuần 10: Làm công việc L\u0026hellip;\nTuần 11: Làm công việc M\u0026hellip;\nTuần 12: Làm công việc N\u0026hellip;\n"},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/5-workshop/5.3-s3-vpc/5.3.1-create-gwe/","title":"Tạo một Gateway Endpoint","tags":[],"description":"","content":" Mở Amazon VPC console Trong thanh điều hướng, chọn Endpoints, click Create Endpoint: Bạn sẽ thấy 6 điểm cuối VPC hiện có hỗ trợ AWS Systems Manager (SSM). Các điểm cuối này được Mẫu CloudFormation triển khai tự động cho workshop này.\nTrong Create endpoint console: Đặt tên cho endpoint: s3-gwe Trong service category, chọn aws services Trong Services, gõ \u0026ldquo;s3\u0026rdquo; trong hộp tìm kiếm và chọn dịch vụ với loại gateway Đối với VPC, chọn VPC Cloud từ drop-down menu. Đối với Route tables, chọn bảng định tuyến mà đã liên kết với 2 subnets (lưu ý: đây không phải là bảng định tuyến chính cho VPC mà là bảng định tuyến thứ hai do CloudFormation tạo). Đối với Policy, để tùy chọn mặc định là Full access để cho phép toàn quyền truy cập vào dịch vụ. Bạn sẽ triển khai VPC endpoint policy trong phần sau để chứng minh việc hạn chế quyền truy cập vào S3 bucket dựa trên các policies. Không thêm tag vào VPC endpoint. Click Create endpoint, click x sau khi nhận được thông báo tạo thành công. "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/1-worklog/1.1-week1/","title":"Worklog Tuần 1","tags":[],"description":"","content":"Mục tiêu tuần 1: Hiểu các kiến thức cơ bản về điện toán đám mây và hạ tầng toàn cầu của AWS. Học cách quản lý dịch vụ AWS thông qua Management Console, CLI và SDK. Tìm hiểu bảo mật, IAM và quản lý chi phí AWS thông qua các bài thực hành. Xây dựng nền tảng kiến thức về mạng VPC và kết nối (Subnet, Route Table, IGW, NAT, Peering, Transit Gateway). Thực hành trực tiếp trên AWS với các bài Lab để củng cố lý thuyết bằng kỹ năng thực tế. Nhiệm vụ trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 - Đọc và ghi chú lại các quy định, nội quy của đơn vị thực tập\n- Học Module 01:\n+ Điện toán đám mây: Khái niệm, lợi ích\n+ Tổng quan AWS:\n+ Điểm khác biệt của AWS, triết lý định giá, nguyên tắc lãnh đạo\n+ Hành trình lên đám mây\n+ Hạ tầng AWS: Data center, AZ, Region, Edge Locations\n+ Quản lý dịch vụ AWS:\n+ AWS Management Console\n+ AWS CLI\n+ AWS SDK\n- Thực hành:\n+ Lab 01: Tạo tài khoản AWS, bật MFA, tạo IAM User/Group, Access Keys\n+ Lab 07: Tạo các loại ngân sách khác nhau\n+ Lab 09: Sử dụng AWS Support Plans và mở case hỗ trợ\n- Nghiên cứu:\n+ AWS Well-Architected Framework 08/09/2025 08/09/2025 2 - Tổng quan mạng: Tầm quan trọng trong kiến trúc AWS Cloud\n+ Amazon VPC: Khái niệm, khác biệt với Private Cloud truyền thống, triển khai Multi-AZ\n+ VPC CIDR: IPv4 (bắt buộc), IPv6 (tùy chọn), giới hạn 5 VPC mỗi Region\n+ Subnet: Public vs Private, các địa chỉ IP dự trữ\n+ Route Table: Route mặc định, route tùy chỉnh, định tuyến Public Subnet\n+ Elastic Network Interface (ENI), Elastic IP Address\n+ VPC Endpoint: Interface Endpoint, Gateway Endpoint (S3, DynamoDB)\n+ Internet Gateway: Yêu cầu để có Internet access (public IP + route)\n+ NAT Gateway: Internet outbound từ private subnet 09/09/2025 09/09/2025 3 Bảo mật VPC:\n+ Security Group (stateful, chỉ có allow rules, gắn vào ENI)\n+ Network ACL (stateless, inbound/outbound rules, gắn vào Subnet)\n+ VPC Flow Logs (theo dõi traffic, phát hiện request bị từ chối, lưu CloudWatch/S3)\n+ Kết nối Multi-VPC:\n+ VPC Peering: Kết nối 1:1, không hỗ trợ transitive routing, CIDR không trùng lặp\n+ Transit Gateway: Mô hình hub-and-spoke, đơn giản hóa định tuyến, cần TGW Attachment mỗi AZ\n+ Kết nối Hybrid:\n+ VPN Site-to-Site: Virtual Private Gateway (AWS) \u0026amp; Customer Gateway (On-premises)\n+ VPN Client-to-Site: chi phí cao, thường dùng giải pháp bên thứ 3\n+ Direct Connect: Kết nối chuyên dụng/hosted, độ trễ ổn định (20–30ms), nhà cung cấp VN (Viettel, FPT)\n+ Elastic Load Balancing (ELB):\n+ Khái niệm: health check, sticky session, access log (lưu S3)\n+ Các loại:\n- Application Load Balancer (Layer 7, HTTP/HTTPS, path-based routing)\n- Network Load Balancer (Layer 4, TCP/TLS, static IP, hiệu năng cao)\n- Classic Load Balancer (Layer 4 \u0026amp; 7, cũ)\n- Gateway Load Balancer (Layer 3, điều hướng traffic appliance) 10/09/2025 10/09/2025 4 - Ôn tập:\n- Hệ thống lại kiến thức từ Ngày 2 \u0026amp; Ngày 3: VPC, Subnet, Route Table, Internet Gateway, NAT Gateway, Security Group, Network ACL, VPC Peering, Transit Gateway, VPN, Direct Connect, Elastic Load Balancing.\n+ Lab:\n- Lab 1:\n+ Tạo VPC, Subnet, Internet Gateway, Route Table, Security Group.\n+ Bật VPC Flow Logs.\n+ Khởi chạy EC2 instance và test kết nối SSH.\n+ Tạo NAT Gateway cho Private Subnet có Internet outbound.\n+ Sử dụng Reachability Analyzer để kiểm tra kết nối mạng.\n+ Quản lý EC2 bằng AWS Systems Manager Session Manager.\n+ Bật CloudWatch Monitoring \u0026amp; Alerting để giám sát EC2.\n- Lab 2:\n+ Lặp lại các bước để củng cố kiến thức và kỹ năng thực hành. 11/09/2025 11/09/2025 5 - Thực hành trên AWS:\n+ Lab 02-02: Session Manager (chuẩn bị, kết nối EC2, quản lý session logs, port forwarding)\n+ Lab 02-03: VPC Peering (chuẩn bị, cập nhật Network ACL, tạo kết nối peering, cấu hình route table, bật cross-peer DNS)\n+ Lab 02-04: Transit Gateway (thiết lập hạ tầng, tạo TGW, TGW attachments, tạo TGW route table, thêm gateway, kiểm tra kết quả)\n+ Lab 02-05: Hybrid DNS (thiết lập, tạo outbound endpoint, tạo Route 53 resolver rule, tạo inbound endpoint) 12/09/2025 12/09/2025 Thành tựu Tuần 1: Nắm vững kiến thức nền tảng về AWS và Điện toán đám mây\nHiểu khái niệm, lợi ích của cloud computing và hành trình chuyển đổi lên cloud. Nắm vững hạ tầng AWS: Region, AZ, Edge Location, Data Center. Thực hành công cụ quản lý AWS\nSử dụng thành thạo AWS Management Console, AWS CLI, AWS SDK. Tạo và quản lý IAM Users/Groups, kích hoạt MFA, cấu hình Access Keys. Quản lý chi phí và hỗ trợ AWS\nTạo và quản lý các loại Budget khác nhau. Tìm hiểu các gói Support Plans và thực hành mở case hỗ trợ. Kiến thức Networking \u0026amp; Security trên AWS\nXây dựng và cấu hình VPC, Subnet, Route Table, Internet Gateway, NAT Gateway. Triển khai Security Group, Network ACL, VPC Flow Logs. So sánh VPC Peering và Transit Gateway, tìm hiểu kết nối Hybrid (VPN, Direct Connect). Quản lý hệ thống trên AWS\nQuản lý EC2 bằng Session Manager thay vì SSH. Thực hành Port Forwarding và quản lý Session Logs. Bật giám sát bằng CloudWatch Monitoring \u0026amp; Alerts. Giải pháp nâng cao\nCấu hình VPC Peering và Transit Gateway để kết nối nhiều VPC. Thiết lập Hybrid DNS với Route 53 Resolver (Inbound/Outbound Endpoints). Thực hành với Elastic Load Balancer (ALB, NLB, CLB, GWLB). 👉 Kết quả: Sau Tuần 1, tôi đã xây dựng nền tảng vững chắc về AWS cơ bản và các khái niệm mạng ở mức trung cấp, đồng thời hoàn thành nhiều bài Lab trực tiếp trên AWS để rèn luyện kỹ năng thực hành.\n"},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/1-worklog/1.2-week2/","title":"Worklog Tuần 2","tags":[],"description":"","content":"Mục tiêu tuần 2: Học và thực hành dịch vụ Compute của AWS (EC2, AMI, EBS, Auto Scaling, ELB). Nắm vững kỹ năng giám sát và sao lưu với CloudWatch và AWS Backup. Tìm hiểu dịch vụ lưu trữ: S3, Storage Gateway, FSx. Thực hành triển khai, mở rộng và host website tĩnh. Các công việc cần triển khai trong tuần này: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 Lý thuyết (Module 03 – Máy ảo Compute trên AWS)\n- Tìm hiểu Amazon EC2: khái niệm, kiến trúc, loại instance, hypervisor Nitro.\n- Các thành phần liên quan: AMI, Backup, Snapshot, Key Pair.\n- Hiểu cách sử dụng Elastic Block Store (EBS) và Instance Store.\n- Tìm hiểu User Data \u0026amp; Meta Data cho tự động hóa EC2.\n- EC2 Auto Scaling và các mô hình giá: On-demand, Reserved, Saving Plans, Spot.\n- Tổng quan về Amazon Lightsail, Amazon EFS, Amazon FSx, AWS Application Migration Service (MGN).\nThực hành (Lab 04 – Amazon EC2)\n- Khởi chạy và làm quen với các tính năng cơ bản của EC2.\n- Cấu hình Linux VPC và Windows VPC với Security Groups.\n- Kết nối tới EC2:\n• Windows qua RDP (3389) dùng Key Pair.\n• Linux qua SSH bằng MobaXterm và PuTTY.\n- Thực hiện các thao tác:\n• Thay đổi loại instance.\n• Tạo snapshot EBS.\n• Tạo AMI tùy chỉnh và khởi chạy instance từ AMI.\n• Truy cập EC2 không cần Key Pair bằng AWS Systems Manager (SSM).\n- Triển khai ứng dụng Node.js CRUD User Management trên cả Amazon Linux và Windows EC2. 14/09/2025 15/09/2025 2 Lab 06: EC2 Auto Scaling và Elastic Load Balancing\n- Triển khai ứng dụng bằng Auto Scaling Group để tăng khả năng mở rộng.\n- Sử dụng Elastic Load Balancer để phân phối tải ứng dụng.\n- Chuẩn bị hạ tầng mạng, khởi chạy EC2 và cấu hình RDS.\n- Tạo AMI và Launch Template cho triển khai đồng nhất.\n- Cấu hình Auto Scaling Group kết hợp Load Balancer đảm bảo HA \u0026amp; tiết kiệm chi phí.\nLab 08: Amazon CloudWatch\n- Khám phá CloudWatch để giám sát môi trường AWS, hybrid và on-premises.\n- Thu thập, phân tích log và metrics hiệu năng.\n- Cấu hình CloudFormation để tạo môi trường CloudWatch.\n- Thực hành Metrics: biểu đồ, phép tính, gán nhãn dữ liệu.\n- Thực hành Logs: thu thập tập trung, chính sách lưu giữ, phát hiện bất thường.\n- Thiết lập Alarms để giám sát và kích hoạt hành động.\n- Xây dựng Dashboards hiển thị real-time tình trạng hệ thống.\nLab 13: AWS Backup\n- Học AWS Backup để tạo kế hoạch sao lưu tự động cho EBS, RDS, DynamoDB, EFS.\n- Triển khai hạ tầng với CloudFormation và tạo S3 bucket lưu trữ.\n- Thiết kế Backup Plan dựa trên RTO và RPO.\n- Cấu hình thông báo qua SNS về trạng thái backup, khôi phục và lỗi. 16/09/2025 16/09/2025 3 Lý thuyết: Dịch vụ lưu trữ AWS (Amazon S3)\n- S3 là dịch vụ lưu trữ đối tượng:\n• Đối tượng bất biến, cập nhật phải re-upload.\n• Phù hợp dữ liệu WORM (Write Once Read Many).\n• Lưu trữ không giới hạn, 1 object ≤ 5TB.\n• Độ bền 99.999999999%, khả dụng 99.99%.\n• Mặc định replicate dữ liệu trên 3 AZ trong 1 Region.\n• Hỗ trợ multipart upload và trigger event.\n- Truy cập S3:\n• Giao thức REST API (PUT, GET).\n• URL object: https://bucket.s3.amazonaws.com/key\n- Access Point: hostname riêng cho từng app/user.\n- Storage Class: Standard, Standard-IA, Intelligent-Tiering, One Zone-IA, Glacier/Deep Archive.\n- Quản lý vòng đời object bằng Lifecycle Policy.\n- S3 Static Website \u0026amp; CORS: host web tĩnh, hỗ trợ cross-origin.\n- Access Control: ACL và Bucket Policy.\n- Endpoint \u0026amp; Versioning: truy cập nội bộ VPC, versioning chống xóa/ghi đè.\n- Object Key \u0026amp; Performance: partitioning, random prefix để tối ưu.\n- Glacier: lưu trữ chi phí thấp, truy xuất Expedited/Standard/Bulk, rẻ hơn S3 Standard 20 lần. 17/09/2025 17/09/2025 4 Lab 24: AWS Storage Gateway (File Gateway)\n- Chuẩn bị hạ tầng:\n• Tạo S3 Bucket backend.\n• Khởi chạy EC2 làm Storage Gateway.\n- Cấu hình Storage Gateway:\n• Tạo Gateway và File Share.\n• Mount File Share vào máy local.\n- Ghi chú:\n• Thực tế triển khai Appliance on-premises.\n• Hỗ trợ VMware, Hyper-V, KVM, Appliance vật lý. 18/09/2025 18/09/2025 5 Lab 25: Amazon FSx for Windows File Server\n- Tìm hiểu kiến trúc FSx:\n• File Servers (Windows File Server qua SMB).\n• Storage (lưu trên Amazon S3).\n• Networking (ENIs trong VPC).\n• Data Replication (tự động nhân bản đa AZ).\n• Quản lý và giám sát bởi AWS.\n- Triển khai FSx để cung cấp dịch vụ lưu trữ file dùng chung.\n- Học tích hợp với Windows Server, quản lý và truy cập dữ liệu.\nLab 57: Amazon S3 \u0026amp; Static Website Hosting\n- Ôn lại khái niệm S3: Bucket, Object (≤ 5TB).\n- Chuẩn bị hạ tầng:\n• Tạo bucket, cấu hình ACL và Public Access.\n• Upload và tổ chức object.\n- Cấu hình Static Website Hosting:\n• Bật hosting, khai báo index/error document.\n• Kiểm thử endpoint DNS.\n- Quản lý truy cập \u0026amp; bảo mật:\n• Điều chỉnh Block Public Access.\n• Gán ACL cho object.\n- Tăng tốc website bằng CloudFront:\n• Tạo Distribution liên kết bucket.\n• Cấu hình OAI, test endpoint CloudFront.\n- Tính năng bổ sung:\n• Bật Versioning phục hồi dữ liệu.\n• Thực hành di chuyển object giữa folder/bucket. 19/09/2025 19/09/2025 Kết quả đạt được tuần 2: Tính toán \u0026amp; Triển khai\nHiểu rõ kiến thức về Amazon EC2, kiến trúc và các thành phần liên quan (AMI, Snapshot, Key Pair, EBS). Triển khai và quản lý thành công EC2 cho cả Linux và Windows. Thực hành triển khai ứng dụng thực tế Node.js CRUD trên EC2. Nắm được các kỹ thuật tự động hóa với User Data, Meta Data, AWS Systems Manager. Khả năng mở rộng \u0026amp; Tính sẵn sàng cao\nTriển khai EC2 Auto Scaling Group để tự động điều chỉnh năng lực theo nhu cầu. Cấu hình Elastic Load Balancer (ELB) để phân phối lưu lượng. Tích hợp Auto Scaling với Load Balancer nhằm đảm bảo high availability và tối ưu chi phí. Giám sát \u0026amp; Quan sát hệ thống\nSử dụng Amazon CloudWatch để giám sát hạ tầng và ứng dụng. Tạo metrics, dashboards, alarms để theo dõi tình trạng hệ thống theo thời gian thực. Quản lý log tập trung với CloudWatch Logs, thiết lập chính sách lưu trữ và phát hiện bất thường. Thực hành thiết lập giám sát tự động qua CloudFormation. Bảo vệ \u0026amp; Sao lưu dữ liệu\nThiết kế AWS Backup Plans cho nhiều dịch vụ (EBS, RDS, DynamoDB, EFS). Áp dụng các mục tiêu RTO/RPO trong chiến lược khôi phục dữ liệu. Cấu hình SNS notifications để nhận thông báo trạng thái sao lưu và phục hồi. Lưu trữ \u0026amp; Quản lý dữ liệu\nHiểu rõ Amazon S3 là dịch vụ lưu trữ đối tượng với lifecycle policies và storage classes. Thực hành các tính năng: versioning, ACL, Bucket Policy, CORS. Cấu hình S3 Static Website Hosting và kiểm tra truy cập công khai. Tích hợp với CloudFront để tăng tốc độ phân phối nội dung và bảo mật bằng OAI. Tìm hiểu Amazon FSx for Windows File Server: kiến trúc, tích hợp Windows, và dịch vụ lưu trữ file được quản lý hoàn toàn. "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/1-worklog/1.3-week3/","title":"Worklog Tuần 3","tags":[],"description":"","content":"Mục tiêu tuần 3: Hiểu triết lý bảo mật AWS (“Security is Job Zero”) và Mô hình Trách nhiệm chia sẻ. Thành thạo các dịch vụ Quản lý danh tính \u0026amp; truy cập: IAM Users, Groups, Roles, Policies, Permission Boundaries, Organizations, Identity Center, Cognito. Ứng dụng AWS KMS để mã hóa dữ liệu, tích hợp CloudTrail và phân tích logs bằng Athena. Nắm vững các dịch vụ cơ sở dữ liệu AWS: RDS, Aurora, Redshift, ElastiCache và các khái niệm cơ bản SQL, NoSQL, OLTP, OLAP. Triển khai Amazon RDS với Multi-AZ, subnet groups, backup/restore để đảm bảo tính sẵn sàng và khả năng phục hồi. Các công việc cần triển khai trong tuần này: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 Module 05: Dịch vụ bảo mật trên AWS\n- Tìm hiểu triết lý bảo mật của AWS\n- Hiểu nguyên tắc “Security is Job Zero” — bảo mật là ưu tiên hàng đầu trong các dịch vụ AWS.\n- Mô hình chia sẻ trách nhiệm\n- AWS bảo mật hạ tầng, lưu trữ, tính toán và các dịch vụ được quản lý.\n- Khách hàng chịu trách nhiệm về cấu hình, mã hóa, xác thực, hệ điều hành, mạng và bảo mật cấp dữ liệu.\n- Nhận ra sự khác biệt về mức độ trách nhiệm tùy theo loại dịch vụ (hạ tầng, quản lý, toàn phần).\n- Quản lý danh tính và truy cập (IAM)\n- Tìm hiểu về rủi ro tài khoản Root và các thực hành tốt (hạn chế sử dụng, MFA, tách lưu trữ thông tin truy cập).\n- Hiểu các khái niệm IAM: Người dùng, Nhóm, Vai trò, Chính sách.\n- Phân biệt chính sách dựa trên danh tính và tài nguyên.\n- Khám phá IAM Role với thông tin truy cập tạm thời qua AWS STS (assume-role).\n- Amazon Cognito\n- User Pool: xác thực và đăng nhập cho ứng dụng.\n- Identity Pool: cung cấp quyền truy cập tài nguyên AWS sau khi xác thực.\n- Tích hợp xác thực với các nhà cung cấp xã hội (Google, Facebook, v.v.).\n- AWS Organizations\n- Quản lý nhiều tài khoản tập trung.\n- Tạo Đơn vị Tổ chức (OU), hợp nhất hóa đơn và Chính sách Kiểm soát Dịch vụ (SCPs).\n- AWS Identity Center\n- Quản lý truy cập tập trung trên các tài khoản AWS và ứng dụng bên ngoài.\n- Các bước: Nhóm người dùng → Tạo bộ quyền → Gán quyền truy cập.\n- AWS Key Management Service (KMS)\n- Dịch vụ tạo và quản lý khóa mã hóa.\n- Khóa do khách hàng quản lý (CMK) dùng để tạo khóa dữ liệu mã hóa/giải mã bên ngoài KMS.\n- AWS Security Hub\n- Dịch vụ kiểm tra bảo mật liên tục tuân thủ thực hành tốt và tiêu chuẩn AWS.\n- Cung cấp điểm số bảo mật và xác định tài nguyên/tài khoản cấu hình sai. 22/09/2025 22/09/2025 2 Lab 02: Kiến thức cơ bản về AWS IAM\n- Tìm hiểu nền tảng IAM: Người dùng, Nhóm, Vai trò, Chính sách.\n- Khám phá các thực hành tốt với nguyên tắc quyền tối thiểu.\n- Hiểu các phương thức xác thực IAM: mật khẩu, khóa truy cập, thông tin truy cập tạm thời qua AWS STS.\n- Thực hành tạo và quản lý Người dùng và Nhóm IAM.\nLab 44: Vai trò \u0026amp; Điều kiện IAM\n- Ôn lại luồng yêu cầu IAM: chủ thể, hành động, tài nguyên, dữ liệu môi trường.\n- Thực hành quá trình xác thực và nhận vai trò bằng sts:AssumeRole.\n- Tạo Nhóm IAM với các chính sách: AmazonEC2FullAccess, AmazonRDSFullAccess, DatabaseAdministrator.\n- Tạo nhiều Người dùng IAM: EC2-admin-user, RDS-admin-user, Group-user, và No-permission-user.\n- Cấu hình Vai trò IAM với Điều kiện:\n- Giới hạn quyền truy cập vai trò theo địa chỉ IP.\n- Áp dụng điều kiện thời gian tăng cường bảo mật.\nLab 48: Vai trò IAM cho ứng dụng\n- So sánh sử dụng Access Keys và IAM Role trên EC2:\n- Nhấn mạnh rủi ro bảo mật khi mã hóa cứng Access Keys trong ứng dụng.\n- Chỉ ra cách IAM Role loại bỏ rủi ro bằng cách tự động cấp quyền tạm thời.\n- Triển khai EC2 instance với IAM Role, cho phép truy cập an toàn đến S3 mà không cần quản lý Access Keys. 23/09/2025 23/09/2025 3 Lab 18: Liên kết danh tính với Amazon Cognito\n- Tìm hiểu về liên kết danh tính với Amazon Cognito.\n- Cấu hình User Pool và Identity Pool hỗ trợ xác thực từ nhiều nguồn (Google, Facebook, SAML).\n- Thực hành tạo ứng dụng khách, tích hợp và xác thực người dùng.\nLab 27: Vai trò IAM\n- Hiểu khái niệm Vai trò IAM và sự khác biệt với Người dùng IAM.\n- Gán Vai trò cho EC2 để truy cập tài nguyên AWS mà không cần mã hóa thông tin truy cập.\n- Thực hiện nguyên tắc quyền tối thiểu với Vai trò IAM.\nLab 28: Nhóm và Chính sách IAM\n- Tạo Nhóm IAM và thêm nhiều Người dùng vào nhóm.\n- Gắn chính sách cho Nhóm để quản lý quyền tập trung.\n- Thực hành viết và áp dụng chính sách IAM bằng JSON.\nLab 30: Giới hạn quyền IAM\n- Tìm hiểu về Giới hạn quyền để giới hạn quyền tối đa cho Người dùng/Nhóm.\n- Tạo chính sách giới hạn quyền truy cập EC2 đầy đủ cho một vùng duy nhất.\n- Gán cả chính sách dựa trên danh tính và giới hạn quyền cho Người dùng, quan sát hiệu quả quyền kết hợp.\nLab 33: Mã hóa dữ liệu lưu trữ với AWS KMS\n- Tìm hiểu về AWS KMS: sử dụng khóa đối xứng \u0026amp; bất đối xứng.\n- Tạo CMK, cấu hình chính sách khóa, tích hợp CloudTrail để giám sát.\n- Thực hành mã hóa dữ liệu trong S3 bằng KMS.\n- Sử dụng CloudTrail để ghi lại mọi hoạt động liên quan đến khóa.\n- Truy vấn log với Amazon Athena để phân tích quyền truy cập và kiểm tra tuân thủ. 24/09/2025 24/09/2025 4 Lý thuyết: Dịch vụ cơ sở dữ liệu AWS\n- Ôn lại các khái niệm cơ bản về cơ sở dữ liệu:\n- Khóa chính, khóa ngoại, đánh chỉ mục, phân vùng, kế hoạch thực thi, log, bộ đệm.\n- Phân biệt RDBMS (SQL) và cơ sở dữ liệu NoSQL.\n- Hiểu sự khác biệt OLTP (xử lý giao dịch) và OLAP (xử lý phân tích).\n- Amazon RDS (Dịch vụ cơ sở dữ liệu quan hệ):\n- Tìm hiểu các tính năng quản lý: tự động sao lưu, bản sao đọc, chuyển đổi dự phòng Multi-AZ, mã hóa, tự động mở rộng.\n- Hiểu rằng RDS dựa trên EC2 nhưng do AWS quản lý toàn bộ.\n- Amazon Aurora:\n- RDBMS hiệu năng cao, tối ưu cho AWS, tương thích MySQL và PostgreSQL.\n- Tính năng: Backtrack, Cloning, Global Database, kiến trúc Multi-Master.\n- Amazon Redshift:\n- Giải pháp kho dữ liệu tối ưu cho OLAP và phân tích dữ liệu lớn.\n- Sử dụng lưu trữ dạng cột, kiến trúc MPP, node trưởng/nút tính toán.\n- Tối ưu hóa chi phí: Transient Cluster, Redshift Spectrum (truy vấn dữ liệu trên S3).\n- Amazon ElastiCache:\n- Dịch vụ bộ nhớ đệm quản lý (Redis, Memcached).\n- Tăng hiệu năng ứng dụng bằng cách giảm tải truy vấn thường xuyên từ cơ sở dữ liệu.\n- Yêu cầu logic bộ đệm phía ứng dụng. 25/09/2025 25/09/2025 5 Lab 05: Dịch vụ cơ sở dữ liệu quan hệ Amazon (RDS)\n- Tìm hiểu Amazon RDS là dịch vụ cơ sở dữ liệu quan hệ quản lý:\n- Hỗ trợ OLTP, dữ liệu có cấu trúc và quan hệ.\n- Lợi ích: tự động sao lưu, cập nhật bản vá, mở rộng, sao chép, độ sẵn sàng cao.\n- Tìm hiểu các hệ quản trị cơ sở dữ liệu hỗ trợ: Aurora, MySQL, MariaDB, Oracle, SQL Server, PostgreSQL.\n- Chuẩn bị hạ tầng:\n- Tạo VPC với subnet cho triển khai Multi-AZ.\n- Cấu hình Security Group EC2 cho máy chủ ứng dụng.\n- Cấu hình Security Group RDS (tách biệt với EC2 để tăng bảo mật).\n- Tạo nhóm Subnet DB với subnet riêng cho RDS.\n- Triển khai EC2 instance để kết nối với RDS.\n- Tạo RDS Database Instance với cả Easy Create và tùy chọn nâng cao.\n- Triển khai ứng dụng sử dụng RDS làm cơ sở dữ liệu backend.\n- Thực hành sao lưu và phục hồi:\n- Sao lưu tự động và snapshot thủ công.\n- Khôi phục dữ liệu theo điểm thời gian để bảo vệ dữ liệu. 26/09/2025 26/09/2025 Kết quả đạt được tuần 3: Dịch vụ bảo mật:\nÁp dụng thực tế Mô hình Trách nhiệm chia sẻ. Quản lý IAM với Users, Groups, Roles, Policies, Conditions và Permission Boundaries. Tích hợp IAM Role với EC2 để loại bỏ rủi ro khi dùng Access Keys cố định. Thực hành Liên kết danh tính (Identity Federation) với Cognito (Google, Facebook, SAML). Quản lý tập trung nhiều tài khoản bằng AWS Organizations và Identity Center. Mã hóa \u0026amp; Giám sát:\nTạo và quản lý KMS CMK cho việc mã hóa. Mã hóa dữ liệu trong S3 bằng KMS. Ghi lại hoạt động khóa với CloudTrail và phân tích bằng Athena. Dịch vụ cơ sở dữ liệu:\nHiểu sự khác biệt giữa RDBMS và NoSQL, OLTP và OLAP. Triển khai Amazon RDS với Multi-AZ, subnet groups, backup tự động, snapshots, và phục hồi theo thời gian (point-in-time recovery). Nghiên cứu Aurora (Backtrack, Global DB, Cloning), Redshift (MPP, Spectrum), và ElastiCache (Redis, Memcached). Thực hành:\nHoàn thành nhiều bài lab: IAM Basics, IAM Roles \u0026amp; Conditions, IAM Roles for Applications, Cognito Federation, IAM Permission Boundaries, KMS Encryption, RDS Deployment. Xây dựng được môi trường RDS an toàn với khả năng backup và phục hồi dữ liệu. "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/1-worklog/1.4-week4/","title":"Worklog Tuần 4","tags":[],"description":"","content":"Mục tiêu tuần 4: Mục tiêu của tuần này là củng cố hiểu biết về các dịch vụ dữ liệu và AI của AWS — từ xây dựng kiến trúc DataLake có khả năng mở rộng đến làm việc với cơ sở dữ liệu NoSQL serverless (DynamoDB) và khám phá quản lý vòng đời phát triển AI. Ngoài ra, tuần này còn nhằm nâng cao kỹ năng dịch thuật kỹ thuật và kỹ năng giao tiếp thông qua các lab thực hành, dịch blog và tham gia các sự kiện của AWS. Các nhiệm vụ thực hiện trong tuần này: Day Task Start Date Completion Date Reference Material 1 Lab 35: DataLake trên AWS\n- Giới thiệu về DataLake:\n- Hiểu DataLake như một kho tập trung lưu trữ dữ liệu thô và đã xử lý để phục vụ phân tích và khai thác thông tin.\n- Nắm các đặc tính chính: thu thập tất cả dữ liệu, truy cập đa người dùng, và mô hình truy cập linh hoạt (batch, interactive, real-time, search).\n- Hiểu cách các dịch vụ AWS (Glue, Athena, QuickSight) tích hợp để xây dựng một giải pháp DataLake hoàn chỉnh.\n- Amazon Glue (dịch vụ ETL):\n- Tìm hiểu về Glue Crawlers để phát hiện schema tự động và tạo Glue Data Catalog.\n- Hiểu cách Glue ETL job sinh script Python tùy chỉnh cho chuyển đổi và nạp dữ liệu.\n- Thực hành tạo Crawler để quét dữ liệu trên S3 và xây dựng Data Catalog cho truy vấn.\n- Amazon Athena (dịch vụ truy vấn tương tác):\n- Athena cho phép truy vấn dữ liệu trên S3 bằng SQL tiêu chuẩn mà không cần pipeline ETL phức tạp.\n- Cấu hình Athena để truy vấn dataset trên S3 và hiểu mô hình chi phí (trả theo truy vấn).\n- Khám phá các định dạng dữ liệu Athena hỗ trợ (CSV, JSON, ORC, Avro, Parquet).\n- Amazon QuickSight (dịch vụ trực quan hóa dữ liệu):\n- Tìm hiểu cách QuickSight kết nối với nguồn dữ liệu và xây dựng dataset để trực quan hóa.\n- Tạo biểu đồ, phân tích và dashboard để thể hiện các chỉ số kinh doanh chính.\n- Hiểu cấu trúc QuickSight: Datasource → Dataset → Analysis → Visual → Dashboard.\n- Các bước triển khai:\n- Tạo IAM Role với quyền S3FullAccess và AWSGlueServiceRole.\n- Chuẩn bị cấu trúc bucket S3 (/data, /ref_data) và tải file lên.\n- Thiết lập Kinesis Delivery Stream để liên tục đưa dữ liệu vào S3.\n- Triển khai stack CloudFormation để tự động hóa hạ tầng.\n- Chạy AWS Glue Crawler để catalog dữ liệu S3 và xác thực bằng Amazon Athena.\n- Khởi chạy SageMaker Notebook qua Glue Studio để thực hiện workflow chuyển đổi dữ liệu bổ sung. 29/09/2025 29/09/2025 2 Lab40:\n- Ôn lại AWS Glue như một dịch vụ ETL quản lý (Extract – Transform – Load) hỗ trợ chuẩn bị dữ liệu cho phân tích. - Hiểu workflow: 1. Tải dữ liệu thô lên Amazon S3. 2. Dùng Glue Crawler để phát hiện schema và tạo database trong Glue Data Catalog. 3. Chuyển đổi dữ liệu sang định dạng tối ưu như Parquet. 4. Truy vấn dữ liệu đã chuyển đổi bằng Amazon Athena. - Cấu hình AWS Glue và Athena cho cập nhật schema tự động và lên lịch chạy crawler. - Thực thi các truy vấn SQL trong Athena để phân tích: - Top 10 tài khoản và dịch vụ AWS có chi phí cao nhất. - Phân tích chi tiết chi phí theo dịch vụ và tag (ví dụ: cost_center). - Phân tách các kỳ tính phí và loại sử dụng. - Học cách tối thiểu hóa chi phí truy vấn Athena bằng: - Sử dụng file Parquet nén. - Hạn chế kết quả truy vấn bằng LIMIT. - Cấu trúc dữ liệu hiệu quả cho truy vấn phân vùng. - Khám phá phân bổ chi phí và tagging cho theo dõi chi phí cấp doanh nghiệp. 30/09/2025 30/09/2025 3 Lab 60: Amazon DynamoDB\n- Tổng quan:\n- Nghiên cứu Amazon DynamoDB — dịch vụ cơ sở dữ liệu NoSQL được quản lý hoàn toàn, cung cấp hiệu năng nhanh và khả năng mở rộng mượt mà.\n- Hiểu cách DynamoDB tự động quản lý hạ tầng, scale và sao chép dữ liệu giữa các Availability Zone.\n- Khám phá các tính năng như chế độ dung lượng on-demand và provisioned, mã hoá dữ liệu khi lưu trữ, point-in-time recovery, và tự động xoá item khi hết hạn.\n- Thành phần chính:\n- Table: Tập hợp logic của các item (tương tự bảng trong DB quan hệ).\n- Item: Bản ghi riêng lẻ trong table (tương tự hàng).\n- Attribute: Thuộc tính trong item (tương tự cột).\n- Khóa chính:\n- Tìm hiểu về Partition Key và Composite Primary Key (Partition + Sort Key) để xác định duy nhất item.\n- Hiểu cách composite key cải thiện tính linh hoạt khi truy vấn.\n- Secondary Indexes:\n- Thực hành sử dụng Global Secondary Index (GSI) và Local Secondary Index (LSI) để tối ưu hiệu năng truy vấn.\n- Nhận biết DynamoDB hỗ trợ tới 20 GSI và 5 LSI cho mỗi bảng.\n- Read Consistency:\n- So sánh Eventually Consistent Reads (nhanh hơn, có thể đọc dữ liệu cũ) và Strongly Consistent Reads (luôn đọc dữ liệu mới nhất, chậm hơn và tốn kém hơn).\n- Chế độ dung lượng đọc/ghi:\n- On-Demand Mode: Phù hợp cho workload không dự báo trước, tự động scale theo nhu cầu.\n- Provisioned Mode: Thích hợp cho workload có thể dự đoán với lưu lượng ổn định hoặc có kế hoạch.\n- Triển khai:\n- Khám phá AWS Management Console và AWS CloudShell để thiết lập và quản lý DynamoDB.\n- Học cách dùng AWS SDK (Boto3) để tương tác chương trình với bảng DynamoDB. 01/10/2025 01/10/2025 4 Hoạt động: Dịch các bài blog kỹ thuật AWS\nNội dung đã dịch:\n- “Accelerating Generative AI Development with Fully Managed MLflow 3.0 on Amazon SageMaker AI” – Tìm hiểu cách AWS tích hợp MLflow để quản lý vòng đời mô hình Generative AI.\n- “AI-Enhanced Subsurface Infrastructure Mapping on AWS” – Hiểu cách deep learning và HPC được áp dụng để phát hiện cơ sở hạ tầng ngầm.\n- “Unlocking the Full Potential of Amazon Connect” – Nắm bắt các best practice khi triển khai trung tâm liên lạc được hỗ trợ AI trên AWS.\nKỹ năng đạt được:\n- Cải thiện kỹ năng dịch thuật kỹ thuật (AI, HPC, Cloud Computing).\n- Hiểu sâu hơn về các dịch vụ AWS: SageMaker, Batch, ParallelCluster và Amazon Connect.\n- Mở rộng vốn từ kỹ thuật tiếng Anh liên quan đến cloud và AI. 2/10/2025 2/10/2025 5 Hoạt động: Tham dự sự kiện AWS về AI Development Lifecycle và giới thiệu Kiro\nChi tiết:\n- Tham gia sự kiện do AWS tổ chức tập trung vào Vòng đời phát triển AI, bao quát các giai đoạn chính từ chuẩn bị dữ liệu, huấn luyện và đánh giá mô hình đến triển khai và giám sát liên tục.\n- Tìm hiểu cách các dịch vụ AWS như Amazon SageMaker, Bedrock và CodeWhisperer hỗ trợ quy trình phát triển và tối ưu mô hình AI.\n- Tham dự phần giới thiệu chi tiết về Kiro – một giải pháp AWS mới nhằm đơn giản hóa và hợp nhất quản lý workflow AI giữa các đội.\n- Hiểu cách Kiro tích hợp với các công cụ AWS khác để quản lý dataset, phiên bản mô hình và tracking experiment hiệu quả hơn, nâng cao hợp tác và quản trị.\n- Khám phá các case study thực tế cho thấy tổ chức tận dụng hạ tầng AWS để tăng tốc tự động hoá nhờ AI, giảm thời gian huấn luyện và cải thiện độ tin cậy mô hình trong môi trường production.\nKỹ năng đạt được:\n- Nâng cao hiểu biết về vòng đời phát triển AI trong hệ sinh thái AWS.\n- Học các ứng dụng thực tiễn của quản lý vòng đời mô hình bằng dịch vụ AWS và Kiro.\n- Tăng kiến thức về observability mô hình, tracking experiment và best practice triển khai.\n- Củng cố vốn từ kỹ thuật và kỹ năng giao tiếp liên quan đến AI, ML và Cloud Computing. 3/10/2025 3/10/2025 Thành tựu Tuần 4: Xây dựng pipeline DataLake trên AWS tích hợp Glue, Athena và QuickSight, có kinh nghiệm thực hành trong ingest, chuyển đổi và trực quan hóa dữ liệu. Cấu hình AWS Glue Crawlers và truy vấn Athena cho phân tích chi phí và tự động hóa schema, áp dụng các chiến lược tối ưu chi phí (ví dụ: Parquet, partitioning, giới hạn truy vấn). Nắm vững các kiến thức cơ bản về DynamoDB, bao gồm khóa chính/khóa hợp nhất, index (GSI, LSI), mô hình nhất quán đọc và chế độ dung lượng. Nâng cao kỹ năng dịch và hiểu nội dung kỹ thuật bằng cách dịch các bài blog kỹ thuật về AI, MLflow và HPC, nắm vững các dịch vụ như SageMaker, Batch, ParallelCluster và Connect. Tham gia một sự kiện AWS tập trung vào AI Development Lifecycle và Kiro, thu nhận kiến thức về quản lý phiên bản mô hình, theo dõi thử nghiệm và best practice triển khai. Cải thiện vốn từ kỹ thuật và hiểu biết thực tiễn về thiết kế kiến trúc dữ liệu, quản trị mô hình AI và cloud computing trong hệ sinh thái AWS. "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/1-worklog/1.5-week5/","title":"Worklog Tuần 5","tags":[],"description":"","content":"Mục tiêu tuần 5: Củng cố kiến thức thực hành và kỹ năng triển khai với các dịch vụ AWS Data Analytics bao gồm Glue, Athena, QuickSight, S3 DataLake, và thu thập dữ liệu streaming bằng Kinesis. Hiểu sâu về kiến trúc, mô hình hiệu năng, chỉ mục và các chiến lược lưu trữ NoSQL có độ khả dụng cao của DynamoDB. Nâng cao kỹ năng giao tiếp tiếng Anh chuyên ngành thông qua việc dịch các bài blog kỹ thuật của AWS về AI, HPC và giải pháp doanh nghiệp trên đám mây. Cập nhật các đổi mới mới nhất của AWS bằng cách tham gia một sự kiện ngành tập trung vào vòng đời phát triển AI và quản lý workflow với Kiro. Cải thiện khả năng thiết kế, truy vấn, biến đổi và trực quan hóa dữ liệu hiệu quả trên hệ sinh thái phân tích dữ liệu của AWS. Công việc thực hiện trong tuần này: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 Lab 35: DataLake trên AWS\n- Giới thiệu về DataLake:\n- Hiểu DataLake là kho tập trung lưu trữ dữ liệu thô và đã xử lý cho mục đích phân tích và khai thác thông tin.\n- Nắm các đặc điểm chính: thu thập mọi thứ, truy cập đa người dùng, và các mô hình truy cập linh hoạt (batch, tương tác, real-time, tìm kiếm).\n- Học cách các dịch vụ AWS (Glue, Athena, QuickSight) tích hợp để xây dựng giải pháp DataLake hoàn chỉnh.\n- Amazon Glue (dịch vụ ETL):\n- Tìm hiểu về Glue Crawlers để tự động phát hiện schema và tạo Glue Data Catalog.\n- Hiểu cách Glue ETL job sinh ra mã Python có thể tùy chỉnh để biến đổi và nạp dữ liệu.\n- Thực hành tạo Crawler để quét dữ liệu trên S3 và xây dựng Data Catalog để truy vấn.\n- Amazon Athena (dịch vụ truy vấn tương tác):\n- Học rằng Athena cho phép truy vấn dữ liệu trên S3 bằng SQL tiêu chuẩn mà không cần pipeline ETL phức tạp.\n- Cấu hình Athena để truy vấn bộ dữ liệu S3 và hiểu mô hình chi phí (trả cho mỗi truy vấn).\n- Khám phá các định dạng dữ liệu được Athena hỗ trợ (CSV, JSON, ORC, Avro, Parquet).\n- Amazon QuickSight (dịch vụ trực quan hóa dữ liệu):\n- Nghiên cứu cách QuickSight kết nối nguồn dữ liệu và xây dựng dataset để trực quan hóa.\n- Tạo biểu đồ, phân tích và dashboard để thể hiện các chỉ số kinh doanh chính.\n- Hiểu cấu trúc QuickSight: Datasource → Dataset → Analysis → Visual → Dashboard.\n- Các bước triển khai:\n- Tạo IAM Role với quyền S3FullAccess và AWSGlueServiceRole.\n- Chuẩn bị cấu trúc bucket S3 (/data, /ref_data) và upload file dữ liệu.\n- Thiết lập Kinesis Delivery Stream để liên tục chuyển dữ liệu vào S3.\n- Triển khai CloudFormation stack để tự động hóa hạ tầng.\n- Chạy AWS Glue Crawler để catalog dữ liệu S3 và kiểm tra bằng Amazon Athena.\n- Khởi chạy SageMaker Notebook qua Glue Studio cho các workflow biến đổi dữ liệu bổ sung. 29/09/2025 29/09/2025 2 Lab40:\n- Ôn lại AWS Glue như một dịch vụ ETL được quản lý hỗ trợ chuẩn bị dữ liệu cho phân tích. - Hiểu luồng công việc: 1. Upload dữ liệu thô lên Amazon S3. 2. Dùng Glue Crawler để phát hiện schema và tạo database trong Glue Data Catalog. 3. Biến đổi dữ liệu sang định dạng tối ưu như Parquet. 4. Truy vấn dữ liệu đã biến đổi bằng Amazon Athena. - Cấu hình AWS Glue và Athena để cập nhật schema tự động và lịch chạy crawler. - Thực thi các truy vấn SQL trong Athena để phân tích: - Top 10 tài khoản và dịch vụ AWS có chi phí lớn nhất. - Phân tích chi tiết chi phí theo dịch vụ và tag (ví dụ: cost_center). - Các kỳ thanh toán và loại sử dụng khác nhau. - Học cách giảm chi phí truy vấn Athena bằng: - Sử dụng file Parquet nén. - Hạn chế kết quả truy vấn bằng LIMIT. - Cấu trúc dữ liệu hiệu quả để truy vấn theo partition. - Khám phá phân bổ chi phí và tagging cho theo dõi chi phí ở cấp doanh nghiệp. 30/09/2025 30/09/2025 3 Lab 60: Amazon DynamoDB\n- Tổng quan:\n- Nghiên cứu Amazon DynamoDB — dịch vụ cơ sở dữ liệu NoSQL được quản lý hoàn toàn, cung cấp hiệu năng nhanh và khả năng mở rộng mượt mà.\n- Hiểu DynamoDB tự động quản lý hạ tầng, scaling và nhân bản dữ liệu trên nhiều Availability Zone.\n- Khám phá các tính năng như chế độ on-demand và provisioned capacity, mã hóa khi nghỉ, phục hồi theo thời gian (PITR), và tự động xóa item theo thời hạn (TTL).\n- Thành phần chính:\n- Table: Tập hợp logic của các item (tương tự bảng trong cơ sở dữ liệu quan hệ).\n- Item: Bản ghi riêng lẻ trong table (tương tự hàng).\n- Attribute: Thuộc tính trong item (tương tự cột).\n- Khóa chính:\n- Học về Partition Key và Composite Primary Key (Partition + Sort Key) để định danh duy nhất item.\n- Hiểu cách khóa composite tăng tính linh hoạt khi truy vấn.\n- Chỉ mục phụ:\n- Thực hành sử dụng Global Secondary Index (GSI) và Local Secondary Index (LSI) để tối ưu hiệu năng truy vấn.\n- Nhận biết DynamoDB hỗ trợ lên tới 20 GSI và 5 LSI cho mỗi bảng.\n- Tính nhất quán đọc:\n- So sánh Eventually Consistent Reads (nhanh hơn, có thể trả dữ liệu cũ) vs Strongly Consistent Reads (luôn mới nhất, tốn kém và chậm hơn).\n- Chế độ Read/Write Capacity:\n- On-Demand Mode: Phù hợp với workload không thể dự đoán, tự động scale theo nhu cầu.\n- Provisioned Mode: Phù hợp workload có thể dự đoán với lưu lượng ổn định hoặc có dự báo.\n- Triển khai:\n- Khám phá AWS Management Console và AWS CloudShell để cấu hình và quản lý DynamoDB.\n- Học cách dùng AWS SDK (Boto3) để tương tác chương trình với các bảng DynamoDB. 01/10/2025 01/10/2025 4 Hoạt động: Dịch các bài blog kỹ thuật của AWS\nBài dịch:\n- “Accelerating Generative AI Development with Fully Managed MLflow 3.0 on Amazon SageMaker AI” – Hiểu cách AWS tích hợp MLflow để quản lý vòng đời mô hình Generative AI.\n- “AI-Enhanced Subsurface Infrastructure Mapping on AWS” – Nắm cách deep learning và HPC được áp dụng để phát hiện cơ sở hạ tầng ngầm.\n- “Unlocking the Full Potential of Amazon Connect” – Hiểu các best practice khi triển khai contact center được tăng cường AI trên AWS.\nKỹ năng đạt được:\n- Cải thiện kỹ năng dịch kỹ thuật (AI, HPC, Điện toán đám mây).\n- Hiểu sâu hơn về các dịch vụ AWS: SageMaker, Batch, ParallelCluster, và Amazon Connect.\n- Mở rộng vốn từ chuyên môn và diễn đạt tiếng Anh trong lĩnh vực đám mây và AI. 2/10/2025 2/10/2025 5 Hoạt động: Tham dự sự kiện AWS về Vòng đời phát triển AI và Giới thiệu Kiro\nChi tiết:\n- Tham gia một sự kiện do AWS tổ chức tập trung vào vòng đời phát triển AI, bao gồm các giai đoạn từ chuẩn bị dữ liệu, huấn luyện mô hình, đánh giá đến triển khai và giám sát liên tục.\n- Học về cách các dịch vụ AWS như Amazon SageMaker, Bedrock, và CodeWhisperer hỗ trợ phát triển end-to-end và tối ưu hóa mô hình AI.\n- Tham dự phần trình bày chi tiết về Kiro — giải pháp mới của AWS giúp đơn giản hóa và hợp nhất quản lý workflow AI giữa các nhóm.\n- Hiểu cách Kiro tích hợp với các công cụ AWS khác để quản lý dataset, phiên bản mô hình và theo dõi thử nghiệm hiệu quả hơn, tăng cường hợp tác và quản trị.\n- Khám phá các case study thực tế về cách tổ chức tận dụng hạ tầng AWS để tăng tốc tự động hóa dựa trên AI, giảm thời gian huấn luyện và cải thiện độ tin cậy của mô hình trong môi trường sản xuất.\nKỹ năng đạt được:\n- Hiểu sâu hơn về vòng đời phát triển AI trong hệ sinh thái AWS.\n- Học cách quản lý lifecycle mô hình thực tế bằng các dịch vụ và Kiro.\n- Nâng cao kiến thức về observability mô hình, theo dõi thử nghiệm và best practice triển khai.\n- Củng cố vốn từ và kỹ năng giao tiếp kỹ thuật về AI, ML và Điện toán đám mây. 3/10/2025 3/10/2025 Thành tựu tuần 5: Hoàn thành thành công Lab 35: DataLake trên AWS, tích hợp workflow Glue ETL, truy vấn Athena SQL và dashboard QuickSight cho pipeline phân tích dữ liệu hoàn chỉnh. Hoàn thành Lab 40 với phân tích chi phí nâng cao sử dụng Glue Data Catalog và Athena, đồng thời tối ưu chi phí truy vấn bằng định dạng Parquet và partitioning. Xây dựng kiến thức thực hành vững chắc về Amazon DynamoDB bao gồm thiết kế khóa chính, chế độ capacity, chỉ mục GSI và LSI, cấu hình nhất quán đọc và tự động hóa bằng SDK. Dịch nhiều bài viết kỹ thuật của AWS, cải thiện thuật ngữ chuyên ngành về AI, HPC và dịch vụ Cloud-native, đồng thời mở rộng hiểu biết thực tế về các dịch vụ. Tham gia sự kiện chính thức của AWS, nắm bắt kiến thức về cách SageMaker, Bedrock, CodeWhisperer và Kiro nâng cao hiệu quả phát triển AI doanh nghiệp và quản trị. Cải thiện rõ rệt kỹ năng kỹ sư dữ liệu đám mây, phân tích serverless, thiết kế hiệu năng NoSQL và best practice vận hành AI trên AWS. "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/1-worklog/1.6-week6/","title":"Worklog Tuần 6","tags":[],"description":"","content":"Mục tiêu tuần 6: Củng cố kỹ năng thực hành với các dịch vụ dữ liệu và phân tích chính của AWS bao gồm Glue, Athena, QuickSight và kiến trúc DataLake trên S3. Xây dựng kiến thức lý thuyết và thực hành về Amazon DynamoDB cho các khối lượng công việc NoSQL có thể mở rộng. Nâng cao kỹ năng truyền đạt kỹ thuật trên nền tảng đám mây bằng cách dịch các bài blog AWS về Generative AI, HPC và giải pháp contact center. Cập nhật kiến thức ngành bằng cách tham dự một sự kiện AWS tập trung vào vòng đời phát triển AI và các công cụ mới như Kiro. Cải thiện khả năng thiết kế và triển khai các giải pháp phân tích cho phép thu thập dữ liệu, biến đổi, truy vấn và trực quan hóa trên AWS. Các nhiệm vụ thực hiện trong tuần này: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 Lab 35: DataLake trên AWS\n- Giới thiệu về DataLake:\n- Hiểu DataLake là kho lưu trữ tập trung chứa dữ liệu thô và dữ liệu đã xử lý phục vụ cho phân tích và rút ra insight.\n- Nắm các đặc tính chính: thu thập mọi loại dữ liệu, truy cập đa người dùng, và mô hình truy cập linh hoạt (batch, tương tác, real-time, tìm kiếm).\n- Tìm hiểu cách các dịch vụ AWS (Glue, Athena, QuickSight) tích hợp để xây dựng giải pháp DataLake hoàn chỉnh.\n- Amazon Glue (dịch vụ ETL):\n- Tìm hiểu về Glue Crawlers để tự động phát hiện schema và tạo Glue Data Catalog.\n- Hiểu cách các job ETL của Glue sinh ra script Python có thể tùy chỉnh để biến đổi và tải dữ liệu.\n- Thực hành tạo Crawler để quét dữ liệu trên S3 và xây dựng Data Catalog để truy vấn.\n- Amazon Athena (dịch vụ truy vấn tương tác):\n- Tìm hiểu Athena cho phép truy vấn dữ liệu trên S3 bằng SQL tiêu chuẩn mà không cần pipeline ETL phức tạp.\n- Cấu hình Athena để truy vấn dataset trên S3 và hiểu mô hình chi phí (trả theo truy vấn).\n- Khám phá các định dạng dữ liệu mà Athena hỗ trợ (CSV, JSON, ORC, Avro, Parquet).\n- Amazon QuickSight (dịch vụ trực quan hóa):\n- Học cách QuickSight kết nối tới nguồn dữ liệu và xây dựng dataset cho trực quan hóa.\n- Tạo các biểu đồ, phân tích và dashboard để thể hiện các chỉ số kinh doanh quan trọng.\n- Hiểu cấu trúc QuickSight: Datasource → Dataset → Analysis → Visual → Dashboard.\n- Các bước triển khai:\n- Tạo IAM Role với quyền S3FullAccess và AWSGlueServiceRole.\n- Chuẩn bị cấu trúc bucket S3 (/data, /ref_data) và tải các tệp lên.\n- Thiết lập Kinesis Delivery Stream để liên tục đưa dữ liệu vào S3.\n- Triển khai stack CloudFormation để tự động hóa hạ tầng.\n- Chạy AWS Glue Crawler để catalog dữ liệu S3 và kiểm tra bằng Amazon Athena.\n- Khởi chạy SageMaker Notebook qua Glue Studio cho các workflow biến đổi dữ liệu bổ sung. 29/09/2025 29/09/2025 2 Lab 40:\n- Ôn lại AWS Glue như một dịch vụ ETL được quản lý để chuẩn bị dữ liệu cho phân tích. - Hiểu workflow: 1. Tải dữ liệu thô lên Amazon S3. 2. Dùng Glue Crawler để phát hiện schema và tạo database trong Glue Data Catalog. 3. Biến đổi dữ liệu sang định dạng tối ưu như Parquet. 4. Truy vấn dữ liệu đã biến đổi bằng Amazon Athena. - Cấu hình AWS Glue và Athena cho cập nhật schema tự động và lịch chạy crawler. - Thực thi các truy vấn SQL trong Athena để phân tích: - Top 10 tài khoản AWS có chi phí cao nhất và các dịch vụ tương ứng. - Phân tích chi tiết chi phí theo dịch vụ và tag (ví dụ: cost_center). - Các kỳ thanh toán khác nhau và các loại sử dụng. - Học cách giảm chi phí truy vấn Athena bằng: - Sử dụng file Parquet nén. - Hạn chế kết quả truy vấn bằng LIMIT. - Tổ chức dữ liệu hiệu quả để truy vấn phân vùng. - Khám phá phân bổ chi phí và tagging cho theo dõi và tối ưu hóa chi phí ở cấp doanh nghiệp. 30/09/2025 30/09/2025 3 Lab 60: Amazon DynamoDB\n- Tổng quan:\n- Nghiên cứu Amazon DynamoDB — dịch vụ cơ sở dữ liệu NoSQL được quản lý hoàn toàn, cung cấp hiệu năng nhanh và khả năng mở rộng mượt mà.\n- Hiểu DynamoDB tự động quản lý hạ tầng, scaling và nhân bản dữ liệu trên nhiều Availability Zone.\n- Khám phá các tính năng như chế độ tính công suất on-demand và provisioned, mã hóa khi lưu trữ, point-in-time recovery, và tự động xóa item theo thời gian (TTL).\n- Các thành phần chính:\n- Table: Tập hợp logic của các item (tương tự table trong DB quan hệ).\n- Item: Bản ghi riêng lẻ trong table (tương tự hàng).\n- Attribute: Thuộc tính trong item (tương tự cột).\n- Khóa chính:\n- Tìm hiểu về Partition Key và Composite Primary Key (Partition + Sort Key) để định danh duy nhất item.\n- Hiểu cách composite key tăng tính linh hoạt khi truy vấn.\n- Secondary Indexes:\n- Thực hành sử dụng Global Secondary Index (GSI) và Local Secondary Index (LSI) để tối ưu truy vấn.\n- Nhận biết DynamoDB hỗ trợ tối đa 20 GSI và 5 LSI cho mỗi bảng.\n- Tính nhất quán đọc:\n- So sánh Eventually Consistent Reads (nhanh hơn, có thể trả dữ liệu cũ) và Strongly Consistent Reads (luôn trả dữ liệu mới nhất, chậm và tốn hơn).\n- Chế độ công suất đọc/ghi:\n- Chế độ On-Demand: Phù hợp cho workloads không dự đoán trước, tự động scale theo nhu cầu.\n- Chế độ Provisioned: Phù hợp cho workloads có lưu lượng dự đoán được, ổn định hoặc có forecast.\n- Triển khai:\n- Khám phá AWS Management Console và AWS CloudShell để thiết lập và quản lý DynamoDB.\n- Học cách sử dụng AWS SDK (Boto3) để tương tác chương trình với các bảng DynamoDB. 01/10/2025 01/10/2025 4 Hoạt động: Dịch các bài blog kỹ thuật của AWS\nNội dung dịch:\n- “Accelerating Generative AI Development with Fully Managed MLflow 3.0 on Amazon SageMaker AI” – Học cách AWS tích hợp MLflow để quản lý vòng đời các mô hình Generative AI.\n- “AI-Enhanced Subsurface Infrastructure Mapping on AWS” – Hiểu cách deep learning và HPC được áp dụng để phát hiện cơ sở hạ tầng ngầm dưới đất.\n- “Unlocking the Full Potential of Amazon Connect” – Nâng cao hiểu biết về các best practice triển khai contact center có AI.\nKỹ năng đạt được:\n- Cải thiện kỹ năng dịch thuật kỹ thuật (AI, HPC, Điện toán đám mây).\n- Nâng cao hiểu biết về các dịch vụ AWS: SageMaker, Batch, ParallelCluster, và Amazon Connect.\n- Mở rộng vốn từ kỹ thuật và cách diễn đạt tiếng Anh trong lĩnh vực đám mây và AI. 2/10/2025 2/10/2025 5 Hoạt động: Tham dự sự kiện AWS về vòng đời phát triển AI và giới thiệu Kiro\nChi tiết:\n- Tham gia một sự kiện do AWS tổ chức tập trung vào vòng đời phát triển AI, bao phủ các giai đoạn chính từ chuẩn bị dữ liệu, huấn luyện mô hình, đánh giá đến triển khai và giám sát liên tục.\n- Học về cách các dịch vụ AWS như Amazon SageMaker, Bedrock, và CodeWhisperer hỗ trợ phát triển và tối ưu mô hình end-to-end.\n- Nghe bài trình bày chi tiết về Kiro – một giải pháp mới của AWS được giới thiệu nhằm đơn giản hóa và hợp nhất quản lý workflow AI giữa các nhóm.\n- Nhận biết cách Kiro tích hợp với các công cụ AWS khác để quản lý dataset, phiên bản mô hình và theo dõi thí nghiệm, tăng cường hợp tác và quản trị.\n- Khám phá các case study thực tế cho thấy tổ chức sử dụng hạ tầng AWS để tăng tốc tự động hóa dựa trên AI, giảm thời gian huấn luyện và cải thiện độ tin cậy của mô hình trong môi trường production.\nKỹ năng đạt được:\n- Sâu hơn trong hiểu biết về vòng đời phát triển AI trên hệ sinh thái AWS.\n- Học ứng dụng thực tế quản lý vòng đời mô hình bằng các dịch vụ AWS và Kiro.\n- Nâng cao kiến thức về observability mô hình, theo dõi thí nghiệm và best practice triển khai.\n- Củng cố vốn ngôn ngữ và kỹ năng giao tiếp kỹ thuật liên quan đến AI, ML và Điện toán đám mây. 3/10/2025 3/10/2025 Thành tựu Tuần 6: Hoàn thành thành công Lab 35 về DataLake trên AWS, thu được kinh nghiệm thực hành với pipeline ETL Glue, truy vấn tương tác Athena, trực quan hóa BI bằng QuickSight, và điều phối dữ liệu trên S3. Hoàn thành Lab 40 để phân tích dữ liệu chi phí AWS bằng cách dùng Glue để phát hiện schema và truy vấn bằng Athena, đồng thời học tối ưu chi phí bằng định dạng lưu trữ hiệu quả như Parquet. Khám phá đầy đủ chức năng Amazon DynamoDB trong Lab 60 bao gồm các chế độ công suất, indexing GSI/LSI, tính nhất quán đọc và tự động hóa bằng SDK của AWS. Dịch nhiều bài viết kỹ thuật của AWS, cải thiện thuật ngữ đám mây, hiểu biết về vòng đời AI và kỹ năng viết kỹ thuật. Tham dự sự kiện AWS tập trung vào workflow AI end-to-end, nắm bắt sâu hơn về SageMaker, Bedrock và nền tảng mới Kiro. Củng cố tổng thể kiến thức thực hành và lý thuyết về Kỹ thuật dữ liệu, Cơ sở dữ liệu NoSQL, giải pháp AI/ML và các best practice kiến trúc đám mây. "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/1-worklog/1.7-week7/","title":"Worklog Tuần 7","tags":[],"description":"","content":"Mục tiêu tuần 7: Ôn tập và củng cố kiến thức lý thuyết về các dịch vụ cốt lõi của AWS và nguyên tắc kiến trúc tốt nhất. Luyện làm các câu hỏi thi AWS Cloud Practitioner hàng ngày để cải thiện khả năng nhận diện dịch vụ và phân tích tình huống. Tăng cường hiểu biết về bảo mật AWS, thiết kế mạng, chiến lược lưu trữ, các lựa chọn compute và mô hình sẵn sàng của cơ sở dữ liệu. Xây dựng khả năng lựa chọn dịch vụ AWS phù hợp dựa trên yêu cầu doanh nghiệp, chi phí và kỳ vọng vận hành. Các nhiệm vụ thực hiện trong tuần này: Ngày Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 1 Lab 35: DataLake trên AWS\n- Giới thiệu về DataLake:\n- Hiểu DataLake là kho dữ liệu tập trung lưu trữ cả dữ liệu thô và đã xử lý để phục vụ phân tích và khai thác thông tin.\n- Học các đặc tính chính: thu thập mọi thứ, truy cập đa người dùng, và các dạng truy cập linh hoạt (batch, tương tác, thời gian thực, tìm kiếm).\n- Nắm cách các dịch vụ AWS (Glue, Athena, QuickSight) tích hợp để xây dựng giải pháp DataLake hoàn chỉnh.\n- Amazon Glue (dịch vụ ETL):\n- Tìm hiểu Glue Crawlers để tự động khám phá schema và tạo Data Catalog.\n- Hiểu cách các job ETL của Glue sinh ra các script Python có thể tùy chỉnh cho việc chuyển đổi và nạp dữ liệu.\n- Thực hành tạo Crawler để quét dữ liệu trên S3 và xây dựng Data Catalog để truy vấn.\n- Amazon Athena (dịch vụ truy vấn tương tác):\n- Biết rằng Athena cho phép truy vấn dữ liệu trên S3 bằng SQL tiêu chuẩn mà không cần pipeline ETL phức tạp.\n- Cấu hình Athena để truy vấn tập dữ liệu trên S3 và hiểu mô hình chi phí của nó (trả theo truy vấn).\n- Khám phá các định dạng dữ liệu được Athena hỗ trợ (CSV, JSON, ORC, Avro, Parquet).\n- Amazon QuickSight (dịch vụ trực quan hóa dữ liệu):\n- Học cách QuickSight kết nối tới nguồn dữ liệu và xây dựng dataset để trực quan hóa.\n- Tạo các biểu đồ, phân tích và dashboard để thể hiện các chỉ số kinh doanh chính.\n- Hiểu cấu trúc của QuickSight: Datasource → Dataset → Analysis → Visual → Dashboard.\n- Các bước triển khai:\n- Tạo IAM Role với quyền S3FullAccess và AWSGlueServiceRole.\n- Chuẩn bị cấu trúc bucket S3 (/data, /ref_data) và tải file lên.\n- Thiết lập Kinesis Delivery Stream để liên tục đưa dữ liệu vào S3.\n- Triển khai CloudFormation stack để tự động hóa hạ tầng.\n- Chạy AWS Glue Crawler để catalog dữ liệu S3 và kiểm tra bằng Amazon Athena.\n- Khởi chạy SageMaker Notebook qua Glue Studio cho các luồng chuyển đổi dữ liệu bổ sung. 29/09/2025 29/09/2025 2 Lab40:\n- Ôn lại AWS Glue như dịch vụ ETL được quản lý hỗ trợ chuẩn bị dữ liệu cho phân tích. - Hiểu workflow: 1. Upload dữ liệu thô lên Amazon S3. 2. Dùng Glue Crawler để phát hiện schema và tạo cơ sở dữ liệu trong Glue Data Catalog. 3. Chuyển đổi dữ liệu sang định dạng tối ưu như Parquet. 4. Truy vấn dữ liệu đã chuyển đổi bằng Amazon Athena. - Cấu hình AWS Glue và Athena để cập nhật schema tự động và đặt lịch chạy crawler. - Thực hiện các truy vấn SQL trong Athena để phân tích: - Top 10 tài khoản và dịch vụ AWS tốn kém nhất. - Phân tích chi phí chi tiết theo dịch vụ và tag (ví dụ: cost_center). - Các kỳ thanh toán và loại sử dụng khác nhau. - Học cách giảm chi phí truy vấn Athena bằng cách: - Sử dụng file Parquet nén. - Giới hạn kết quả truy vấn bằng LIMIT. - Cấu trúc dữ liệu hợp lý cho truy vấn phân vùng. - Khám phá phân bổ chi phí và tagging cho quản trị chi phí ở cấp doanh nghiệp. 30/09/2025 30/09/2025 3 Lab 60: Amazon DynamoDB\n- Tổng quan:\n- Học về Amazon DynamoDB — dịch vụ cơ sở dữ liệu NoSQL được quản lý hoàn toàn, cung cấp hiệu năng nhanh và khả năng mở rộng mượt mà.\n- Hiểu DynamoDB quản lý tự động hạ tầng, scale, và nhân bản dữ liệu qua nhiều Availability Zone.\n- Khám phá các tính năng như chế độ on-demand và provisioned capacity, mã hóa khi lưu (encryption at rest), phục hồi theo thời điểm (PITR), và tự động xoá item theo thời hạn.\n- Thành phần chính:\n- Table: tập hợp logic của các item (tương tự bảng trong DB quan hệ).\n- Item: bản ghi trong bảng (tương tự hàng).\n- Attribute: thuộc tính trong item (tương tự cột).\n- Khóa chính:\n- Tìm hiểu Partition Key và Composite Primary Key (Partition + Sort Key) để định danh duy nhất item.\n- Hiểu cách khóa kép tăng tính linh hoạt cho truy vấn.\n- Chỉ mục phụ:\n- Thực hành sử dụng Global Secondary Index (GSI) và Local Secondary Index (LSI) để tối ưu truy vấn.\n- Nhận biết DynamoDB hỗ trợ tối đa 20 GSI và 5 LSI cho mỗi bảng.\n- Tính nhất quán đọc:\n- So sánh Eventually Consistent Reads (nhanh hơn, có thể trả dữ liệu cũ) và Strongly Consistent Reads (luôn là dữ liệu mới nhất, chậm và tốn kém hơn).\n- Chế độ đọc/ghi:\n- On-Demand: phù hợp tải không dự đoán, tự động scale theo nhu cầu.\n- Provisioned: phù hợp tải dự đoán với lưu lượng ổn định hoặc có thể dự báo. - Triển khai:\n- Thực hành trên AWS Management Console và AWS CloudShell cho việc thiết lập và quản lý DynamoDB.\n- Học cách sử dụng AWS SDK (Boto3) để tương tác chương trình với bảng DynamoDB. 01/10/2025 01/10/2025 4 Hoạt động: Dịch các bài blog kỹ thuật của AWS\nNội dung đã dịch:\n- “Accelerating Generative AI Development with Fully Managed MLflow 3.0 on Amazon SageMaker AI” – Học cách AWS tích hợp MLflow để quản lý vòng đời mô hình Generative AI.\n- “AI-Enhanced Subsurface Infrastructure Mapping on AWS” – Hiểu cách deep learning và HPC được áp dụng để phát hiện hạ tầng ngầm.\n- “Unlocking the Full Potential of Amazon Connect” – Nắm các best practice khi triển khai contact center được hỗ trợ bởi AI trên AWS.\nKỹ năng đạt được:\n- Cải thiện kỹ năng dịch thuật kỹ thuật (AI, HPC, Cloud Computing).\n- Nâng cao hiểu biết về các dịch vụ AWS: SageMaker, Batch, ParallelCluster, và Amazon Connect.\n- Mở rộng vốn từ kỹ thuật và cách diễn đạt tiếng Anh trong lĩnh vực đám mây và AI. 02/10/2025 02/10/2025 5 Hoạt động: Tham dự sự kiện AWS về vòng đời phát triển AI và giới thiệu Kiro\nChi tiết:\n- Tham dự sự kiện do AWS tổ chức tập trung vào vòng đời phát triển AI, bao gồm các giai đoạn chính từ chuẩn bị dữ liệu, huấn luyện mô hình, đánh giá đến triển khai và giám sát liên tục.\n- Tìm hiểu cách các dịch vụ AWS như Amazon SageMaker, Bedrock và CodeWhisperer hỗ trợ end-to-end việc phát triển và tối ưu hóa mô hình AI.\n- Nghe bài trình bày chi tiết về Kiro – một giải pháp AWS mới nhằm đơn giản hóa và hợp nhất quản lý workflow AI giữa các nhóm.\n- Nắm cách Kiro tích hợp với các công cụ AWS khác để quản lý dataset, phiên bản mô hình và theo dõi thử nghiệm hiệu quả hơn, tăng cường hợp tác và quản trị. - Khám phá các case study thực tế cho thấy tổ chức dùng hạ tầng AWS để tăng tốc tự động hóa bằng AI, rút ngắn thời gian huấn luyện và cải thiện độ tin cậy của mô hình khi đưa vào production.\nKỹ năng đạt được:\n- Làm sâu hơn hiểu biết về vòng đời phát triển AI trong hệ sinh thái AWS.\n- Học cách ứng dụng thực tế quản lý vòng đời mô hình bằng dịch vụ AWS và Kiro.\n- Nâng cao kiến thức về quan sát mô hình (observability), theo dõi thử nghiệm và best practice triển khai.\n- Củng cố vốn từ và khả năng giao tiếp kỹ thuật liên quan AI, ML và Cloud Computing. 03/10/2025 03/10/2025 Thành tựu tuần 7: Hoàn thành 2–3 bộ đề luyện thi AWS Cloud Practitioner mỗi ngày với sự tiến bộ đều đặn về hiệu suất. Ôn lại lý thuyết và các tình huống thực tế liên quan các miền chính của AWS bao gồm Compute, Storage, Networking, Security và Databases. Cải thiện khả năng phân biệt các dịch vụ AWS có chức năng tương tự như: Elastic Load Balancing vs Route 53 vs Global Accelerator, S3 storage classes vs EBS vs EFS, Multi-AZ vs Read Replicas trong RDS. Hiểu sâu cơ sở lý thuyết về các lựa chọn tối ưu hóa chi phí (On-Demand, Reserved Instances, Savings Plans, Spot Instances). Củng cố kiến thức lý thuyết về quản lý danh tính và truy cập: IAM users, roles, policies, MFA, nguyên tắc least privilege. Nâng cao hiểu biết về AWS Well-Architected Framework và sáu trụ cột của nó cho các câu hỏi yêu cầu trong kỳ thi. "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/1-worklog/1.8-week8/","title":"Worklog Tuần 8","tags":[],"description":"","content":"Mục tiêu tuần 8: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 8: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/1-worklog/1.9-week9/","title":"Worklog Tuần 9","tags":[],"description":"","content":"Mục tiêu tuần 9: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 9: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/2-proposal/","title":"Bản đề xuất","tags":[],"description":"","content":"Ứng dụng quản lý tài chính cá nhân 1. Tóm tắt điều hành Dự án Personal Finance Management App hướng đến việc cung cấp một nền tảng quản lý tài chính cá nhân thông minh, hiện đại và mang tính tự động hóa cao. Ứng dụng cho phép người dùng ghi nhận thu chi, tạo và quản lý nhiều hũ tiền (money jars) theo mục đích khác nhau, lập kế hoạch chi tiêu, nhận cảnh báo thông minh và tạo báo cáo phân tích trực quan.\nỨng dụng được xây dựng với kiến trúc microservices trên nền tảng .NET và FastAPI, triển khai trên AWS Cloud, đảm bảo tính linh hoạt, khả năng mở rộng và an toàn dữ liệu. Quy trình phát triển tuân theo mô hình Agile/Scrum (2 tuần/sprint), với thời gian hoàn thành MVP trong 2 tháng.\n2. Tuyên bố vấn đề Vấn đề hiện tại Trên thị trường đã có rất nhiều ứng dụng quản lý tài chính, tuy nhiên phần lớn vẫn yêu cầu người dùng nhập liệu thủ công — một công việc tốn thời gian, dễ sai sót và khiến người dùng nhanh chóng bỏ cuộc. Các ứng dụng hiện có chỉ tập trung vào thống kê chi tiêu mà chưa thực sự giúp người dùng tự động hóa quy trình quản lý tài chính cá nhân.\nGiải pháp Giải pháp sử dụng AWS Cloud kết hợp kiến trúc microservices để xây dựng một nền tảng quản lý tài chính cá nhân tự động hóa, tích hợp AI trong xử lý giọng nói và nhận diện hóa đơn. Hệ thống được triển khai trên AWS ECS Fargate cho các service backend (.NET), FastAPI cho xử lý AI, và Next.js cho frontend. So với các nền tảng tài chính phổ biến như Money Lover hay Misa Money Keeper, ứng dụng này tập trung vào tự động hóa hoàn toàn nhập liệu tài chính thông qua AI voice-to-text và bill scanning chi tiết tiếng Việt, giúp giảm thao tác thủ công và sai sót. Hệ thống phù hợp cho người dùng cá nhân và nhóm nhỏ, đồng thời có thể mở rộng khi cần cho quy mô doanh nghiệp hoặc ứng dụng ngân hàng số.\nLợi ích và hoàn vốn đầu tư (ROI) Giải pháp mang lại nhiều lợi ích thiết thực cả về mặt kỹ thuật và giá trị kinh doanh:\nTự động hóa nhập liệu: Giảm hơn 70% thao tác thủ công nhờ AI nhận diện giọng nói và hóa đơn. Tăng độ chính xác: Hạn chế sai sót nhập liệu, đảm bảo tính toàn vẹn của dữ liệu tài chính (\u0026gt;90% chính xác). Cải thiện hiệu suất người dùng: Ghi nhận và phân loại giao dịch chỉ trong vài giây, tối ưu trải nghiệm sử dụng. Tiết kiệm chi phí: Chi phí hạ tầng thấp nhờ tận dụng AWS Free Tier đến năm 2026; chỉ ước tính ~60 USD/tháng cho AWS và ~30 USD cho compute AI. Hoàn vốn nhanh: Dự kiến hoàn vốn trong 6–12 tháng, nhờ tiết kiệm thời gian nhập liệu và tăng hiệu suất vận hành. Khả năng mở rộng \u0026amp; tích hợp: Kiến trúc microservices trên AWS cho phép dễ dàng bổ sung tính năng (mobile app, phân tích nâng cao, tích hợp ngân hàng). 3. Kiến trúc giải pháp Hệ thống được triển khai theo mô hình microservices trên nền tảng AWS Cloud, kết hợp các dịch vụ serverless, container, và cơ sở dữ liệu quản lý để đảm bảo hiệu năng và khả năng mở rộng.\nNgười dùng truy cập ứng dụng web Next.js thông qua Amazon CloudFront, nội dung tĩnh được lưu trữ trong Amazon S3 và phân phối qua Amazon Route 53. Lớp bảo mật đầu tiên được cung cấp bởi AWS WAF nhằm ngăn chặn các tấn công phổ biến như SQL Injection hoặc XSS.\nKhi người dùng đăng nhập, quá trình xác thực được xử lý bởi Amazon Cognito, cấp token truy cập để frontend gửi các yêu cầu API qua Amazon API Gateway. API Gateway định tuyến yêu cầu đến Application Load Balancer (ALB) thông qua AWS PrivateLink, sau đó chuyển tiếp đến Amazon ECS (Fargate) — nơi triển khai các container backend bao gồm:\nBackend Service (.NET): Xử lý nghiệp vụ chính của hệ thống.\nAI Service (FastAPI): Xử lý hóa đơn, nhận dạng giọng nói và các tác vụ AI.\nKhi người dùng tải hóa đơn hoặc ghi âm, file tạm thời được lưu trong Amazon S3.\nAI Service có thể truy cập tệp từ Amazon S3 để thực hiện các xử lý dữ liệu, sau đó trả kết quả lại cho Backend Service thông qua message broker.\nHình ảnh container được lưu trữ trong Amazon ECR, và quá trình triển khai được tự động hóa qua GitLab CI/CD Pipeline — bao gồm các bước build image, push lên ECR, và cập nhật Task Definition trên ECS.\nTất cả logs, metrics và cảnh báo từ ECS, API Gateway, và ALB được gửi về Amazon CloudWatch để giám sát tập trung, đồng thời Amazon SNS được cấu hình để gửi cảnh báo tự động khi có sự cố.\nDịch vụ AWS sử dụng\nAmazon Route 53: Quản lý DNS và tên miền truy cập. AWS WAF: Bảo vệ hệ thống khỏi các tấn công web phổ biến. Amazon CloudFront: Phân phối nội dung tĩnh toàn cầu và tăng tốc truy cập frontend. Amazon S3: Lưu trữ website tĩnh và file người dùng (hóa đơn, ghi âm). Amazon Cognito: Xác thực và quản lý người dùng. Amazon API Gateway: Cổng vào của hệ thống, định tuyến request từ frontend đến backend. AWS PrivateLink: Tạo kết nối riêng giữa API Gateway và ALB trong VPC để tăng cường bảo mật. Application Load Balancer (ALB): Cân bằng tải giữa các container backend trên ECS. Amazon ECS (Fargate): Chạy các microservices Backend và FastAPI (AI). Amazon ECR: Kho lưu trữ image container cho ECS. Amazon CloudWatch: Giám sát logs, hiệu năng và cảnh báo hệ thống. Amazon SNS: Gửi thông báo hoặc cảnh báo khi có sự cố. GitLab CI/CD: Tự động hóa pipeline build, push và deploy container lên ECS. 4. Triển khai kỹ thuật Các giai đoạn triển khai Nghiên cứu và vẽ kiến trúc: Nghiên cứu các mô hình microservices và thiết kế kiến trúc tổng thể trên AWS (bao gồm CloudFront, ECS Fargate, RDS, S3, API Gateway, Cognito) — (Tháng 1). Tính toán chi phí và điều chỉnh giải pháp: Sử dụng AWS Pricing Calculator để ước tính chi phí, tối ưu lựa chọn dịch vụ nhằm đảm bảo chi phí thấp và dễ triển khai cho người mới học — (Tháng 1–2). Phát triển, kiểm thử, triển khai: Xây dựng frontend (Next.js), backend (.NET), và AI service (FastAPI); kiểm thử tích hợp microservices, sau đó triển khai toàn bộ hệ thống lên AWS bằng ECS Fargate và thiết lập giám sát qua CloudWatch — (Tháng 2–3). Yêu cầu kỹ thuật Frontend: Ứng dụng web Next.js được lưu trữ trong Amazon S3 và phân phối qua CloudFront, giao tiếp với backend thông qua API Gateway. Người dùng đăng nhập qua Amazon Cognito, nhận token để gọi API bảo mật. Backend: Viết bằng .NET hoặc framework tương tự, triển khai trên ECS Fargate. Các service xử lý nghiệp vụ người dùng, giao dịch và các yêu cầu từ frontend. Container image được lưu trong ECR, được cập nhật qua pipeline CI/CD từ GitLab. ALB được dùng để cân bằng tải giữa các container backend. AI Service: Viết bằng FastAPI, xử lý hình ảnh hóa đơn và giọng nói, kết nối đến S3 để đọc dữ liệu. Kết quả được trả về Backend Service thông qua API nội bộ. Hạ tầng Cloud: Sử dụng Amazon VPC (multi-AZ), Application Load Balancer, và CloudWatch để giám sát. Hình ảnh container được lưu trữ trên ECR và triển khai qua ECS Fargate. CI/CD được thực hiện qua GitLab CI/CD để tự động hóa build và deploy. Bảo mật: Quản lý quyền truy cập người dùng bằng Amazon Cognito. Sử dụng IAM Roles cho ECS, S3, CloudWatch, và API Gateway để giới hạn quyền truy cập. Security Group được cấu hình chặt chẽ giữa ECS, ALB và các dịch vụ khác để đảm bảo an toàn mạng. AWS WAF được cấu hình để bảo vệ tầng frontend khỏi các tấn công web phổ biến. 5. Lộ trình \u0026amp; Mốc triển khai Trước thực tập (Tháng 0): 1 tháng lên kế hoạch. Thực tập (Tháng 1–3): Tháng 1: Học AWS và nâng cấp kỹ năng lập trình. Tháng 2: Thiết kế và điều chỉnh kiến trúc. Tháng 3: Triển khai, kiểm thử, đưa vào sử dụng. Sau triển khai: Nghiên cứu thêm về mobile và triển khai sau tháng thứ 4. 6. Ước tính ngân sách Có thể xem chi phí trên AWS Pricing Calculator\nDịch vụ Trong Free Tier Sau khi hết Free Tier Amazon ECS (Fargate) 0,00 USD / tháng 8,00 USD / tháng Amazon API Gateway 0,00 USD / tháng 2,00 USD / tháng Amazon S3 0,00 USD / tháng 1,00 USD / tháng Amazon CloudWatch 0,00 USD / tháng 2,00 USD / tháng Amazon Cognito 0,00 USD / tháng 0,00 USD / tháng Amazon ECR 0,00 USD / tháng 0,20 USD / tháng Amazon Route 53 1,00 USD / tháng 1,00 USD / tháng AWS WAF 0,00 USD / tháng 1,00 USD / tháng Amazon SNS 0,00 USD / tháng 0,50 USD / tháng GitLab CI/CD 0,00 USD / tháng 2,00 USD / tháng Tổng ước tính ≈ 1,00 USD / tháng (≈ 12,00 USD / năm) ≈ 17,70 USD / tháng (≈ 212,40 USD / năm) 7. Đánh giá rủi ro Ma trận rủi ro\nMô hình AI nhận dạng sai (voice/bill): Ảnh hưởng trung bình, xác suất trung bình. Mất kết nối AWS hoặc lỗi dịch vụ vùng (region): Ảnh hưởng cao, xác suất thấp. Vượt ngân sách sử dụng AWS: Ảnh hưởng trung bình, xác suất thấp. Lỗi đồng bộ dữ liệu giữa các microservices: Ảnh hưởng trung bình, xác suất trung bình. Lộ thông tin người dùng (Cognito/Database): Ảnh hưởng cao, xác suất thấp. Chiến lược giảm thiểu\nAI: Cải thiện mô hình OCR và voice-to-text qua huấn luyện thêm, kiểm thử định kỳ với dữ liệu thực tế. AWS Region: Thiết lập triển khai đa vùng (multi-AZ) và backup định kỳ cơ sở dữ liệu RDS. Chi phí: Cấu hình AWS Budget Alert và tối ưu ECS, S3 theo mức sử dụng thực tế. Microservices: Dùng SQS/RabbitMQ để đảm bảo xử lý bất đồng bộ và retry khi lỗi. Bảo mật: Mã hóa dữ liệu (AES-256, HTTPS), kiểm soát IAM theo nguyên tắc “Least Privilege”. Kế hoạch dự phòng\nNếu AWS gặp sự cố: Tạm thời chuyển sang lưu trữ dữ liệu giao dịch cục bộ và đồng bộ lại sau khi khôi phục. Khôi phục hạ tầng bằng AWS CloudFormation hoặc IaC (Infrastructure as Code) đã lưu sẵn. Giữ bản sao cơ sở dữ liệu định kỳ (RDS snapshot) để phục hồi trong tình huống mất dữ liệu. 8. Kết quả kỳ vọng của dự án Tự động hóa nhập liệu tài chính: Ứng dụng giúp người dùng không cần nhập thủ công, chỉ cần chụp hóa đơn hoặc ghi âm giọng nói để hệ thống tự phân loại chi tiêu. Quản lý tài chính trực quan: Người dùng có thể xem biểu đồ chi tiêu, báo cáo tháng, và nhận gợi ý tiết kiệm dựa trên hành vi tiêu dùng. Trải nghiệm người dùng tối giản: Giao diện web thân thiện, thiết kế hiện đại, tối ưu cho thiết bị di động và phù hợp với người mới quản lý tài chính. Hệ thống ổn định, dễ mở rộng: Kiến trúc microservices giúp dễ dàng bổ sung tính năng mới như nhắc nhở chi tiêu, phân tích dự báo AI, hoặc mở rộng sang mobile app. Chi phí vận hành thấp: Tận dụng Free Tier AWS và mô hình serverless để duy trì hệ thống với chi phí trung bình \u0026lt; 50 USD/tháng. Nâng cao kỹ năng nhóm phát triển: Thành viên dự án tiếp cận thực tế với quy trình DevOps, triển khai CI/CD, và tối ưu ứng dụng trên nền tảng cloud. 9. Hạn chế của dự án Mô hình AI tiếng Việt còn hạn chế: Khả năng nhận dạng giọng nói vùng miền hoặc hóa đơn viết tay chưa đạt độ chính xác cao. Chưa có ứng dụng di động riêng: Phiên bản MVP chỉ hỗ trợ nền web, chưa có mobile app native. Giới hạn người dùng: Kiến trúc hiện tại chỉ tối ưu cho 50–100 người dùng hoạt động; khi mở rộng quy mô cần tái cấu trúc hạ tầng. Phụ thuộc kết nối Internet: Mọi thao tác xử lý và lưu trữ đều qua cloud, không thể hoạt động offline. Chưa triển khai hệ thống bảo mật nâng cao: Mới dừng ở xác thực Cognito và mã hóa cơ bản, chưa có MFA (Multi-Factor Authentication) hay log bảo mật chuyên sâu. "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/5-workshop/5.2-prerequiste/","title":"Các bước chuẩn bị","tags":[],"description":"","content":"IAM permissions Gắn IAM permission policy sau vào tài khoản aws user của bạn để triển khai và dọn dẹp tài nguyên trong workshop này.\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;VisualEditor0\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;cloudformation:*\u0026#34;, \u0026#34;cloudwatch:*\u0026#34;, \u0026#34;ec2:AcceptTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:AcceptTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:AllocateAddress\u0026#34;, \u0026#34;ec2:AssociateAddress\u0026#34;, \u0026#34;ec2:AssociateIamInstanceProfile\u0026#34;, \u0026#34;ec2:AssociateRouteTable\u0026#34;, \u0026#34;ec2:AssociateSubnetCidrBlock\u0026#34;, \u0026#34;ec2:AssociateTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:AssociateVpcCidrBlock\u0026#34;, \u0026#34;ec2:AttachInternetGateway\u0026#34;, \u0026#34;ec2:AttachNetworkInterface\u0026#34;, \u0026#34;ec2:AttachVolume\u0026#34;, \u0026#34;ec2:AttachVpnGateway\u0026#34;, \u0026#34;ec2:AuthorizeSecurityGroupEgress\u0026#34;, \u0026#34;ec2:AuthorizeSecurityGroupIngress\u0026#34;, \u0026#34;ec2:CreateClientVpnEndpoint\u0026#34;, \u0026#34;ec2:CreateClientVpnRoute\u0026#34;, \u0026#34;ec2:CreateCustomerGateway\u0026#34;, \u0026#34;ec2:CreateDhcpOptions\u0026#34;, \u0026#34;ec2:CreateFlowLogs\u0026#34;, \u0026#34;ec2:CreateInternetGateway\u0026#34;, \u0026#34;ec2:CreateLaunchTemplate\u0026#34;, \u0026#34;ec2:CreateNetworkAcl\u0026#34;, \u0026#34;ec2:CreateNetworkInterface\u0026#34;, \u0026#34;ec2:CreateNetworkInterfacePermission\u0026#34;, \u0026#34;ec2:CreateRoute\u0026#34;, \u0026#34;ec2:CreateRouteTable\u0026#34;, \u0026#34;ec2:CreateSecurityGroup\u0026#34;, \u0026#34;ec2:CreateSubnet\u0026#34;, \u0026#34;ec2:CreateSubnetCidrReservation\u0026#34;, \u0026#34;ec2:CreateTags\u0026#34;, \u0026#34;ec2:CreateTransitGateway\u0026#34;, \u0026#34;ec2:CreateTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:CreateTransitGatewayPrefixListReference\u0026#34;, \u0026#34;ec2:CreateTransitGatewayRoute\u0026#34;, \u0026#34;ec2:CreateTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:CreateTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:CreateVpc\u0026#34;, \u0026#34;ec2:CreateVpcEndpoint\u0026#34;, \u0026#34;ec2:CreateVpcEndpointConnectionNotification\u0026#34;, \u0026#34;ec2:CreateVpcEndpointServiceConfiguration\u0026#34;, \u0026#34;ec2:CreateVpnConnection\u0026#34;, \u0026#34;ec2:CreateVpnConnectionRoute\u0026#34;, \u0026#34;ec2:CreateVpnGateway\u0026#34;, \u0026#34;ec2:DeleteCustomerGateway\u0026#34;, \u0026#34;ec2:DeleteFlowLogs\u0026#34;, \u0026#34;ec2:DeleteInternetGateway\u0026#34;, \u0026#34;ec2:DeleteNetworkInterface\u0026#34;, \u0026#34;ec2:DeleteNetworkInterfacePermission\u0026#34;, \u0026#34;ec2:DeleteRoute\u0026#34;, \u0026#34;ec2:DeleteRouteTable\u0026#34;, \u0026#34;ec2:DeleteSecurityGroup\u0026#34;, \u0026#34;ec2:DeleteSubnet\u0026#34;, \u0026#34;ec2:DeleteSubnetCidrReservation\u0026#34;, \u0026#34;ec2:DeleteTags\u0026#34;, \u0026#34;ec2:DeleteTransitGateway\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayPrefixListReference\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayRoute\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:DeleteVpc\u0026#34;, \u0026#34;ec2:DeleteVpcEndpoints\u0026#34;, \u0026#34;ec2:DeleteVpcEndpointServiceConfigurations\u0026#34;, \u0026#34;ec2:DeleteVpnConnection\u0026#34;, \u0026#34;ec2:DeleteVpnConnectionRoute\u0026#34;, \u0026#34;ec2:Describe*\u0026#34;, \u0026#34;ec2:DetachInternetGateway\u0026#34;, \u0026#34;ec2:DisassociateAddress\u0026#34;, \u0026#34;ec2:DisassociateRouteTable\u0026#34;, \u0026#34;ec2:GetLaunchTemplateData\u0026#34;, \u0026#34;ec2:GetTransitGatewayAttachmentPropagations\u0026#34;, \u0026#34;ec2:ModifyInstanceAttribute\u0026#34;, \u0026#34;ec2:ModifySecurityGroupRules\u0026#34;, \u0026#34;ec2:ModifyTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:ModifyVpcAttribute\u0026#34;, \u0026#34;ec2:ModifyVpcEndpoint\u0026#34;, \u0026#34;ec2:ReleaseAddress\u0026#34;, \u0026#34;ec2:ReplaceRoute\u0026#34;, \u0026#34;ec2:RevokeSecurityGroupEgress\u0026#34;, \u0026#34;ec2:RevokeSecurityGroupIngress\u0026#34;, \u0026#34;ec2:RunInstances\u0026#34;, \u0026#34;ec2:StartInstances\u0026#34;, \u0026#34;ec2:StopInstances\u0026#34;, \u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsEgress\u0026#34;, \u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsIngress\u0026#34;, \u0026#34;iam:AddRoleToInstanceProfile\u0026#34;, \u0026#34;iam:AttachRolePolicy\u0026#34;, \u0026#34;iam:CreateInstanceProfile\u0026#34;, \u0026#34;iam:CreatePolicy\u0026#34;, \u0026#34;iam:CreateRole\u0026#34;, \u0026#34;iam:DeleteInstanceProfile\u0026#34;, \u0026#34;iam:DeletePolicy\u0026#34;, \u0026#34;iam:DeleteRole\u0026#34;, \u0026#34;iam:DeleteRolePolicy\u0026#34;, \u0026#34;iam:DetachRolePolicy\u0026#34;, \u0026#34;iam:GetInstanceProfile\u0026#34;, \u0026#34;iam:GetPolicy\u0026#34;, \u0026#34;iam:GetRole\u0026#34;, \u0026#34;iam:GetRolePolicy\u0026#34;, \u0026#34;iam:ListPolicyVersions\u0026#34;, \u0026#34;iam:ListRoles\u0026#34;, \u0026#34;iam:PassRole\u0026#34;, \u0026#34;iam:PutRolePolicy\u0026#34;, \u0026#34;iam:RemoveRoleFromInstanceProfile\u0026#34;, \u0026#34;lambda:CreateFunction\u0026#34;, \u0026#34;lambda:DeleteFunction\u0026#34;, \u0026#34;lambda:DeleteLayerVersion\u0026#34;, \u0026#34;lambda:GetFunction\u0026#34;, \u0026#34;lambda:GetLayerVersion\u0026#34;, \u0026#34;lambda:InvokeFunction\u0026#34;, \u0026#34;lambda:PublishLayerVersion\u0026#34;, \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:DeleteLogGroup\u0026#34;, \u0026#34;logs:DescribeLogGroups\u0026#34;, \u0026#34;logs:PutRetentionPolicy\u0026#34;, \u0026#34;route53:ChangeTagsForResource\u0026#34;, \u0026#34;route53:CreateHealthCheck\u0026#34;, \u0026#34;route53:CreateHostedZone\u0026#34;, \u0026#34;route53:CreateTrafficPolicy\u0026#34;, \u0026#34;route53:DeleteHostedZone\u0026#34;, \u0026#34;route53:DisassociateVPCFromHostedZone\u0026#34;, \u0026#34;route53:GetHostedZone\u0026#34;, \u0026#34;route53:ListHostedZones\u0026#34;, \u0026#34;route53domains:ListDomains\u0026#34;, \u0026#34;route53domains:ListOperations\u0026#34;, \u0026#34;route53domains:ListTagsForDomain\u0026#34;, \u0026#34;route53resolver:AssociateResolverEndpointIpAddress\u0026#34;, \u0026#34;route53resolver:AssociateResolverRule\u0026#34;, \u0026#34;route53resolver:CreateResolverEndpoint\u0026#34;, \u0026#34;route53resolver:CreateResolverRule\u0026#34;, \u0026#34;route53resolver:DeleteResolverEndpoint\u0026#34;, \u0026#34;route53resolver:DeleteResolverRule\u0026#34;, \u0026#34;route53resolver:DisassociateResolverEndpointIpAddress\u0026#34;, \u0026#34;route53resolver:DisassociateResolverRule\u0026#34;, \u0026#34;route53resolver:GetResolverEndpoint\u0026#34;, \u0026#34;route53resolver:GetResolverRule\u0026#34;, \u0026#34;route53resolver:ListResolverEndpointIpAddresses\u0026#34;, \u0026#34;route53resolver:ListResolverEndpoints\u0026#34;, \u0026#34;route53resolver:ListResolverRuleAssociations\u0026#34;, \u0026#34;route53resolver:ListResolverRules\u0026#34;, \u0026#34;route53resolver:ListTagsForResource\u0026#34;, \u0026#34;route53resolver:UpdateResolverEndpoint\u0026#34;, \u0026#34;route53resolver:UpdateResolverRule\u0026#34;, \u0026#34;s3:AbortMultipartUpload\u0026#34;, \u0026#34;s3:CreateBucket\u0026#34;, \u0026#34;s3:DeleteBucket\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34;, \u0026#34;s3:GetAccountPublicAccessBlock\u0026#34;, \u0026#34;s3:GetBucketAcl\u0026#34;, \u0026#34;s3:GetBucketOwnershipControls\u0026#34;, \u0026#34;s3:GetBucketPolicy\u0026#34;, \u0026#34;s3:GetBucketPolicyStatus\u0026#34;, \u0026#34;s3:GetBucketPublicAccessBlock\u0026#34;, \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:GetObjectVersion\u0026#34;, \u0026#34;s3:GetBucketVersioning\u0026#34;, \u0026#34;s3:ListAccessPoints\u0026#34;, \u0026#34;s3:ListAccessPointsForObjectLambda\u0026#34;, \u0026#34;s3:ListAllMyBuckets\u0026#34;, \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:ListBucketMultipartUploads\u0026#34;, \u0026#34;s3:ListBucketVersions\u0026#34;, \u0026#34;s3:ListJobs\u0026#34;, \u0026#34;s3:ListMultipartUploadParts\u0026#34;, \u0026#34;s3:ListMultiRegionAccessPoints\u0026#34;, \u0026#34;s3:ListStorageLensConfigurations\u0026#34;, \u0026#34;s3:PutAccountPublicAccessBlock\u0026#34;, \u0026#34;s3:PutBucketAcl\u0026#34;, \u0026#34;s3:PutBucketPolicy\u0026#34;, \u0026#34;s3:PutBucketPublicAccessBlock\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;secretsmanager:CreateSecret\u0026#34;, \u0026#34;secretsmanager:DeleteSecret\u0026#34;, \u0026#34;secretsmanager:DescribeSecret\u0026#34;, \u0026#34;secretsmanager:GetSecretValue\u0026#34;, \u0026#34;secretsmanager:ListSecrets\u0026#34;, \u0026#34;secretsmanager:ListSecretVersionIds\u0026#34;, \u0026#34;secretsmanager:PutResourcePolicy\u0026#34;, \u0026#34;secretsmanager:TagResource\u0026#34;, \u0026#34;secretsmanager:UpdateSecret\u0026#34;, \u0026#34;sns:ListTopics\u0026#34;, \u0026#34;ssm:DescribeInstanceProperties\u0026#34;, \u0026#34;ssm:DescribeSessions\u0026#34;, \u0026#34;ssm:GetConnectionStatus\u0026#34;, \u0026#34;ssm:GetParameters\u0026#34;, \u0026#34;ssm:ListAssociations\u0026#34;, \u0026#34;ssm:ResumeSession\u0026#34;, \u0026#34;ssm:StartSession\u0026#34;, \u0026#34;ssm:TerminateSession\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Khởi tạo tài nguyên bằng CloudFormation Trong lab này, chúng ta sẽ dùng N.Virginia region (us-east-1).\nĐể chuẩn bị cho môi trường làm workshop, chúng ta deploy CloudFormation template sau (click link): PrivateLinkWorkshop . Để nguyên các lựa chọn mặc định.\nLựa chọn 2 mục acknowledgement Chọn Create stack Quá trình triển khai CloudFormation cần khoảng 15 phút để hoàn thành.\n2 VPCs đã được tạo 3 EC2s đã được tạo "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/5-workshop/5.3-s3-vpc/5.3.2-test-gwe/","title":"Kiểm tra Gateway Endpoint","tags":[],"description":"","content":"Tạo S3 bucket Đi đến S3 management console Trong Bucket console, chọn Create bucket Trong Create bucket console Đặt tên bucket: chọn 1 tên mà không bị trùng trong phạm vi toàn cầu (gợi ý: lab\u0026lt;số-lab\u0026gt;\u0026lt;tên-bạn\u0026gt;) Giữ nguyên giá trị của các fields khác (default) Kéo chuột xuống và chọn Create bucket Tạo thành công S3 bucket Kết nối với EC2 bằng session manager Trong workshop này, bạn sẽ dùng AWS Session Manager để kết nối đến các EC2 instances. Session Manager là 1 tính năng trong dịch vụ Systems Manager được quản lý hoàn toàn bởi AWS. System manager cho phép bạn quản lý Amazon EC2 instances và các máy ảo on-premises (VMs)thông qua 1 browser-based shell. Session Manager cung cấp khả năng quản lý phiên bản an toàn và có thể kiểm tra mà không cần mở cổng vào, duy trì máy chủ bastion host hoặc quản lý khóa SSH.\nFirst cloud journey Lab để hiểu sâu hơn về Session manager.\nTrong AWS Management Console, gõ Systems Manager trong ô tìm kiếm và nhấn Enter: Từ Systems Manager menu, tìm Node Management ở thanh bên trái và chọn Session Manager: Click Start Session, và chọn EC2 instance tên Test-Gateway-Endpoint. Phiên bản EC2 này đã chạy trong \u0026ldquo;VPC cloud\u0026rdquo; và sẽ được dùng để kiểm tra khả năng kết nối với Amazon S3 thông qua điểm cuối Cổng mà bạn vừa tạo (s3-gwe).\nSession Manager sẽ mở browser tab mới với shell prompt: sh-4.2 $\nBạn đã bắt đầu phiên kết nối đến EC2 trong VPC Cloud thành công. Trong bước tiếp theo, chúng ta sẽ tạo một S3 bucket và một tệp trong đó.\nCreate a file and upload to s3 bucket Đổi về ssm-user\u0026rsquo;s thư mục bằng lệnh \u0026ldquo;cd ~\u0026rdquo; Tạo 1 file để kiểm tra bằng lệnh \u0026ldquo;fallocate -l 1G testfile.xyz\u0026rdquo;, 1 file tên \u0026ldquo;testfile.xyz\u0026rdquo; có kích thước 1GB sẽ được tạo. Tải file mình vừa tạo lên S3 với lệnh \u0026ldquo;aws s3 cp testfile.xyz s3://your-bucket-name\u0026rdquo;. Thay your-bucket-name bằng tên S3 bạn đã tạo. Bạn đã tải thành công tệp lên bộ chứa S3 của mình. Bây giờ bạn có thể kết thúc session.\nKiểm tra object trong S3 bucket Đi đến S3 console. Click tên s3 bucket của bạn Trong Bucket console, bạn sẽ thấy tệp bạn đã tải lên S3 bucket của mình Tóm tắt Chúc mừng bạn đã hoàn thành truy cập S3 từ VPC. Trong phần này, bạn đã tạo gateway endpoint cho Amazon S3 và sử dụng AWS CLI để tải file lên. Quá trình tải lên hoạt động vì gateway endpoint cho phép giao tiếp với S3 mà không cần Internet gateway gắn vào \u0026ldquo;VPC Cloud\u0026rdquo;. Điều này thể hiện chức năng của gateway endpoint như một đường dẫn an toàn đến S3 mà không cần đi qua pub lic Internet.\n"},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/5-workshop/5.4-s3-onprem/5.4.2-create-interface-enpoint/","title":"Tạo một S3 Interface endpoint","tags":[],"description":"","content":"Trong phần này, bạn sẽ tạo và kiểm tra Interface Endpoint S3 bằng cách sử dụng môi trường truyền thống mô phỏng.\nQuay lại Amazon VPC menu. Trong thanh điều hướng bên trái, chọn Endpoints, sau đó click Create Endpoint.\nTrong Create endpoint console:\nĐặt tên interface endpoint Trong Service category, chọn aws services Trong Search box, gõ S3 và nhấn Enter. Chọn endpoint có tên com.amazonaws.us-east-1.s3. Đảm bảo rằng cột Type có giá trị Interface. Đối với VPC, chọn VPC Cloud từ drop-down. Đảm bảo rằng bạn chọn \u0026ldquo;VPC Cloud\u0026rdquo; và không phải \u0026ldquo;VPC On-prem\u0026rdquo;\nMở rộng Additional settings và đảm bảo rằng Enable DNS name không được chọn (sẽ sử dụng điều này trong phần tiếp theo của workshop) Chọn 2 subnets trong AZs sau: us-east-1a and us-east-1b Đối với Security group, chọn SGforS3Endpoint: Giữ default policy - full access và click Create endpoint Chúc mừng bạn đã tạo thành công S3 interface endpoint. Ở bước tiếp theo, chúng ta sẽ kiểm tra interface endpoint.\n"},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/1-worklog/1.10-week10/","title":"Worklog Tuần 10","tags":[],"description":"","content":"Mục tiêu tuần 10: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 10: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/1-worklog/1.11-week11/","title":"Worklog Tuần 11","tags":[],"description":"","content":"Mục tiêu tuần 11: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 11: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/1-worklog/1.12-week12/","title":"Worklog Tuần 12","tags":[],"description":"","content":"Mục tiêu tuần 12: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 11/08/2025 11/08/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 12/08/2025 12/08/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 13/08/2025 13/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 14/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance + Kết nối SSH + Gắn EBS volume 15/08/2025 15/08/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 12: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản:\nCompute Storage Networking Database \u0026hellip; Đã tạo và cấu hình AWS Free Tier account thành công.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web.\nCài đặt và cấu hình AWS CLI trên máy tính bao gồm:\nAccess Key Secret Key Region mặc định \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/3-blogstranslated/","title":"Các bài blogs đã dịch","tags":[],"description":"","content":"Blog 1 - Tăng tốc phát triển Generative AI với MLflow 3.0 được quản lý hoàn toàn trên Amazon SageMaker AI Bài viết giới thiệu MLflow 3.0 được quản lý hoàn toàn trên Amazon SageMaker AI, giúp tăng tốc phát triển Generative AI bằng cách hợp nhất theo dõi thí nghiệm, giám sát hành vi và quản lý vòng đời mô hình trong một công cụ duy nhất. Phiên bản mới bổ sung khả năng tracing và version tracking, cho phép ghi lại input, output, metadata của ứng dụng AI để dễ dàng truy vết lỗi và tối ưu hiệu năng. Với giao diện trực quan và tích hợp sâu với Amazon Bedrock cùng SageMaker HyperPod, MLflow 3.0 giúp nhóm phát triển cải thiện khả năng quan sát, gỡ lỗi và đưa mô hình AI vào sản xuất nhanh hơn, hiệu quả hơn.\nBlog 2 - Ánh xạ Cơ sở hạ tầng Dưới lòng đất được Cải tiến bằng AI trên AWS Bài viết giới thiệu cách S2 Labs, Empact AI, và Kraken Robotics ứng dụng AI kết hợp vật lý trên AWS HPC để cải thiện bản đồ hạ tầng ngầm. Phương pháp này dùng magnetic imaging và deep learning (mô hình U-Net) để tái tạo hình ảnh chính xác các đường ống, bồn chứa dưới lòng đất hoặc đáy biển. Nhờ sức mạnh xử lý song song của AWS Batch, EC2, và S3, hệ thống đạt độ chính xác cao trong phát hiện cấu trúc ngầm sâu đến 40 m, vượt trội hơn các phương pháp truyền thống.\nBlog 3 - Khai mở toàn bộ tiềm năng của Amazon Connect Bài viết chia sẻ cách khai thác tối đa tiềm năng của Amazon Connect, nền tảng trung tâm liên hệ dựa trên AI và AWS. Tác giả nhấn mạnh tầm quan trọng của việc quản trị thay đổi: xác định đúng bên liên quan, có nhà tài trợ cấp lãnh đạo, xây dựng đại sứ thay đổi, và đo lường chỉ số hiệu quả thực tế. Thành công đến từ việc hiểu rõ nhu cầu kinh doanh, đào tạo đúng đối tượng và truyền thông nội bộ tốt. Nếu được triển khai đúng cách, Amazon Connect giúp tối ưu vận hành, tự động hóa và nâng cao trải nghiệm khách hàng.\nBlog 4 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 5 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 6 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\n"},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/5-workshop/5.4-s3-onprem/5.4.3-test-endpoint/","title":"Kiểm tra Interface Endpoint","tags":[],"description":"","content":"Lấy regional DNS name (tên DNS khu vực) của S3 interface endpoint Trong Amazon VPC menu, chọn Endpoints.\nClick tên của endpoint chúng ta mới tạo ở mục 4.2: s3-interface-endpoint. Click details và lưu lại regional DNS name của endpoint (cái đầu tiên) vào text-editor của bạn để dùng ở các bước sau.\nKết nối đến EC2 instance ở trong \u0026ldquo;VPC On-prem\u0026rdquo; (giả lập môi trường truyền thống) Đi đến Session manager bằng cách gõ \u0026ldquo;session manager\u0026rdquo; vào ô tìm kiếm\nClick Start Session, chọn EC2 instance có tên Test-Interface-Endpoint. EC2 instance này đang chạy trên \u0026ldquo;VPC On-prem\u0026rdquo; và sẽ được sử dụng để kiểm tra kết nối đến Amazon S3 thông qua Interface endpoint. Session Manager sẽ mở 1 browser tab mới với shell prompt: sh-4.2 $\nĐi đến ssm-user\u0026rsquo;s home directory với lệnh \u0026ldquo;cd ~\u0026rdquo;\nTạo 1 file tên testfile2.xyz\nfallocate -l 1G testfile2.xyz Copy file vào S3 bucket mình tạo ở section 4.2 aws s3 cp --endpoint-url https://bucket.\u0026lt;Regional-DNS-Name\u0026gt; testfile2.xyz s3://\u0026lt;your-bucket-name\u0026gt; Câu lệnh này yêu cầu thông số \u0026ndash;endpoint-url, bởi vì bạn cần sử dụng DNS name chỉ định cho endpoint để truy cập vào S3 thông qua Interface endpoint. Không lấy \u0026rsquo; * \u0026rsquo; khi copy/paste tên DNS khu vực. Cung cấp tên S3 bucket của bạn Bây giờ tệp đã được thêm vào bộ chứa S3 của bạn. Hãy kiểm tra bộ chứa S3 của bạn trong bước tiếp theo.\nKiểm tra Object trong S3 bucket Đi đến S3 console Click Buckets Click tên bucket của bạn và bạn sẽ thấy testfile2.xyz đã được thêm vào s3 bucket của bạn "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/5-workshop/5.3-s3-vpc/","title":"Truy cập S3 từ VPC","tags":[],"description":"","content":"Sử dụng Gateway endpoint Trong phần này, bạn sẽ tạo một Gateway endpoint để truy cập Amazon S3 từ một EC2 instance. Gateway endpoint sẽ cho phép tải một object lên S3 bucket mà không cần sử dụng Internet Công cộng. Để tạo endpoint, bạn phải chỉ định VPC mà bạn muốn tạo endpoint và dịch vụ (trong trường hợp này là S3) mà bạn muốn thiết lập kết nối.\nNội dung Tạo gateway endpoint Test gateway endpoint "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/4-eventparticipated/","title":"Các events đã tham gia","tags":[],"description":"","content":"Trong quá trình thực tập, em đã tham gia 3 events, với mỗi event là một trải nghiệm đáng nhớ với những kiến thức mới, hay và bổ ích, cùng với đó là nhứng món quà và những khoảnh khắc rất tuyệt vời.\nEvent 1 Tên sự kiện: Vietnam Cloud Day 2025 - Ho Chi Minh City Connect Edition for Builders (Track 1: GenAI \u0026amp; Data)\nThời gian: 09:00 ngày 18/09/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 2 Tên sự kiện: Vòng đời phát triển theo hướng AI: Tái định hình kỹ thuật phần mềm\nThời gian: 14:00 ngày 03/10/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 3 Tên sự kiện: WORKSHOP KHOA HỌC DỮ LIỆU TRÊN AWS\nThời gian: 09:30 ngày 16/10/2025\nĐịa điểm: Đại học FPT, Đường D1, Khu Công nghệ cao, Phường Tăng Nhơn Phú, TP. Hồ Chí Minh.\nVai trò trong sự kiện: Người tham dự\n"},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/5-workshop/5.4-s3-onprem/5.4.4-dns-simulation/","title":"Mô phỏng On-premises DNS ","tags":[],"description":"","content":"AWS PrivateLink endpoint có một địa chỉ IP cố định trong từng AZ nơi chúng được triển khai, trong suốt thời gian tồn tại của endpoint (cho đến khi endpoint bị xóa). Các địa chỉ IP này được gắn vào Elastic network interface (ENI). AWS khuyến nghị sử dụng DNS để resolve địa chỉ IP cho endpoint để các ứng dụng downstream sử dụng địa chỉ IP mới nhất khi ENIs được thêm vào AZ mới hoặc bị xóa theo thời gian.\nTrong phần này, bạn sẽ tạo một quy tắc chuyển tiếp (forwarding rule) để gửi các yêu cầu resolve DNS từ môi trường truyền thống (mô phỏng) đến Private Hosted Zone trên Route 53. Phần này tận dụng cơ sở hạ tầng do CloudFormation triển khai trong phần Chuẩn bị môi trường.\nTạo DNS Alias Records cho Interface endpoint Click link để đi đến Route 53 management console (Hosted Zones section). Mẫu CloudFormation mà bạn triển khai trong phần Chuẩn bị môi trường đã tạo Private Hosted Zone này. Nhấp vào tên của Private Hosted Zone, s3.us-east-1.amazonaws.com: Tạo 1 record mới trong Private Hosted Zone: Giữ nguyên Record name và record type Alias Button: click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Add another record, và add 1 cái record thứ 2 sử dụng những thông số sau: Record name: *. Record type: giữ giá trị default (type A) Alias Button: Click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Create records Record mới xuất hiện trên giao diện Route 53.\nTạo một Resolver Forwarding Rule Route 53 Resolver Forwarding Rules cho phép bạn chuyển tiếp các DNS queries từ VPC của bạn đến các nguồn khác để resolve name. Bên ngoài môi trường workshop, bạn có thể sử dụng tính năng này để chuyển tiếp các DNS queries từ VPC của bạn đến các máy chủ DNS chạy trên on-premises. Trong phần này, bạn sẽ mô phỏng một on-premises conditional forwarder bằng cách tạo một forwarding rule để chuyển tiếp các DNS queries for Amazon S3 đến một Private Hosted Zone chạy trong \u0026ldquo;VPC Cloud\u0026rdquo; để resolve PrivateLink interface endpoint regional DNS name.\nTừ giao diện Route 53, chọn Inbound endpoints trên thanh bên trái\nTrong giao diện Inbound endpoint, Chọn ID của Inbound endpoint.\nSao chép 2 địa chỉ IP trong danh sách vào trình chỉnh sửa. Từ giao diện Route 53, chọn Resolver \u0026gt; Rules và chọn Create rule Trong giao diện Create rule Name: myS3Rule Rule type: Forward Domain name: s3.us-east-1.amazonaws.com VPC: VPC On-prem Outbound endpoint: VPCOnpremOutboundEndpoint Target IP Addresses: điền cả hai IP bạn đã lưu trữ trên trình soạn thảo (inbound endpoint addresses) và sau đó chọn Submit Bạn đã tạo thành công resolver forwarding rule.\nKiểm tra on-premises DNS mô phỏng. Kết nối đến Test-Interface-Endpoint EC2 instance với Session Manager Kiểm tra DNS resolution. Lệnh dig sẽ trả về địa chỉ IP được gán cho VPC endpoint interface đang chạy trên VPC (địa chỉ IP của bạn sẽ khác): dig +short s3.us-east-1.amazonaws.com Các địa chỉ IP được trả về là các địa chỉ IP VPC enpoint, KHÔNG phải là các địa chỉ IP Resolver mà bạn đã dán từ trình chỉnh sửa văn bản của mình. Các địa chỉ IP của Resolver endpoint và VPC endpoin trông giống nhau vì chúng đều từ khối CIDR VPC Cloud.\nTruy cập vào menu VPC (phần Endpoints), chọn S3 interface endpoint. Nhấp vào tab Subnets và xác nhận rằng các địa chỉ IP được trả về bởi lệnh Dig khớp với VPC endpoint: Hãy quay lại shell của bạn và sử dụng AWS CLI để kiểm tra danh sách các bucket S3 của bạn: aws s3 ls --endpoint-url https://s3.us-east-1.amazonaws.com Kết thúc phiên làm việc của Session Manager của bạn: Trong phần này, bạn đã tạo một Interface Endpoint cho Amazon S3. Điểm cuối này có thể được truy cập từ on-premises thông qua Site-to-Site VPN hoặc AWS Direct Connect. Các điểm cuối Route 53 Resolver outbound giả lập chuyển tiếp các yêu cầu DNS từ on-premises đến một Private Hosted Zone đang chạy trên đám mây. Các điểm cuối Route 53 inbound nhận yêu cầu giải quyết và trả về một phản hồi chứa địa chỉ IP của Interface Endpoint VPC. Sử dụng DNS để giải quyết các địa chỉ IP của điểm cuối cung cấp tính sẵn sàng cao trong trường hợp một Availability Zone gặp sự cố.\n"},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/5-workshop/5.4-s3-onprem/","title":"Truy cập S3 từ môi trường truyền thống","tags":[],"description":"","content":"Tổng quan Trong phần này, bạn sẽ tạo một Interface Endpoint để truy cập Amazon S3 từ môi trường truyền thống mô phỏng. Interface Endpoint sẽ cho phép bạn định tuyến đến Amazon S3 qua kết nối VPN từ môi trường truyền thống mô phỏng của bạn.\nTại sao nên sử dụng Interface Endpoint:\nCác Gateway endpoints chỉ hoạt động với các tài nguyên đang chạy trong VPC nơi chúng được tạo. Interface Endpoint hoạt động với tài nguyên chạy trong VPC và cả tài nguyên chạy trong môi trường truyền thống. Khả năng kết nối từ môi trường truyền thống của bạn với aws cloud có thể được cung cấp bởi AWS Site-to-Site VPN hoặc AWS Direct Connect. Interface Endpoint cho phép bạn kết nối với các dịch vụ do AWS PrivateLink cung cấp. Các dịch vụ này bao gồm một số dịch vụ AWS, dịch vụ do các đối tác và khách hàng AWS lưu trữ trong VPC của riêng họ (gọi tắt là Dịch vụ PrivateLink endpoints) và các dịch vụ Đối tác AWS Marketplace. Đối với workshop này, chúng ta sẽ tập trung vào việc kết nối với Amazon S3. "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/5-workshop/5.5-policy/","title":"VPC Endpoint Policies","tags":[],"description":"","content":"Khi bạn tạo một Interface Endpoint hoặc cổng, bạn có thể đính kèm một chính sách điểm cuối để kiểm soát quyền truy cập vào dịch vụ mà bạn đang kết nối. Chính sách VPC Endpoint là chính sách tài nguyên IAM mà bạn đính kèm vào điểm cuối. Nếu bạn không đính kèm chính sách khi tạo điểm cuối, thì AWS sẽ đính kèm chính sách mặc định cho bạn để cho phép toàn quyền truy cập vào dịch vụ thông qua điểm cuối.\nBạn có thể tạo chính sách chỉ hạn chế quyền truy cập vào các S3 bucket cụ thể. Điều này hữu ích nếu bạn chỉ muốn một số Bộ chứa S3 nhất định có thể truy cập được thông qua điểm cuối.\nTrong phần này, bạn sẽ tạo chính sách VPC Endpoint hạn chế quyền truy cập vào S3 bucket được chỉ định trong chính sách VPC Endpoint.\nKết nối tới EC2 và xác minh kết nối tới S3. Bắt đầu một phiên AWS Session Manager mới trên máy chủ có tên là Test-Gateway-Endpoint. Từ phiên này, xác minh rằng bạn có thể liệt kê nội dung của bucket mà bạn đã tạo trong Phần 1: Truy cập S3 từ VPC. aws s3 ls s3://\u0026lt;your-bucket-name\u0026gt; Nội dung của bucket bao gồm hai tệp có dung lượng 1GB đã được tải lên trước đó.\nTạo một bucket S3 mới; tuân thủ mẫu đặt tên mà bạn đã sử dụng trong Phần 1, nhưng thêm \u0026lsquo;-2\u0026rsquo; vào tên. Để các trường khác là mặc định và nhấp vào Create. Tạo bucket thành công. Policy mặc định cho phép truy cập vào tất cả các S3 Buckets thông qua VPC endpoint.\nTrong giao diện Edit Policy, sao chép và dán theo policy sau, thay thế yourbucketname-2 với tên bucket thứ hai của bạn. Policy này sẽ cho phép truy cập đến bucket mới thông qua VPC endpoint, nhưng không cho phép truy cập đến các bucket còn lại. Chọn Save để kích hoạt policy. { \u0026#34;Id\u0026#34;: \u0026#34;Policy1631305502445\u0026#34;, \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;Stmt1631305501021\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:*\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::yourbucketname-2\u0026#34;, \u0026#34;arn:aws:s3:::yourbucketname-2/*\u0026#34; ], \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34; } ] } Cấu hình policy thành công.\nTừ session của bạn trên Test-Gateway-Endpoint instance, kiểm tra truy cập đến S3 bucket bạn tạo ở bước đầu aws s3 ls s3://\u0026lt;yourbucketname\u0026gt; Câu lệnh trả về lỗi bởi vì truy cập vào S3 bucket không có quyền trong VPC endpoint policy.\nTrở lại home directory của bạn trên EC2 instance cd~ Tạo file fallocate -l 1G test-bucket2.xyz Sao chép file lên bucket thứ 2 aws s3 cp test-bucket2.xyz s3://\u0026lt;your-2nd-bucket-name\u0026gt; Thao tác này được cho phép bởi VPC endpoint policy.\nSau đó chúng ta kiểm tra truy cập vào S3 bucket đầu tiên\naws s3 cp test-bucket2.xyz s3://\u0026lt;your-1st-bucket-name\u0026gt;\nCâu lệnh xảy ra lỗi bởi vì bucket không có quyền truy cập bởi VPC endpoint policy.\nTrong phần này, bạn đã tạo chính sách VPC Endpoint cho Amazon S3 và sử dụng AWS CLI để kiểm tra chính sách. Các hoạt động AWS CLI liên quan đến bucket S3 ban đầu của bạn thất bại vì bạn áp dụng một chính sách chỉ cho phép truy cập đến bucket thứ hai mà bạn đã tạo. Các hoạt động AWS CLI nhắm vào bucket thứ hai của bạn thành công vì chính sách cho phép chúng. Những chính sách này có thể hữu ích trong các tình huống khi bạn cần kiểm soát quyền truy cập vào tài nguyên thông qua VPC Endpoint.\n"},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/5-workshop/","title":"Workshop","tags":[],"description":"","content":"Đảm bảo truy cập Hybrid an toàn đến S3 bằng cách sử dụng VPC endpoint Tổng quan AWS PrivateLink cung cấp kết nối riêng tư đến các dịch vụ aws từ VPCs hoặc trung tâm dữ liệu (on-premise) mà không làm lộ lưu lượng truy cập ra ngoài public internet.\nTrong bài lab này, chúng ta sẽ học cách tạo, cấu hình, và kiểm tra VPC endpoints để cho phép workload của bạn tiếp cận các dịch vụ AWS mà không cần đi qua Internet công cộng.\nChúng ta sẽ tạo hai loại endpoints để truy cập đến Amazon S3: gateway vpc endpoint và interface vpc endpoint. Hai loại vpc endpoints này mang đến nhiều lợi ích tùy thuộc vào việc bạn truy cập đến S3 từ môi trường cloud hay từ trung tâm dữ liệu (on-premise).\nGateway - Tạo gateway endpoint để gửi lưu lượng đến Amazon S3 hoặc DynamoDB using private IP addresses. Bạn điều hướng lưu lượng từ VPC của bạn đến gateway endpoint bằng các bảng định tuyến (route tables) Interface - Tạo interface endpoint để gửi lưu lượng đến các dịch vụ điểm cuối (endpoints) sử dụng Network Load Balancer để phân phối lưu lượng. Lưu lượng dành cho dịch vụ điểm cuối được resolved bằng DNS. Nội dung Tổng quan về workshop Chuẩn bị Truy cập đến S3 từ VPC Truy cập đến S3 từ TTDL On-premises VPC Endpoint Policies (làm thêm) Dọn dẹp tài nguyên "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/5-workshop/5.6-cleanup/","title":"Dọn dẹp tài nguyên","tags":[],"description":"","content":"Dọn dẹp tài nguyên Xin chúc mừng bạn đã hoàn thành xong lab này! Trong lab này, bạn đã học về các mô hình kiến trúc để truy cập Amazon S3 mà không sử dụng Public Internet.\nBằng cách tạo Gateway endpoint, bạn đã cho phép giao tiếp trực tiếp giữa các tài nguyên EC2 và Amazon S3, mà không đi qua Internet Gateway. Bằng cách tạo Interface endpoint, bạn đã mở rộng kết nối S3 đến các tài nguyên chạy trên trung tâm dữ liệu trên chỗ của bạn thông qua AWS Site-to-Site VPN hoặc Direct Connect. Dọn dẹp Điều hướng đến Hosted Zones trên phía trái của bảng điều khiển Route 53. Nhấp vào tên của s3.us-east-1.amazonaws.com zone. Nhấp vào Delete và xác nhận việc xóa bằng cách nhập từ khóa \u0026ldquo;delete\u0026rdquo;. Disassociate Route 53 Resolver Rule - myS3Rule from \u0026ldquo;VPC Onprem\u0026rdquo; and Delete it. 4.Mở console của CloudFormation và xóa hai stack CloudFormation mà bạn đã tạo cho bài thực hành này:\nPLOnpremSetup PLCloudSetup Xóa các S3 bucket Mở bảng điều khiển S3 Chọn bucket chúng ta đã tạo cho lab, nhấp chuột và xác nhận là empty. Nhấp Delete và xác nhận delete. "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/6-self-evaluation/","title":"Tự đánh giá","tags":[],"description":"","content":"Trong suốt thời gian thực tập tại [Tên công ty/tổ chức] từ [ngày bắt đầu] đến [ngày kết thúc], tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế.\nTôi đã tham gia [mô tả ngắn gọn dự án hoặc công việc chính], qua đó cải thiện kỹ năng [liệt kê kỹ năng: lập trình, phân tích, viết báo cáo, giao tiếp…].\nVề tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ nội quy, và tích cực trao đổi với đồng nghiệp để nâng cao hiệu quả công việc.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ✅ ☐ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ☐ ☐ ✅ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ☐ ✅ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Cần cải thiện Nâng cao tính kỹ luật, chấp hành nghiêm chỉnh nội quy của công ty hoặc bất kỳ trong một tổ chức nào Cải thiện trong cách tư duy giải quyết vấn đề Học cách giao tiếp tốt hơn trong giao tiếp hằng ngày và trong công việc, xử lý tình huống "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/7-feedback/","title":"Chia sẻ, đóng góp ý kiến","tags":[],"description":"","content":" Tại đây bạn có thể tự do đóng góp ý kiến cá nhân về những trải nghiệm khi tham gia chương trình First Cloud Journey, giúp team FCJ cải thiện những vấn đề còn thiếu sót dựa trên các hạng mục sau:\nĐánh giá chung 1. Môi trường làm việc\nMôi trường làm việc rất thân thiện và cởi mở. Các thành viên trong FCJ luôn sẵn sàng hỗ trợ khi mình gặp khó khăn, kể cả ngoài giờ làm việc. Không gian làm việc gọn gàng, thoải mái, giúp mình tập trung tốt hơn. Tuy nhiên, mình nghĩ có thể bổ sung thêm một số buổi giao lưu hoặc team bonding để mọi người hiểu nhau hơn.\n2. Sự hỗ trợ của mentor / team admin\nMentor hướng dẫn rất chi tiết, giải thích rõ ràng khi mình chưa hiểu và luôn khuyến khích mình đặt câu hỏi. Team admin hỗ trợ các thủ tục, tài liệu và tạo điều kiện để mình làm việc thuận lợi. Mình đánh giá cao việc mentor cho phép mình thử và tự xử lý vấn đề thay vì chỉ đưa đáp án.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nCông việc mình được giao phù hợp với kiến thức mình đã học ở trường, đồng thời mở rộng thêm những mảng mới mà mình chưa từng được tiếp cận. Nhờ vậy, mình vừa củng cố kiến thức nền tảng, vừa học thêm kỹ năng thực tế.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình học được nhiều kỹ năng mới như sử dụng công cụ quản lý dự án, kỹ năng làm việc nhóm, và cả cách giao tiếp chuyên nghiệp trong môi trường công ty. Mentor cũng chia sẻ nhiều kinh nghiệm thực tế giúp mình định hướng tốt hơn cho sự nghiệp.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa công ty rất tích cực: mọi người tôn trọng lẫn nhau, làm việc nghiêm túc nhưng vẫn vui vẻ. Khi có dự án gấp, mọi người cùng nhau cố gắng, hỗ trợ không phân biệt vị trí. Điều này giúp mình cảm thấy mình là một phần của tập thể, dù chỉ là thực tập sinh.\n6. Chính sách / phúc lợi cho thực tập sinh\nCông ty có hỗ trợ phụ cấp thực tập và tạo điều kiện về thời gian linh hoạt khi cần thiết. Ngoài ra, việc được tham gia các buổi đào tạo nội bộ là một điểm cộng lớn.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập? Điều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau? Nếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao? Đề xuất \u0026amp; mong muốn Bạn có đề xuất gì để cải thiện trải nghiệm trong kỳ thực tập? Bạn có muốn tiếp tục chương trình này trong tương lai? Góp ý khác (tự do chia sẻ): "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/tags/","title":"Tags","tags":[],"description":"","content":""}]