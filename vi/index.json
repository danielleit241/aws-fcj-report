[{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/","title":"Báo cáo thực tập","tags":[],"description":"","content":"Báo cáo thực tập Thông tin sinh viên: Họ và tên: Lê Vũ Phương Hòa\nSố điện thoại: 0327 030 024\nEmail: danielleee241@gmail.com\nTrường: Đại học FPT TP.HCM\nNgành: Công nghệ thông tin\nLớp: SE181951\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 12/08/2025 đến ngày 12/12/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":"Tăng tốc phát triển Generative AI với MLflow 3.0 được quản lý hoàn toàn trên Amazon SageMaker AI Bởi Ram Vittal, Amit Modi, Rahul Easwar, and Sandeep Raveesh-Babu on 10 JUL 2025 in Amazon SageMaker AI, Announcements, Technical How-to\nAmazon SageMaker hiện cung cấp hỗ trợ MLflow 3.0 được quản lý hoàn toàn, giúp đơn giản hóa quá trình thử nghiệm AI và tăng tốc hành trình Generative AI của bạn từ ý tưởng đến triển khai sản xuất. Bản phát hành này biến managed MLflow từ công cụ theo dõi thí nghiệm thành giải pháp end-to-end observability, rút ngắn thời gian đưa Generative AI ra thị trường.\nKhi khách hàng ở nhiều ngành khác nhau tăng tốc phát triển Generative AI, họ cần khả năng theo dõi thí nghiệm, quan sát hành vi và đánh giá hiệu suất của models và AI applications. Các data scientists và developers gặp khó khăn trong việc phân tích hiệu quả của models và AI applications từ giai đoạn thử nghiệm đến sản xuất, gây khó khăn trong việc tìm nguyên nhân và khắc phục sự cố. Các nhóm dành nhiều thời gian tích hợp công cụ thay vì nâng cao chất lượng của models hoặc generative AI applications.\nVới việc ra mắt fully managed MLflow 3.0 trên Amazon SageMaker AI, bạn có thể tăng tốc phát triển Generative AI bằng cách dễ dàng theo dõi thí nghiệm và quan sát hành vi của models và AI applications chỉ bằng một công cụ duy nhất. Tracing capabilities trong MLflow 3.0 cho phép khách hàng ghi lại inputs, outputs, metadata ở mọi bước trong ứng dụng Generative AI, giúp developers nhanh chóng xác định nguồn gốc của lỗi hoặc hành vi bất thường. Bằng cách duy trì lịch sử của từng phiên bản model và ứng dụng, MLflow 3.0 cung cấp khả năng traceability, giúp kết nối phản hồi AI với các thành phần gốc. Điều này cho phép developers nhanh chóng truy vết sự cố trực tiếp đến code, data, hoặc parameters đã tạo ra nó.\nVới các khả năng này, khách hàng sử dụng Amazon SageMaker HyperPod để train và deploy foundation models (FMs) giờ đây có thể dùng managed MLflow để theo dõi thí nghiệm, giám sát quá trình training, có insight sâu hơn về hành vi models và AI applications, và quản lý ML lifecycle ở quy mô lớn. Điều này giảm thời gian khắc phục sự cố và giúp các nhóm tập trung nhiều hơn vào đổi mới.\nBài viết này sẽ giới thiệu các khái niệm cốt lõi của fully managed MLflow 3.0 trên SageMaker và cung cấp hướng dẫn kỹ thuật để bạn khai thác các tính năng mới, giúp tăng tốc phát triển ứng dụng Generative AI tiếp theo.\nBắt đầu Bạn có thể bắt đầu với MLflow 3.0 được quản lý hoàn toàn trên Amazon SageMaker để theo dõi thí nghiệm, quản lý models, và tối ưu hóa vòng đời Generative AI/ML thông qua AWS Management Console, AWS CLI, hoặc API.\nĐiều kiện cần thiết Để bắt đầu, bạn cần:\nMột AWS account đã bật billing\nMột Amazon SageMaker Studio AI domain (xem hướng dẫn: Guide to getting set up with Amazon SageMaker AI)\nCấu hình môi trường của bạn để sử dụng Máy chủ theo dõi MLflow do SageMaker quản lý Các bước cấu hình: 1. Trong SageMaker Studio UI, ở bảng Applications, chọn MLflow → Create.\n2. Nhập tên duy nhất cho tracking server và chỉ định Amazon S3 URI nơi lưu trữ experiment artifacts. Chọn Create. (Mặc định SageMaker sẽ chọn MLflow v3.0).\n3. Tuỳ chọn: chọn Update để điều chỉnh cài đặt như server size, tags, IAM role.\nMáy chủ sẽ được cấp phát và khởi động tự động, thường mất khoảng 25 phút. Sau khi thiết lập xong, bạn có thể khởi chạy MLflow UI từ SageMaker Studio để bắt đầu tracking các thí nghiệm ML và Generative AI. Để biết thêm chi tiết về cấu hình tracking server, tham khảo Machine learning experiments using Amazon SageMaker AI with MLflow trong SageMaker Developer Guide.\nĐể bắt đầu tracking các thí nghiệm của bạn với SageMaker managed MLflow tracking server vừa tạo, bạn cần cài đặt cả MLflow và gói AWS SageMaker MLflow Python trong môi trường của bạn. Bạn có thể sử dụng SageMaker Studio managed Jupyter Lab, SageMaker Studio Code Editor, một môi trường phát triển tích hợp (IDE) cục bộ, hoặc môi trường khác có hỗ trợ AI workloads để tracking với SageMaker managed MLflow tracking server.\nĐể cài đặt cả hai gói Python bằng lệnh pip:\npip install mlflow==3.0 sagemaker-mlflow==0.1.0\nĐể kết nối và bắt đầu ghi log các thí nghiệm AI, tham số, và mô hình của bạn trực tiếp lên managed MLflow trên SageMaker, hãy thay thế Amazon Resource Name (ARN) của SageMaker MLflow tracking server của bạn:\nimport mlflow # SageMaker MLflow ARN tracking_server_arn = \u0026#34;arn:aws:sagemaker:\u0026lt;Region\u0026gt;:\u0026lt;Account_id\u0026gt;:mlflow-tracking-server/\u0026lt;Name\u0026gt;\u0026#34; # Enter ARN mlflow.set_tracking_uri(tracking_server_arn) mlflow.set_experiment(\u0026#34;customer_support_genai_app\u0026#34;) Bây giờ môi trường của bạn đã được cấu hình và sẵn sàng để tracking các thí nghiệm với SageMaker Managed MLflow tracking server.\nTriển khai tracing và version tracking cho ứng dụng Generative AI Các ứng dụng Generative AI có nhiều thành phần, bao gồm code, cấu hình và dữ liệu, điều này có thể trở nên khó quản lý nếu không có versioning một cách hệ thống. Một thực thể LoggedModel trong managed MLflow 3.0 đại diện cho mô hình AI, agent, hoặc ứng dụng Generative AI của bạn trong một experiment. Nó cung cấp khả năng tracking thống nhất các model artifacts, execution traces, evaluation metrics và metadata trong suốt vòng đời phát triển. Một trace là bản ghi log của input, output và các bước trung gian từ một lần thực thi ứng dụng. Traces mang lại cái nhìn sâu về hiệu suất ứng dụng, luồng thực thi, và chất lượng phản hồi, giúp debugging và đánh giá. Với LoggedModel, bạn có thể tracking và so sánh các phiên bản khác nhau của ứng dụng, giúp dễ dàng xác định vấn đề, triển khai phiên bản tốt nhất, và duy trì hồ sơ rõ ràng về những gì đã được triển khai và khi nào.\nĐể triển khai version tracking và tracing với managed MLflow 3.0 trên SageMaker, bạn có thể thiết lập một danh tính model có version bằng cách sử dụng Git commit hash, đặt nó làm active model context để tất cả các trace sau đó sẽ tự động liên kết với phiên bản cụ thể này, bật tính năng automatic logging cho các tương tác với Amazon Bedrock, và sau đó thực hiện một API call tới Claude 3.5 Sonnet của Anthropic, lệnh gọi này sẽ được tracing đầy đủ với input, output và metadata được tự động ghi lại trong model context đã thiết lập. Managed MLflow 3.0 tracing đã được tích hợp sẵn với nhiều thư viện Generative AI khác nhau và cung cấp trải nghiệm tracing tự động chỉ với một dòng lệnh cho tất cả các thư viện được hỗ trợ. Để biết thêm thông tin về các thư viện được hỗ trợ, hãy tham khảo Supported Integrations trong MLflow documentation.\n# 1. Define your application version using the git commit logged_model= \u0026#34;customer_support_agent\u0026#34; logged_model_name = f\u0026#34;{logged_model}-{git_commit}\u0026#34; # 2.Set the active model context - traces will be linked to this mlflow.set_active_model(name=logged_model_name) # 3.Set auto logging for your model provider mlflow.bedrock.autolog() # 4. Chat with your LLM provider # Ensure that your boto3 client has the necessary auth information bedrock = boto3.client( service_name=\u0026#34;bedrock-runtime\u0026#34;, region_name=\u0026#34;\u0026lt;REPLACE_WITH_YOUR_AWS_REGION\u0026gt;\u0026#34;, ) model = \u0026#34;anthropic.claude-3-5-sonnet-20241022-v2:0\u0026#34; messages = [{ \u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: [{\u0026#34;text\u0026#34;: \u0026#34;Hello!\u0026#34;}]}] # All intermediate executions within the chat session will be logged bedrock.converse(modelId=model, messages=messages) Sau khi ghi lại thông tin này, bạn có thể theo dõi các thí nghiệm Generative AI và LoggedModel cho agent trong Managed MLflow 3.0 tracking server UI, như minh họa trong ảnh chụp màn hình sau.\nBên cạnh chức năng one-line auto tracing, MLflow cung cấp Python SDK để bạn có thể thủ công instrument code và thao tác với các trace. Tham khảo notebook mẫu sagemaker_mlflow_strands.ipynb trong kho aws-samples GitHub repository, nơi chúng tôi sử dụng MLflow manual instrumentation để trace Strands Agents. Với khả năng tracing trong fully managed MLflow 3.0, bạn có thể ghi lại inputs, outputs, và metadata liên quan đến từng bước trung gian của một request, từ đó dễ dàng xác định nguồn gốc của lỗi và các hành vi bất ngờ.\nNhững khả năng này mang lại observability cho workload AI của bạn bằng cách thu thập thông tin chi tiết về quá trình thực thi của các workload services, nodes, và tools, và bạn có thể quan sát dưới tab Traces.\nBạn có thể kiểm tra từng trace, như minh họa trong hình dưới đây, bằng cách chọn request ID trong tab traces cho trace mà bạn muốn xem.\nMLflow 3.0 được quản lý toàn diện trên Amazon SageMaker cũng giới thiệu khả năng gắn thẻ cho traces. Tags là các cặp khóa-giá trị có thể thay đổi mà bạn có thể gắn vào traces để bổ sung metadata và ngữ cảnh giá trị. Trace tags giúp việc tổ chức, tìm kiếm, và lọc traces trở nên đơn giản dựa trên các tiêu chí như phiên người dùng, môi trường, phiên bản mô hình, hoặc đặc tính hiệu năng. Bạn có thể thêm, cập nhật, hoặc xóa tags ở bất kỳ giai đoạn nào—trong khi thực thi trace bằng cách sử dụng mlflow.update_current_trace() hoặc sau khi một trace đã được ghi log thông qua MLflow APIs hoặc UI.\nManaged MLflow 3.0 làm cho việc tìm kiếm và phân tích traces trở nên liền mạch, giúp các nhóm nhanh chóng xác định vấn đề, so sánh hành vi của agent, và tối ưu hóa hiệu năng. Giao diện người dùng tracing và Python API đều hỗ trợ tính năng lọc mạnh mẽ, vì vậy bạn có thể đi sâu vào traces dựa trên các thuộc tính như trạng thái, tags, người dùng, môi trường, hoặc thời gian thực thi như được minh họa trong ảnh chụp màn hình bên dưới.\nVí dụ, bạn có thể ngay lập tức tìm tất cả traces có lỗi, lọc theo môi trường production, hoặc tìm traces từ một request cụ thể. Khả năng này rất quan trọng cho việc gỡ lỗi, phân tích chi phí, và cải tiến liên tục của các ứng dụng Generative AI.\nẢnh chụp màn hình sau đây hiển thị các dấu vết được trả về khi tìm kiếm thẻ ‘Production’.\nĐoạn mã sau đây cho thấy cách bạn có thể sử dụng chức năng tìm kiếm tất cả traces trong môi trường production với trạng thái thành công:\n# Search for traces in production environment with successful status\ntraces = mlflow.search_traces( filter_string=\u0026ldquo;attributes.status = \u0026lsquo;OK\u0026rsquo; AND tags.environment = \u0026lsquo;production\u0026rsquo;\u0026rdquo;)\nHướng dẫn sử dụng AI tạo sinh với tính năng theo dõi MLflow Việc xây dựng và triển khai các generative AI agents như chat-based assistants, code generators hoặc customer support assistants đòi hỏi khả năng quan sát sâu về cách các agent này tương tác với large language models (LLMs) và các công cụ bên ngoài. Trong một quy trình agentic workflow điển hình, agent sẽ lặp qua các bước reasoning, gọi LLMs và sử dụng các công cụ hoặc hệ thống con như search APIs hoặc Model Context Protocol (MCP) servers cho đến khi hoàn thành tác vụ của người dùng. Những tương tác phức tạp, nhiều bước này khiến việc debugging, tối ưu hóa và theo dõi chi phí trở nên đặc biệt thách thức.\nCác công cụ observability truyền thống trở nên thiếu hiệu quả trong generative AI vì các quyết định của agent, các lệnh gọi tool, và phản hồi từ LLM đều mang tính động và phụ thuộc vào ngữ cảnh. Managed MLflow 3.0 tracing cung cấp khả năng quan sát toàn diện bằng cách ghi lại mọi lần gọi LLM, tool invocation, và decision point trong workflow của agent. Bạn có thể sử dụng dữ liệu trace end-to-end này để:\nDebug agent behavior – Xác định chính xác nơi reasoning của agent bị lệch hướng hoặc lý do tại sao nó tạo ra output bất ngờ.\nMonitor tool usage – Khám phá cách và thời điểm các external tools được gọi, đồng thời phân tích tác động của chúng đến chất lượng và chi phí.\nTrack performance and cost – Đo lường latency, token usage và chi phí API ở mỗi bước của agentic loop.\nAudit and govern – Duy trì logs chi tiết để phục vụ compliance và phân tích.\nHãy tưởng tượng một kịch bản thực tế sử dụng managed MLflow 3.0 tracing UI cho một finance customer support agent mẫu, được trang bị một công cụ để truy xuất dữ liệu tài chính từ datastore. Trong khi bạn đang phát triển một generative AI customer support agent hoặc phân tích hành vi của agent trong production, bạn có thể quan sát cách phản hồi của agent và việc thực thi có thể (hoặc không) gọi đến product database tool để đưa ra khuyến nghị chính xác hơn.\nVí dụ minh họa: trace đầu tiên (hiển thị trong screenshot bên dưới) cho thấy agent xử lý một user query mà không gọi bất kỳ tool nào. Trace ghi lại prompt, agent response và các decision points của agent. Phản hồi của agent thiếu chi tiết cụ thể về sản phẩm. Trace cho thấy rõ ràng rằng không có external tool nào được gọi, và bạn nhanh chóng nhận ra hành vi này trong reasoning chain của agent.\nTrace thứ hai (hiển thị trong screenshot bên dưới) ghi lại cùng một agent, nhưng lần này agent quyết định gọi product database tool. Trace này log lại tool invocation, dữ liệu sản phẩm được trả về, và cách agent tích hợp thông tin này vào phản hồi cuối cùng. Tại đây, bạn có thể quan sát thấy chất lượng câu trả lời được cải thiện, độ trễ (latency) tăng nhẹ, và chi phí API bổ sung do mức sử dụng token cao hơn.\nBằng cách so sánh các trace này song song, bạn có thể debug lý do vì sao agent đôi khi bỏ qua việc sử dụng tool, tối ưu hóa thời điểm và cách thức gọi tool, đồng thời cân bằng giữa chất lượng với latency và chi phí. Tracing UI của MLflow giúp các agentic loops trở nên minh bạch, dễ hành động, và liền mạch để phân tích ở quy mô lớn. Agent mẫu trong bài viết này cùng với toàn bộ mã nguồn cần thiết đều có sẵn trên aws-samples GitHub repository, nơi bạn có thể tái tạo và điều chỉnh cho các ứng dụng của riêng mình.\nDọn dẹp tài nguyên Sau khi được tạo, một SageMaker managed MLflow tracking server sẽ phát sinh chi phí cho đến khi bạn xóa hoặc dừng nó. Việc tính phí cho tracking server dựa trên thời gian máy chủ chạy, kích thước được chọn, và lượng dữ liệu được log vào tracking server. Bạn có thể dừng tracking server khi không sử dụng để tiết kiệm chi phí, hoặc có thể xóa chúng bằng API hoặc SageMaker Studio UI. Để biết thêm chi tiết về giá, hãy tham khảo Amazon SageMaker pricing.\nKết luận Fully managed MLflow 3.0 on Amazon SageMaker AI hiện đã khả dụng. Hãy bắt đầu với sample code trong aws-samples GitHub repository. Chúng tôi mời bạn khám phá tính năng mới này và trải nghiệm sự hiệu quả cũng như khả năng kiểm soát nâng cao mà nó mang lại cho các dự án ML của bạn. Để tìm hiểu thêm, hãy truy cập Machine Learning Experiments using Amazon SageMaker with MLflow.\nĐể biết thêm thông tin, hãy tham khảo SageMaker Developer Guide và gửi phản hồi đến AWS re:Post for SageMaker hoặc thông qua kênh AWS Support thông thường của bạn.\nThông tin về các tác giả Ram Vittal Ram Vittal là Kiến trúc sư Giải pháp ML Chính (Principal ML Solutions Architect) tại AWS. Ông có hơn 3 thập kỷ kinh nghiệm trong việc kiến trúc và xây dựng các ứng dụng phân tán, lai (hybrid) và đám mây. Ông đam mê xây dựng các giải pháp AI/ML và dữ liệu lớn an toàn, có khả năng mở rộng và đáng tin cậy để giúp các khách hàng doanh nghiệp trong hành trình áp dụng và tối ưu hóa đám mây nhằm cải thiện kết quả kinh doanh. Trong thời gian rảnh, ông lái xe mô tô và đi dạo cùng chú chó sheep-a-doodle ba tuổi của mình! Sandeep Raveesh Sandeep Raveesh là Kiến trúc sư Giải pháp Chuyên gia GenAI (GenAI Specialist Solutions Architect) tại AWS. Anh làm việc với khách hàng trong suốt hành trình AIOps của họ, bao gồm đào tạo mô hình, Tạo sinh Tăng cường Truy xuất (RAG), Tác tử GenAI (GenAI Agents) và mở rộng quy mô các trường hợp sử dụng GenAI. Anh cũng tập trung vào các chiến lược Go-To-Market giúp AWS xây dựng và điều chỉnh các sản phẩm để giải quyết các thách thức của ngành trong lĩnh vực Trí tuệ Nhân tạo Tạo sinh (Generative AI). Bạn có thể tìm thấy Sandeep trên LinkedIn. Amit Modi Amit Modi là Trưởng bộ phận Sản phẩm cho SageMaker AIOps và Quản trị (Governance), cùng với AI có trách nhiệm (Responsible AI) tại AWS. Với hơn một thập kỷ kinh nghiệm trong lĩnh vực B2B, ông đã xây dựng các sản phẩm và đội ngũ có khả năng mở rộng, thúc đẩy đổi mới và mang lại giá trị cho khách hàng trên toàn cầu. Rahul Easwar Rahul Easwar là Giám đốc Sản phẩm Cấp cao (Senior Product Manager) tại AWS, dẫn dắt mảng MLflow được quản lý và Ứng dụng AI Đối tác (Partner AI Apps) trong nhóm SageMaker AIOps. Với hơn 15 năm kinh nghiệm từ các công ty khởi nghiệp đến công nghệ doanh nghiệp, anh tận dụng nền tảng khởi nghiệp và bằng MBA từ Chicago Booth để xây dựng các nền tảng ML có khả năng mở rộng, giúp đơn giản hóa việc áp dụng AI cho các tổ chức trên toàn thế giới. Kết nối với Rahul trên LinkedIn để tìm hiểu thêm về công việc của anh trong lĩnh vực nền tảng ML và các giải pháp AI cho doanh nghiệp. "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/3-blogstranslated/3.2-blog2/","title":"Blog 2","tags":[],"description":"","content":"Ánh xạ Cơ sở hạ tầng Dưới lòng đất được Cải tiến bằng AI trên AWS Bởi: Santi Adavani, Jacques Guigne, Ryan Qi, Souvik Mukherjee, Srinivas Tadepalli, và Vidyasagar Ananthan, 13/05/2025, AWS Batch, AWS ParallelCluster, Customer Solutions, High Performance Computing, Thought Leadership\nSubsurface infrastructure mapping là quá trình xác định và trực quan hóa các cấu trúc bị chôn vùi như đường ống, cáp, bồn chứa, và nền móng tồn tại bên dưới bề mặt mà không cần khai quật. Công nghệ này rất quan trọng trong quy hoạch đô thị, bảo trì tiện ích, vận hành dầu khí, an toàn xây dựng và bảo vệ môi trường. Không có bản đồ hạ tầng ngầm chính xác, các dự án xây dựng có nguy cơ bị trì hoãn tốn kém, va chạm nguy hiểm với tiện ích, và gây hại môi trường. Ví dụ, khi bão Ivan làm hỏng một giàn khoan dầu ngoài khơi năm 2004, nó để lại hạ tầng quan trọng bị chôn dưới 35–45 mét trầm tích, tạo ra mối nguy vô hình mà các kỹ thuật bản đồ truyền thống không thể phát hiện đầy đủ.\nNhờ sự hợp tác giữa S2 Labs, Empact AI và Kraken Robotics, một bước đột phá trong subsurface infrastructure mapping đã xuất hiện trên AWS. Cách tiếp cận này kết hợp magnetic imaging tiên tiến với physics-informed AI, mang lại hình ảnh rõ nét chưa từng có về các cấu trúc ngầm – đặc biệt trong điều kiện mà phương pháp truyền thống thất bại. Sự kết hợp sức mạnh cloud computing và AI đang thay đổi cách ngành công nghiệp hình dung và hiểu về hạ tầng ngầm quan trọng.\nPhương pháp phát hiện dưới bề mặt và những hạn chế Hình ảnh dưới bề mặt truyền thống sử dụng nhiều kỹ thuật địa vật lý khác nhau, mỗi kỹ thuật phù hợp với những loại vật liệu và điều kiện cụ thể. Ví dụ, electromagnetic methods phát hiện các đường ống kim loại và cáp thông qua độ dẫn điện của chúng, trong khi magnetometers đo sự biến thiên của từ trường Trái Đất để xác định các vật liệu có từ tính như ống thép. Ground-penetrating radar (GPR) đặc biệt hiệu quả trong việc tạo ảnh các công trình bê tông và các cấu trúc địa chất, và các tần số chuyên dụng có thể phát hiện các đường ống nhựa hoặc tài sản chứa nước nhờ vào đặc tính điện môi của chúng.\nViệc diễn giải thủ công dữ liệu hình ảnh thường chỉ bao gồm phân tích tín hiệu địa vật lý 2D và tính toán độ sâu cơ bản – nhanh nhưng chỉ mang tính xấp xỉ. Có hai thách thức chính: Thứ nhất, đôi khi những cách sắp xếp khác nhau của các vật thể ngầm có thể tạo ra kết quả giống hệt nhau trên các công cụ phát hiện, khiến chúng ta không thể biết được cấu hình nào đúng nếu không có dữ liệu bổ sung. Thứ hai, môi trường thực tế có nhiều loại đất, mức độ ẩm và mật độ vật liệu thay đổi trong phạm vi ngắn, tạo ra các tín hiệu phức tạp mà các thuật toán truyền thống khó xử lý chính xác.\nQuan sát kết quả khảo sát từ tính, chúng ta thấy các phép đo bề mặt cho thấy cường độ từ trường thay đổi trong một khu vực rộng 50 mét, như minh họa trong Hình 1(a). Khi xử lý dữ liệu này bằng phương pháp truyền thống, chúng ta thu được hình ảnh sơ bộ về một cấu trúc giống như đường ống kéo dài xuống khoảng 5 mét, nhưng hình ảnh mờ và thiếu chi tiết (Hình 1(b)). Đây chính là nơi phương pháp dựa trên AI cho thấy ưu thế – nó mang lại hình ảnh rõ ràng hơn nhiều, hiển thị một cấu trúc giống đường ống nằm ở độ sâu từ 1 đến 1,5 mét dưới bề mặt (Hình 1(c)). Nhờ vậy, phương pháp AI xác định vị trí chính xác hơn nhiều, đồng thời vẫn duy trì tính nhất quán với các phép đo từ tính ban đầu.\nHình 1. (a) Chế độ xem bản đồ trên một phần khảo sát rộng 50m. (b) Phương pháp đảo ngược bình phương nhỏ thông thường. (c) Phương pháp đảo ngược dựa trên học sâu.\nGiải pháp deep learning dựa trên vật lý S2 Labs ứng dụng physics-informed AI và AWS high performance computing (HPC) để giải quyết các bài toán kỹ thuật phức tạp trong các lĩnh vực dầu khí, sản xuất, chăm sóc sức khỏe và công nghệ sinh học, mang lại các giải pháp vừa đảm bảo tính chính xác khoa học vừa rút ngắn thời gian tính toán. S2 Labs đã hợp tác với hai đối tác chuyên biệt: Empact AI, cung cấp bản đồ đường ống ngầm 3D, và Kraken Robotics, đóng góp hình ảnh dưới nước độ phân giải cao thông qua hệ thống Synthetic Aperture Sonar. Sự hợp tác này tích hợp công nghệ sonar tiên tiến, phân tích dưới bề mặt 3D và nhận dạng mẫu dựa trên AI thông qua AWS Cloud để xác định và định vị nguồn rò rỉ đường ống với độ chính xác và tốc độ cao hơn.\nPhương pháp AI của chúng tôi kết hợp vật lý của từ trường với deep learning để hiểu rõ hơn những gì nằm dưới lòng đất. Bằng cách huấn luyện AI với dữ liệu mô phỏng dựa trên các cấu trúc thực tế như bồn chứa và đường ống, chúng tôi có thể dạy nó “đọc” các phép đo từ trường như đọc một bản đồ. Sử dụng một loại neural network đặc biệt gọi là U-Net, AI học cách chuyển đổi các tín hiệu từ trường này thành hình ảnh rõ nét của các cấu trúc ngầm, cho chúng ta biết không chỉ vị trí mà còn cả thành phần và hình dạng của chúng. Nếu bạn quan tâm đến chi tiết kỹ thuật, hãy xem bài báo khoa học gần đây do S2 Labs công bố.\nModel training Mô hình physics-informed deep learning được huấn luyện trên AWS bằng cách kết hợp các tài nguyên high performance computing, hệ thống lưu trữ dữ liệu, và các dịch vụ xử lý song song, như minh họa trong sơ đồ kiến trúc ở Hình 2.\nSử dụng Amazon EC2 instances, chúng tôi đã tạo ra 202.000 mô hình 3D susceptibility (mỗi mô hình gồm 226.000 cells) đại diện cho nhiều kịch bản dưới lòng đất khác nhau – bao gồm đường ống với nhiều hướng khác nhau, các cấu hình nhiều đường ống, và bồn chứa.\nCác mô hình sau đó được tham số hóa dựa trên kiến thức chuyên ngành và lưu trữ dưới dạng file NumPy trong Amazon S3 buckets. Ứng dụng magnetostatic solver độc quyền của S2 Labs được container hóa và lưu trữ trong Amazon ECR để triển khai đồng nhất trên các tài nguyên tính toán. Solver này xử lý tuần tự các mô hình từ S3, rồi lưu kết quả phản hồi trở lại S3.\nChúng tôi cũng triển khai distributed computing bằng AWS Batch để sinh dữ liệu, sử dụng Spot Instances nhằm tối ưu chi phí. Chúng tôi dùng P4d instances, mỗi instance cung cấp tám NVIDIA A100 GPUs để tính toán phản hồi từ trường tại 1.800 điểm đo với khoảng cách 2 mét. Pipeline đồng bộ dữ liệu giữa Amazon S3 và bộ nhớ cục bộ, huấn luyện kiến trúc 2D U-Net (500 triệu tham số) trong 110 epochs, đạt training loss 0.0018 và validation loss 0.0019. Toàn bộ tính toán yêu cầu 100.000 CPU hours.\nHình 2. Sơ đồ kiến ​​trúc để tạo dữ liệu tổng hợp và đào tạo mô hình trên AWS.\nQuy trình làm việc để suy luận các cuộc khảo sát từ trường quy mô lớn Pipeline xử lý khảo sát từ tính của chúng tôi áp dụng một quy trình bốn giai đoạn có hệ thống để xử lý các khảo sát quy mô lớn một cách hiệu quả, đồng thời vẫn duy trì khả năng tái tạo chất lượng cao các cấu trúc hạ tầng ngầm, minh họa trong Hình 3.\nStage 1 – Data Acquisition: Việc thu thập dữ liệu hiện trường bắt đầu bằng các hệ thống magnetometer được tùy chỉnh theo môi trường khảo sát – gắn trên drone cho khảo sát trên không, hệ thống mặt đất cho khảo sát trên đất liền, hoặc hệ thống dưới nước cho ứng dụng biển. Các khảo sát tuân theo lưới mẫu có hệ thống với độ cao cảm biến và khoảng cách đường khảo sát nhất quán để đảm bảo vùng mục tiêu được bao phủ đồng đều.\nStage 2 – Survey Domain Preparation: Thay vì xử lý toàn bộ khu vực khảo sát cùng lúc, chúng tôi áp dụng phương pháp mô-đun bằng cách chia miền khảo sát thành các ô nhỏ hơn, phù hợp với kích thước huấn luyện của mô hình AI. Các ô liền kề có vùng chồng lấn, rất quan trọng để đảm bảo sự chuyển tiếp mượt mà trong tái tạo cuối cùng và tránh hiện tượng nhiễu ở rìa.\nStage 3 – Parallel Processing Architecture: Quy trình tận dụng parallel computing để xử lý đồng thời nhiều ô, từ đó giảm đáng kể thời gian tính toán trong khi vẫn đảm bảo tính nhất quán với các tham số của mô hình đã huấn luyện. Cách tiếp cận phân tán này giúp sử dụng hiệu quả tài nguyên tính toán thông qua xử lý ô độc lập. Ví dụ, triển khai của chúng tôi có thể xử lý dữ liệu khảo sát kích thước 400 m x 400 m x 60 m trong chưa đến 5 giây.\nStage 4 – AI-Based Inference: Mô hình AI đã huấn luyện thực hiện inference trên từng ô một cách độc lập, tái tạo phân bố magnetic susceptibility dưới bề mặt từ các phép đo từ trường. Các bản tái tạo sau đó được kết hợp liền mạch bằng phương pháp weighted blending tại các vùng chồng lấn, đảm bảo sự chuyển tiếp mượt mà giữa các ô liền kề để tạo ra kết quả cuối cùng thống nhất. Quy trình mô-đun này cho phép khả năng mở rộng cho khảo sát ở mọi kích thước, đồng thời duy trì độ phân giải nhất quán và tối ưu hóa việc sử dụng bộ nhớ nhờ xử lý song song hiệu quả, khiến nó trở nên khả thi trong các ứng dụng thực tế từ bản đồ hạ tầng ngầm đến khảo sát địa chất.\nHình 3. Quy trình xử lý mô-đun cho các cuộc khảo sát từ tính quy mô lớn.\nNghiên cứu điển hình: phát hiện đường ống dẫn dầu khí dưới nước ở Vịnh Mexico Cơn bão Hurricane Ivan (2004) đã làm hư hại một giàn khoan dầu ngoài khơi ở Vịnh Mexico, chôn vùi các well conductors dưới lớp trầm tích dày 35–45 mét. Hình ảnh acoustic imaging ban đầu vào năm 2022, dù có phần thành công, nhưng vẫn bị hạn chế do trầm tích chứa khí che khuất các khu vực quan trọng. Một mảng magnetometer độ phân giải cao được triển khai cách đáy biển 3,5 mét để phát hiện các conductors giàu sắt xuyên qua lớp trầm tích bão hòa hydrocarbon.\nMô hình mà chúng tôi đã mô tả ở các phần trước đã lập bản đồ thành công các conductors bị chôn vùi ở độ sâu 35–45 mét, hé lộ một bó conductor chính và một đoạn mảnh vỡ thứ cấp nằm cách well bay 40 mét về phía đông bắc (như minh họa trong Hình 4). Kết quả cho thấy khả năng phân biệt vượt trội các magnetic signatures trong trường hợp có nhiều mảnh vỡ phức tạp, được xác minh qua các điểm khoan và hình ảnh acoustic khi có thể. Điều này chứng minh hiệu quả của deep learning trong những trường hợp mà các phương pháp acoustic truyền thống thất bại.\nHình 4. Hình chiếu bằng (a) và hình chiếu xiên (b) của phân bố độ nhạy tương đối.\nKết luận Công trình của chúng tôi cho thấy cách AI-enhanced magnetic imaging đang thay đổi lĩnh vực subsurface infrastructure mapping trên nhiều ngành, từ các tiện ích nông trên đất liền đến các offshore well conductors sâu dưới biển. Mô hình physics-informed deep learning được huấn luyện trên AWS bằng cách kết hợp các tài nguyên high performance computing, hệ thống lưu trữ dữ liệu và các dịch vụ xử lý song song.\nThông qua các case study thực tế, chúng tôi đã chứng minh rằng deep learning có thể vượt qua những hạn chế của việc diễn giải dữ liệu từ tính truyền thống, lập bản đồ thành công các cấu trúc ở độ sâu 40 mét dưới đáy biển – những cấu trúc vốn đã “vô hình” với phương pháp acoustic suốt 18 năm.\nTác động của công nghệ này trải dài từ oil \u0026amp; gas decommissioning, urban utility mapping, environmental protection cho đến marine operations. Dù kết quả rất hứa hẹn, vẫn còn nhiều cơ hội phát triển, bao gồm multi-physics integration, xử lý dữ liệu real-time, và nâng cao khả năng phân giải.\nĐể hợp tác hoặc tìm hiểu thêm về việc triển khai, vui lòng liên hệ với chúng tôi qua email: santi@s2labs.co hoặc ryanqi@amazon.com.\nThông tin về các tác giả Santi Adavani Tiến sĩ Santi Adavani là người sáng lập và CEO của S2 Labs, một startup công nghệ chuyên sâu (deep tech) xây dựng các sản phẩm AI nhằm thúc đẩy khám phá khoa học. Trước S2 Labs, Santi là người sáng lập và CTO của RocketML, nơi ông đã xây dựng một nền tảng MLOps được hỗ trợ bởi HPC (Điện toán Hiệu năng Cao). Ông cũng từng là Trưởng bộ phận Sản phẩm và AI tại PostgresML, nơi ông lãnh đạo phát triển một cơ sở dữ liệu vector trong bộ nhớ dựa trên Postgres, và trước đó là Giám đốc Sản phẩm Cấp cao tại Intel. Santi có bằng Tiến sĩ về Khoa học và Kỹ thuật Tính toán từ Đại học Pennsylvania. Jacques Guigné Giáo sư Jacques Yves Guigné là Cố vấn Cấp cao cho Kraken Robotics ở Newfoundland, Canada. Ông giữ chức vụ Giám đốc Khoa học (CSO) của Subsea Micropiles Ltd., công ty hoạt động tại Ireland và Vương quốc Anh. Ông cũng là Giám đốc Điều hành của Acoustic Zoom Inc., một công ty nghiên cứu địa vật lý hàng đầu. Jacques mang đến kinh nghiệm phong phú về hình ảnh âm học và đã đóng góp đáng kể vào việc lập bản đồ đáy biển phức tạp. Những thành tựu khoa học của ông bao gồm hơn 80 bằng sáng chế và 70 ấn phẩm đã nhận được số lượng trích dẫn ấn tượng trên ResearchGate. Ông đã được vinh danh trong lĩnh vực vật lý với các Huy chương Deryck Chesterman và Rayleigh, phản ánh những đóng góp của ông cho địa vật lý, minh chứng bằng bằng DSc và Tiến sĩ của mình. Ngoài ra, ông còn được công nhận là Thành viên của Geoscience Canada và là Giám đốc của PEGNL (Kỹ sư Chuyên nghiệp và Nhà Khoa học Địa chất Newfoundland và Labrador). Ryan Qi Ryan có 19 năm kinh nghiệm trong lĩnh vực mô hình hóa và mô phỏng Đa Vật lý (Multiphysics), chiến lược và phát triển kinh doanh trên cả mảng công nghiệp và kỹ thuật số. Tại AWS, Ryan là Trưởng nhóm BD/GTM Toàn cầu Chính (Principal Worldwide BD/GTM Leader), tập trung vào các công nghệ mô phỏng và hệ thống tự hành. Souvik Mukherjee Tiến sĩ Souvik Mukherjee là thành viên sáng lập của EmPact-AI và là Cố vấn Kỹ thuật Chính. Sự nghiệp hơn 15 năm của ông trải dài qua nhiều lĩnh vực trong ngành năng lượng và công nghệ với vai trò là một nhà địa vật lý, nhà khoa học dữ liệu và người dẫn dắt sản phẩm nổi tiếng. Ông đã được công nhận với nhiều giải thưởng uy tín trong ngành như giải thưởng Shell GameChanger (2015), giải bài báo xuất sắc nhất và đổi mới URTeC 2019, cùng nhiều giải thưởng khác. Ông cũng được công nhận về khả năng quản lý, thực hiện và cung cấp thành công nhiều dự án có giá trị hàng triệu đô la, bao gồm việc thương mại hóa thành công công nghệ phân định vết nứt thủy lực có chống đỡ từng đoạt giải thưởng, QUANTUM cho Carbo Ceramics, và việc thực hiện Nghiên cứu Thăm dò Tiên phong Shell (Shell Frontier Exploration Study), điều phối một đội ngũ gồm 15 chuyên gia kỹ thuật thuộc nhiều chuyên môn và phòng ban, vốn đã có tác động tích cực mạnh mẽ đến chiến lược mua lại hợp đồng thuê trị giá 100 triệu đô la của Shell. Srinivas Tadepalli Srinivas là trưởng bộ phận đưa HPC ra thị trường (go-to-market) toàn cầu tại AWS, chịu trách nhiệm xây dựng một chiến lược GTM toàn diện cho nhiều khối lượng công việc HPC và điện toán tăng tốc (Accelerated computing) cho cả khách hàng thương mại và công khu vực công. Trước đây, ông làm việc tại Dassault Systems và có bằng Tiến sĩ về kỹ thuật y sinh. Vidyasagar Ananthan Vidyasagar chuyên sâu về điện toán hiệu năng cao (high performance computing), mô phỏng số (numerical simulations), kỹ thuật tối ưu hóa và phát triển phần mềm trong cả môi trường công nghiệp và học thuật. Tại AWS, Vidyasagar là Kiến trúc sư Giải pháp Cấp cao (Senior Solutions Architect), phát triển các mô hình dự đoán và công nghệ mô phỏng. "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":"Khai mở toàn bộ tiềm năng của Amazon Connect Bởi Puneet Badlani và Eliza Taylor – ngày 12 tháng 5 năm 2025, chuyên mục Amazon Connect, Best Practices, Foundational (100), Thought Leadership\nNgày nay, người tiêu dùng có kỳ vọng rất cao – và khách hàng của bạn cũng không ngoại lệ. Mọi doanh nghiệp đều đang chạy đua để bắt kịp những đổi mới công nghệ mới nhất có thể cải thiện dịch vụ, giảm chi phí và hỗ trợ tăng trưởng chiến lược. Amazon Connect là một trong những giải pháp đó – được vận hành bởi sức mạnh của AWS và AI, đây là một giải pháp hiện đại và có khả năng mở rộng. Tuy nhiên, nếu bạn cắt giảm trong khâu triển khai, bạn có thể làm ảnh hưởng đến lợi ích tiềm năng.\nChúng ta sẽ cùng xem xét cách mà các thực tiễn quản trị thay đổi có thể không chỉ bảo vệ mà còn tăng tốc cho khoản đầu tư – những rủi ro cần chú ý, những chỉ số nào thực sự tạo khác biệt, và cách tận dụng tối đa thời gian và nguồn lực hạn chế để mang lại những thay đổi có tác động lớn.\nĐừng “vấp ngã” vì các bên liên quan “Các bên liên quan” (stakeholders) thường bị hiểu sai. Nhiều tổ chức hoặc tập trung quá nhiều vào bên trong hoặc bên ngoài. Trong một dự án chuyển đổi công nghệ và quy trình dịch vụ khách hàng, điều quan trọng là tập trung vào các bên liên quan bên ngoài, vì họ có ảnh hưởng trực tiếp.\nCác bên liên quan bên ngoài là khách hàng, đối tác và nhà cung cấp – những người liên hệ với trung tâm chăm sóc khách hàng. Khả năng của họ trong việc tiếp nhận thông tin, giải quyết vấn đề và cảm thấy được lắng nghe có ý nghĩa rất lớn đến thành công của chương trình, cũng như việc họ có tiếp tục gắn bó lâu dài với bạn hay không.\nỞ nội bộ, với các dự án lớn, cần có sự phối hợp toàn tổ chức. Một nhà tài trợ cấp cao (executive sponsor) có thể điều phối nguồn lực và đảm bảo thành công. Ngoài CNTT, vận hành dịch vụ khách hàng và marketing, bạn cũng cần có sự tham gia của tài chính, nhân sự và các bộ phận khác. Cuối cùng, không phải mọi bên liên quan đều bình đẳng – mức độ tham gia và giám sát sẽ phụ thuộc vào vai trò và tầm ảnh hưởng.\nHiểu rõ bạn thực sự cần gì Amazon Connect là một giải pháp mạnh mẽ và có thể tùy biến, hỗ trợ nhiều nhóm – từ liên hệ đa kênh (omnichannel), tự động hóa tương tác, hỗ trợ tác nhân bằng AI sinh, báo cáo động, đánh giá tự động, và nhiều hơn nữa.\nTuy nhiên, nếu không hiểu rõ quy trình hiện tại, điểm đau và yêu cầu kinh doanh, bạn có nguy cơ làm lệch phạm vi (scope) và mất đi lợi ích. Bạn có cần một IVR thông minh để giảm số lượng cuộc gọi và tiết kiệm thời gian chuyển tiếp tác nhân? Bạn có cần Connect tích hợp với hệ thống CRM cũ? Bạn có bị trễ SLA do khối lượng cuộc gọi tăng đột biến hoặc vấn đề lập lịch?\nXác định những yếu tố này từ sớm, lộ trình triển khai sẽ tự hình thành, đi kèm cơ sở kinh doanh rõ ràng. Bạn sẽ có một câu chuyện thuyết phục với các metrics chứng minh ROI và mục tiêu rõ ràng cho đội ngũ. Đây cũng là thế mạnh của AWS Partner – CloudInteract, tận dụng AI để khai mở insight và mang lại độ chính xác cao cho kế hoạch cải tiến.\nĐảm bảo có nhà tài trợ cấp lãnh đạo Một executive sponsor nhiệt huyết đóng vai trò quan trọng trong việc tạo động lực và nâng cao nhận thức trong tổ chức cho bất kỳ chương trình chuyển đổi nào. Họ cần có một tầm nhìn thuyết phục và bằng việc chủ động quảng bá dự án, họ sẽ giúp phát hiện và xử lý các rủi ro tiềm ẩn.\nCách tiếp cận này đảm bảo rào cản được giải quyết sớm, đồng thời thúc đẩy môi trường hợp tác, nơi các bên liên quan đều cảm thấy được khuyến khích đóng góp. Nhờ vậy, tổ chức quản lý dự án tốt hơn và đưa ra quyết định kịp thời. Sự hiện diện và hỗ trợ của executive sponsor cũng xây dựng niềm tin và uy tín – yếu tố thiết yếu để triển khai thành công.\nXây dựng “đại sứ thay đổi” Sai lầm lớn nhất trong chuyển đổi công nghệ là nghĩ rằng không cần “kể câu chuyện” về thay đổi – rằng vài email liệt kê lợi ích kỹ thuật và một khóa đào tạo là đủ.\nBạn cần chạy một chiến dịch truyền thông nội bộ cho sự thay đổi. Nếu đầu tư vào các kênh giao tiếp hai chiều (email được giám sát, buổi chia sẻ, diễn đàn cộng đồng, phiên hỏi đáp sau townhall), bạn sẽ vừa tạo được thiện chí, vừa thu thập insight từ chuyên gia nghiệp vụ.\nHãy mở rộng tầm ảnh hưởng bằng cách tuyển chọn và hỗ trợ champions – những nhân sự có khả năng lan tỏa thay đổi. Họ thường là những người dùng sớm (early adopters), tester. Bạn có thể khuyến khích bằng cách đưa các hoạt động này vào mục tiêu hằng năm, từ đó mở rộng tác động đến các nhóm bị ảnh hưởng.\nĐào tạo hiệu quả hơn với ít nguồn lực hơn Khi dự án đi qua nhiều giai đoạn, các nhóm khác nhau sẽ cần đào tạo khác nhau. Ban đầu, nhóm CNTT cần làm quen với môi trường mới, cách thiết lập và quản lý. Tiếp theo, nhóm vận hành phải đào tạo tác nhân và giám sát viên để sử dụng hằng ngày. Tất cả bắt đầu từ đánh giá tác động thay đổi (change impact assessment).\nTrong đánh giá này, cần xác định nhóm nào bị ảnh hưởng nhiều nhất và quan trọng nhất. Nếu nguồn lực hạn chế và không thể đào tạo trực tiếp cho tất cả, hãy tập trung vào các nhóm “business-breakers” – những nhóm giữ vai trò sống còn. Với các nhóm khác, có thể thay thế bằng đào tạo từ xa hoặc tự học.\nĐo lường những gì thực sự quan trọng Đừng để metrics chỉ là khẩu hiệu. Việc báo cáo tỉ lệ mở email có thực sự cho thấy nhân viên đã hiểu thay đổi chưa? Một email được mở không đồng nghĩa với nhận thức. Một cách đo lường tốt hơn có thể là số lượng buổi họp do quản lý chủ trì – dựa trên bộ công cụ bạn cung cấp.\nSai lầm là chỉ đo lường số liệu dự án. Thực sự, bạn cần chứng minh cải tiến dài hạn: tỉ lệ giảm chuyển cuộc gọi, thời gian xử lý, CSAT, hay so sánh với thời gian cho các công việc thủ công trước đây như lập lịch ca, đánh giá hiệu suất, hoặc báo cáo.\nBáo cáo tiến độ dự án là quan trọng nhưng chỉ mang tính tạm thời – những metrics thực sự quan trọng là từ business case. Hãy bắt đầu theo dõi chúng càng sớm càng tốt, đặc biệt trong triển khai theo giai đoạn, để kịp thời nhận ra lỗ hổng trong đào tạo và mức độ tiếp nhận.\nTóm lại… Có một vài yếu tố then chốt giúp quá trình triển khai Amazon Connect trở nên hiệu quả và khai mở toàn bộ lợi ích. Hãy lập kế hoạch trước, đưa tổ chức đồng hành, triển khai cẩn trọng, và giải pháp contact center được hỗ trợ bởi AI này sẽ vượt xa kỳ vọng – từ đa kênh, tác nhân, tự động hóa đến phân tích.\nHãy liên hệ với AWS và CloudInteract để được hỗ trợ thêm trong việc khai thác tối đa sức mạnh của Amazon Connect (tạm dịch: khai mở các siêu năng lực của Amazon Connect).\n"},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/4-eventparticipated/4.1-event1/","title":"Event 1","tags":[],"description":"","content":"Bài thu hoạch “Vietnam Cloud Day 2025: Ho Chi Minh City Connect Edition for Builders (Track 1: GenAI \u0026amp; Data)” Mục Đích Của Sự Kiện Tìm hiểu bảo mật trong GenAI và AI Agent để tăng cường an toàn cho doanh nghiệp Khám phá AI-Driven Development Lifecycle (AI-DLC) và ứng dụng vào quy trình phát triển phần mềm Xây dựng nền tảng dữ liệu hợp nhất nhằm tối ưu cho phân tích và trí tuệ nhân tạo Cập nhật chiến lược và xu hướng GenAI mới nhất trên AWS Danh Sách Diễn Giả Jun Kai Loke – AI/ML Specialist SA, AWS Kien Nguyen – Solutions Architect, AWS Tamelly Lim – Storage Specialist SA, AWS Binh Tran – Senior Solutions Architect, AWS Taiki Dang – Solutions Architect, AWS Michael Armentano – Principal WW GTM Specialist, AWS Nội Dung Nổi Bật Nội dung chính Nền tảng dữ liệu thống nhất trên AWS cho AI \u0026amp; Analytics\nXây dựng data platform end-to-end: ingestion → lưu trữ → xử lý → truy cập → quản trị. Xóa silo dữ liệu, con người, quy trình; hỗ trợ self-service \u0026amp; chuẩn hóa governance. Dịch vụ tiêu biểu: S3, Glue, Redshift, Lake Formation, OpenSearch, Kinesis/MSK. Chiến lược GenAI trên AWS\nTầm nhìn, xu hướng và lộ trình áp dụng GenAI. Amazon Bedrock: chọn model, RAG, guardrails, tối ưu chi phí/độ trễ. AgentCore \u0026amp; Amazon Nova hỗ trợ tích hợp công cụ và frameworks (CrewAI, LangGraph, LlamaIndex\u0026hellip;). Bảo mật ứng dụng GenAI\nRủi ro OWASP LLM; bảo mật nhiều lớp: hạ tầng → mô hình → ứng dụng. 5 trụ cột: Compliance, Privacy, Controls, Risk Management, Resilience. Công cụ: Bedrock Guardrails, Human-in-the-loop, Observability (OpenTelemetry). AI Agents – Tăng cường năng suất\nTừ assistant đến multi-agent systems, tự động hóa và giảm giám sát. Ứng dụng: CSKH, BI với Amazon Q (QuickSight), tự động hóa quy trình. Độ tin cậy \u0026amp; tính đúng đắn của GenAI\nGiảm hallucination bằng Prompt Engineering, RAG, Fine-tuning. RAG workflow: input → embedding → context → LLM → output. AI-Driven Development Lifecycle (AI-DLC)\nVòng đời: Inception → Construction → Operation. Tiến hóa: AI-Assisted → AI-Driven → AI-Managed. Triển khai với IaC, test tự động, giám sát \u0026amp; quản trị rủi ro. Amazon SageMaker – Unified Studio\nNền tảng hợp nhất cho data, analytics \u0026amp; AI. Hỗ trợ Lakehouse, governance, Zero-ETL integration (S3 ↔ Redshift, Aurora, DynamoDB, RDS…). MLOps đầy đủ: pipelines, registry, deployment, monitoring. Tích hợp Bedrock \u0026amp; JumpStart để tăng tốc phát triển ứng dụng GenAI. Những Gì Học Được Tư duy thiết kế\nThiết kế hệ thống dữ liệu \u0026amp; AI theo hướng end-to-end, loại bỏ silo. Ứng dụng nguyên tắc self-service và governance ngay từ đầu. Kiến trúc kỹ thuật\nTích hợp dịch vụ AWS (S3, Glue, Redshift, SageMaker, Bedrock…) thành nền tảng thống nhất. Áp dụng Zero-ETL, Lakehouse, MLOps để đảm bảo tính mở rộng, quản trị và vận hành bền vững. Tận dụng AI Agents và GenAI frameworks để tự động hóa quy trình \u0026amp; tăng năng suất. Chiến lược\nXác định lộ trình áp dụng GenAI trong doanh nghiệp, cân bằng giữa tốc độ đổi mới và chi phí. Chú trọng bảo mật nhiều lớp: hạ tầng, mô hình, ứng dụng; kết hợp guardrails \u0026amp; human-in-the-loop. Ưu tiên độ tin cậy và tính đúng đắn của AI qua RAG, prompt engineering, fine-tuning. Tư duy phát triển phần mềm\nTiến hóa từ AI-Assisted → AI-Driven → AI-Managed. AI-DLC (AI-Driven Development Lifecycle) giúp chuẩn hóa quy trình phát triển với AI tham gia ở mọi giai đoạn. Ứng Dụng Vào Công Việc Trong dự án:\nThử AI Agent cho đăng ký/đăng nhập và hỗ trợ khách hàng. Dùng validation/guardrails để tích hợp GenAI an toàn. Trong học tập \u0026amp; team project:\nÁp dụng AI-DLC để chia việc: AI hỗ trợ tạo code/tài liệu, team review \u0026amp; approve. Biết khi nào dùng Lambda (serverless) và khi nào dùng container (ECS/Fargate). Trong vai trò học việc:\nHọc cách tiếp cận business-first khi viết tài liệu, thu thập yêu cầu. Nhận ra data foundation là yếu tố cốt lõi để GenAI mang lại giá trị. Trải nghiệm trong event Tham gia workshop “GenAI-powered App-DB Modernization” là một trải nghiệm rất bổ ích, giúp tôi có cái nhìn toàn diện về cách hiện đại hóa ứng dụng và cơ sở dữ liệu bằng các phương pháp và công cụ hiện đại. Một số trải nghiệm nổi bật:\nHọc hỏi từ các chuyên gia Các chuyên gia AWS chia sẻ xu hướng mới về GenAI, Data Foundation và Security. Hiểu rõ hơn cách xây dựng nền tảng dữ liệu thống nhất để phục vụ AI \u0026amp; Analytics. Ấn tượng với tầm nhìn AI Agents và tiềm năng nâng cao năng suất trong doanh nghiệp. Trải nghiệm kỹ thuật thực tế Học cách thiết kế pipeline dữ liệu end-to-end: ingestion → lưu trữ → xử lý → truy cập → governance. Tiếp cận các công cụ như Amazon Bedrock, AgentCore, SageMaker Unified Studio. Trải nghiệm các giải pháp giảm hallucination (Prompt Engineering, RAG). Hiểu cách áp dụng AI-DLC để phân chia task giữa AI và con người trong quá trình phát triển phần mềm. Ứng dụng công cụ và phương pháp Tìm hiểu Bedrock Guardrails để đảm bảo tính an toàn khi triển khai GenAI. Thấy rõ giá trị của serverless (AWS Lambda) và khi nào nên dùng containerization (ECS/Fargate). Biết cách tận dụng Amazon Q cho BI (QuickSight) và hỗ trợ customer support. Kết nối \u0026amp; trao đổi Event là cơ hội để trao đổi với chuyên gia AWS và học hỏi từ case study thực tế. Nhận ra tầm quan trọng của business-first approach trong mọi quyết định công nghệ. Bài học rút ra GenAI không chỉ là công cụ, mà cần chiến lược \u0026amp; kiến trúc kỹ thuật đúng đắn để tạo giá trị. Dữ liệu và bảo mật là nền tảng, không có thì AI khó phát huy hiệu quả. AI Agents và AI-DLC hứa hẹn thay đổi cách chúng ta thiết kế và vận hành hệ thống. Một số hình ảnh khi tham gia sự kiện "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/4-eventparticipated/4.2-event2/","title":"Event 2","tags":[],"description":"","content":"Bài thu hoạch “Vòng đời phát triển theo hướng AI: Tái định hình kỹ thuật phần mềm” Mục Đích Của Sự Kiện Hiểu rõ cách AI có thể tự động hóa và tối ưu hóa từng giai đoạn trong vòng đời phát triển phần mềm (Software Development Lifecycle – SDLC). Nắm bắt được triết lý AI hỗ trợ con người thay vì thay thế con người trong quá trình xây dựng ứng dụng. Trực tiếp quan sát cách Amazon Q và các công cụ AI khác hỗ trợ lập trình viên từ giai đoạn khởi tạo ý tưởng, viết mã, đến triển khai hạ tầng (IaC – Infrastructure as Code). Nhận thức được xu hướng “AI-first development” – nơi AI trở thành một phần tự nhiên của quy trình phát triển phần mềm tương lai. Danh Sách Diễn Giả Toan Huynh My Nguyen Nội Dung Nổi Bật Thử thách khi lập trình với AI Phần mở đầu trình bày những hạn chế và thách thức khi đưa AI vào lập trình:\nAI chưa thể xử lý các project có logic phức tạp, đòi hỏi hiểu biết sâu về ngữ cảnh nghiệp vụ. Lập trình viên khó kiểm soát chi tiết trong mã sinh ra nếu không mô tả rõ ràng mục tiêu và phạm vi. Chất lượng code phụ thuộc nhiều vào prompt và context mà người dùng cung cấp. Đây chính là lý do AI-DLC ra đời: tạo ra một quy trình có cấu trúc, giúp AI và con người phối hợp hiệu quả hơn.\nAI in Development – How AI is Changing Software Phần này phân tích cách AI đang thay đổi ngành phần mềm:\nAI hỗ trợ sinh code, tạo tài liệu kỹ thuật, thiết kế API, và kiểm thử tự động. Developer chuyển vai trò từ “code writer” sang “AI orchestrator” — người điều phối, định hướng và đánh giá đầu ra. Các công cụ như Amazon Q, GitHub Copilot, ChatGPT for Developers trở thành công cụ trung tâm trong workflow của team dev hiện đại. 🔹 Giới thiệu về AI-DLC là gì AI-Driven Development Lifecycle (AI-DLC) là phương pháp tiếp cận phát triển phần mềm có sự đồng hành của AI, nơi mỗi bước được thiết kế để cung cấp cho AI ngữ cảnh và mục tiêu cụ thể nhằm tạo ra kết quả chính xác hơn.\n🟧 Inception\nBuild Context on Existing Codes – AI được “nuôi” bằng mã nguồn hiện tại để hiểu cấu trúc dự án. Elaborate Intent with User Stories – Developer mô tả yêu cầu thông qua user story, làm rõ mục tiêu. Plan with Units of Work – Phân tách công việc thành các đơn vị nhỏ để AI có thể thực thi và sinh code từng phần. 🟦 Construction\nDomain Model (Component Model) – Xây dựng mô hình miền hoặc sơ đồ kiến trúc logic. Generate Code \u0026amp; Test – AI sinh code và test tự động dựa trên thông tin đã lên kế hoạch. Add Architectural Components – Bổ sung các thành phần kiến trúc như API, data layer, logging, security. Deploy with IaC \u0026amp; Tests – Tự động triển khai hệ thống với Infrastructure as Code và test tích hợp. 🔁 Mỗi bước đều cung cấp thêm “rich context” cho bước kế tiếp, giúp AI hiểu sâu hơn về hệ thống và sinh ra kết quả ngày càng chính xác.\nCORE CONCEPTS – Ba nguyên lý cốt lõi Context Awareness – AI cần có ngữ cảnh rõ ràng về mã, yêu cầu và domain để hoạt động hiệu quả. Collaborative Generation – Con người và AI hợp tác: AI sinh code, con người định hướng và kiểm duyệt. Continuous Refinement – Quy trình lặp lại liên tục để tinh chỉnh đầu ra và cải thiện chất lượng. Mob Elaboration Mob Elaboration là phương pháp mở rộng yêu cầu (intent elaboration) theo hình thức cộng tác nhóm:\nNhiều thành viên cùng nhau mô tả yêu cầu, đặt câu hỏi, và bổ sung thông tin cho AI. Giúp AI hiểu sâu hơn về nghiệp vụ, mục tiêu và logic phức tạp của dự án. Cách tiếp cận này giúp giảm rủi ro hiểu sai yêu cầu, đặc biệt trong các team lớn hoặc đa miền. 5-Stage Sequential Process của AI-DLC AI-DLC được thực hiện qua 5 giai đoạn:\nInception – Hiểu yêu cầu, phân tích hệ thống. Construction – Tạo mô hình miền và cấu trúc ban đầu. Generation – Sinh mã tự động. Testing – Tự động hóa kiểm thử đơn vị và tích hợp. Deployment – Triển khai ứng dụng với IaC và CI/CD pipelines. Mỗi vòng lặp giúp AI học thêm và cải thiện chất lượng đầu ra.\nDemo 1 – Trải nghiệm trực quan AI DLC với Amazon Q Buổi demo minh họa cách áp dụng AI-DLC trong thực tế thông qua một dự án nhỏ:\nBắt đầu từ ý tưởng đơn giản → chuyển thành user story mô tả yêu cầu nghiệp vụ. AI hỗ trợ phân chia công việc (Units of Work) và lập kế hoạch chi tiết cho từng module. Người tham dự có thể điều khiển AI thông qua câu hỏi, checkbox và điều kiện logic, giúp AI hiểu rõ phạm vi công việc. AI tiếp tục sinh code, viết test, tạo cấu trúc dự án và triển khai thử nghiệm tự động. Demo thể hiện rõ cách AI và con người phối hợp nhịp nhàng: AI làm việc lặp đi lặp lại, con người định hướng và ra quyết định chiến lược. Giới Thiệu Về Kiro Triết Lý Của Kiro\nPhần tiếp theo của workshop giới thiệu Kiro, một môi trường phát triển thông minh được thiết kế xoay quanh triết lý “AI-native development” – nơi AI là một phần cốt lõi, không phải chỉ là công cụ hỗ trợ.\nTriết lý của Kiro tập trung vào ba yếu tố chính:\nTích hợp sâu với quy trình phát triển – AI không chỉ hỗ trợ viết code, mà còn tham gia lập kế hoạch, quản lý context, và phân tích tác động thay đổi. Hiểu ngữ cảnh dự án toàn diện – Kiro duy trì trạng thái hiểu biết liên tục về cấu trúc hệ thống, cho phép AI tương tác với toàn bộ project thay vì từng file riêng lẻ. Kiểm soát \u0026amp; cộng tác thông minh – Lập trình viên có thể hướng dẫn AI thông qua contextual commands, giúp đảm bảo rằng mỗi thay đổi đều có mục đích rõ ràng và nhất quán với hệ thống. Cấu Trúc Project Trong Kiro\nKhác với các text editor truyền thống như VSCode hay JetBrains, Kiro không chỉ là môi trường viết mã — nó là AI workspace có nhận thức cấu trúc.\nCấu trúc project trong Kiro bao gồm:\nContext Layer – Lưu trữ ngữ cảnh, domain model, và quan hệ giữa các module. Task Layer – Quản lý các đơn vị công việc (Units of Work) được AI theo dõi và hoàn thành dần. AI Agent Layer – Mỗi tác vụ (code, test, refactor, deploy) có agent riêng đảm nhận, tạo ra mô hình phát triển đa agent – hợp tác – song song. Human-in-the-Loop Control – Lập trình viên có thể can thiệp ở mọi bước: xác nhận, sửa đổi hoặc từ chối đầu ra của AI. Điều này giúp Kiro không chỉ là công cụ sinh code mà trở thành một hệ sinh thái phát triển hợp tác giữa người và AI.\nDemo 2: Kiro – Áp Dụng AI-DLC Trong phần trình diễn, diễn giả minh họa cách Kiro vận hành AI-DLC một cách liền mạch:\nNgười dùng nhập một yêu cầu nghiệp vụ cơ bản, ví dụ “xây dựng hệ thống quản lý sự kiện”. Kiro tự động phân tích intent, tạo domain model và chia nhỏ thành các user story. AI trong Kiro sinh ra các module, component và test case tương ứng. Developer có thể tương tác qua bảng kiểm (checkbox-based task control) để xác nhận từng phần việc. Cuối cùng, Kiro triển khai hệ thống hoàn chỉnh với IaC và kiểm thử tự động. Buổi demo cho thấy AI-DLC không chỉ là lý thuyết, mà có thể được triển khai thực tế ngay trong môi trường Kiro — nơi AI, con người, và quy trình phát triển hòa quyện thành một hệ thống thống nhất.\nTrải nghiệm trong event Tham gia buổi workshop “AI DLC x Kiro: Reinventing Developer Experience with AI” là một trải nghiệm vô cùng bổ ích, giúp tôi hiểu rõ hơn về cách AI được tích hợp sâu vào môi trường phát triển phần mềm và cách mà triết lý thiết kế của Kiro mang lại hướng tiếp cận mới cho developer.\nHọc hỏi từ các diễn giả có chuyên môn cao Các diễn giả đã chia sẻ về AI DLC – một nền tảng hỗ trợ phát triển phần mềm dựa trên AI, giúp tự động hóa nhiều quy trình trong SDLC. Ngoài ra, phần giới thiệu về Kiro Editor mang lại cái nhìn sâu sắc về cách xây dựng một text editor theo hướng AI-native thay vì chỉ “thêm plugin AI” vào môi trường cũ. Tôi đặc biệt ấn tượng với triết lý của Kiro: tối giản, hiệu năng cao, tập trung vào trải nghiệm người dùng và khả năng mở rộng theo module. Trải nghiệm kỹ thuật thực tế Buổi demo minh họa cách sử dụng AI DLC kết hợp với Kiro để tạo, chỉnh sửa và tối ưu mã nguồn một cách thông minh. Tôi được chứng kiến một project nhỏ được khởi tạo và quản lý ngay trong Kiro, với khả năng AI tự động đề xuất refactor, viết test case và phân tích logic code. So với các text editor phổ biến như VSCode hay Sublime, Kiro thể hiện sự khác biệt nhờ kiến trúc AI-first và plugin architecture nhẹ, cho phép tích hợp AI mà không làm giảm hiệu suất. Ứng dụng công cụ hiện đại Việc trải nghiệm AI DLC trên Kiro giúp tôi hiểu rõ hơn về khả năng tự động hóa quy trình phát triển, đặc biệt là ở các bước như code generation, documentation và debugging. Tôi nhận ra tiềm năng của việc xây dựng công cụ học tập và làm việc cá nhân có khả năng gợi ý thông minh, giúp rút ngắn thời gian phát triển và nâng cao chất lượng sản phẩm. Các khái niệm về modular design của Kiro cũng gợi ý cho tôi hướng đi trong việc thiết kế hệ thống linh hoạt, dễ mở rộng và dễ bảo trì. Kết nối và trao đổi Workshop tạo cơ hội để tôi giao lưu với các developer, nhà nghiên cứu AI và product designer, từ đó hiểu thêm về xu hướng AI-augmented development. Qua các cuộc thảo luận, tôi học được nhiều về cách AI có thể đóng vai trò cộng tác viên sáng tạo, giúp developer tập trung hơn vào logic và tư duy hệ thống thay vì những thao tác lặp lại. Bài học rút ra AI DLC kết hợp Kiro là ví dụ điển hình cho thế hệ công cụ phát triển mới — AI-first IDE, nơi AI không chỉ hỗ trợ mà còn đồng hành cùng lập trình viên trong mọi giai đoạn phát triển. Triết lý “less is more” của Kiro nhấn mạnh rằng sự tối giản và hiệu suất có thể tạo ra trải nghiệm mạnh mẽ hơn bất kỳ hệ thống phức tạp nào. Tôi học được rằng việc áp dụng AI hiệu quả không chỉ nằm ở công nghệ, mà còn ở cách tích hợp và triết lý thiết kế, điều này có thể được mang vào các dự án học tập hoặc phát triển phần mềm thực tế của tôi. Một số hình ảnh khi tham gia sự kiện "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/4-eventparticipated/4.3-event3/","title":"Event 3","tags":[],"description":"","content":"Bài thu hoạch “WORKSHOP KHOA HỌC DỮ LIỆU TRÊN AWS” Mục Đích Của Sự Kiện Chia sẻ các dịch vụ AI trên AWS Hướng dẫn triển khai mô hình AI thông qua Amazon SageMaker Chia sẻ cách deploy mô hình AI và truy cập thông qua API Danh Sách Diễn Giả Văn Hoàng Kha - Cloud Solutions Architec AWS User Group Leader Bạch Doãn Vương - Cloud Develops Engineer AWS Community Builder Nội Dung Nổi Bật Giới thiệu \u0026amp; Tầm quan trọng của Cloud trong Data Science Trình bày vai trò của điện toán đám mây (Cloud Computing) trong việc hỗ trợ xử lý dữ liệu, huấn luyện và triển khai mô hình AI quy mô lớn.\nSo sánh Cloud vs. On-premise:\nCloud: khả năng mở rộng linh hoạt, triển khai nhanh, tiết kiệm chi phí vận hành, dễ dàng tích hợp. On-premise: tốn kém chi phí đầu tư ban đầu, khó mở rộng, bảo trì phức tạp. Cloud (đặc biệt là AWS) mang lại nền tảng mạnh mẽ cho Data Science pipeline — từ thu thập, lưu trữ, xử lý dữ liệu, huấn luyện, cho đến triển khai mô hình AI.\nCác Layer AI Trên AWS AWS chia hệ sinh thái AI thành 3 tầng (layers), giúp người dùng lựa chọn mức độ quản lý phù hợp với năng lực và mục tiêu của mình:\n1. AI Services (Fully Managed Layer)\nDành cho người dùng muốn ứng dụng AI mà không cần kiến thức chuyên sâu về Machine Learning.\nCác dịch vụ AI sẵn có, đã được huấn luyện bởi AWS.\nNgười dùng chỉ cần gọi API là có thể sử dụng ngay trong ứng dụng.\nVí dụ:\nAmazon Comprehend: Phân tích ngôn ngữ tự nhiên (NLP) Amazon Translate: Dịch máy học đa ngôn ngữ Amazon Textract: Trích xuất dữ liệu từ tài liệu, hóa đơn Amazon Rekognition: Nhận diện hình ảnh và video Amazon Polly: Chuyển văn bản thành giọng nói Amazon Bedrock: Truy cập các mô hình nền tảng (Foundation Models) như Claude, Titan, Mistral\u0026hellip; 👉 Lợi ích: Triển khai nhanh, không cần huấn luyện mô hình, chi phí linh hoạt theo nhu cầu sử dụng.\n2. ML Services (Semi-managed Layer)\nDành cho Data Scientist, ML Engineer muốn xây dựng, huấn luyện và triển khai mô hình ML một cách tùy chỉnh hơn.\nAmazon SageMaker là trung tâm của tầng này: cung cấp bộ công cụ đầy đủ để build – train – deploy mô hình Machine Learning.\nCác tính năng nổi bật:\nData Wrangler: Làm sạch và xử lý dữ liệu trực quan. Feature Store: Quản lý đặc trưng (features) dùng cho nhiều mô hình. AutoML (SageMaker Autopilot): Tự động huấn luyện mô hình. Model Registry \u0026amp; Monitoring: Theo dõi và quản lý mô hình sau khi deploy. 👉 Lợi ích: Toàn quyền kiểm soát pipeline ML, có thể tùy chỉnh thuật toán, môi trường huấn luyện, và quy trình triển khai.\n3. AI Infrastructure (Self-managed Layer)\nDành cho tổ chức hoặc chuyên gia muốn tự quản lý toàn bộ hạ tầng AI/ML để tối ưu chi phí hoặc hiệu năng.\nNgười dùng có thể xây dựng môi trường huấn luyện bằng cách kết hợp các dịch vụ hạ tầng cơ bản của AWS:\nAmazon EC2 / EC2 GPU Instances (P5, G6, Inferentia): Huấn luyện mô hình tùy chỉnh quy mô lớn. Amazon EKS / ECS: Chạy các workload ML trong container hoặc Kubernetes. AWS Lambda: Xử lý dữ liệu hoặc inference nhỏ gọn, serverless. Amazon S3 / EFS: Lưu trữ dữ liệu và mô hình. 👉 Lợi ích: Linh hoạt tối đa, kiểm soát toàn bộ quá trình huấn luyện, nhưng yêu cầu kiến thức kỹ thuật cao hơn.\nCác Dịch Vụ AI Phổ Biến Của AWS Hỗ Trợ Sinh Viên Trong Quá Trình Train Model 1. Amazon SageMaker\nMôi trường phát triển tích hợp (SageMaker Studio) cho toàn bộ quy trình ML:\nChuẩn bị dữ liệu Huấn luyện mô hình Theo dõi kết quả Triển khai endpoint phục vụ API inference Hỗ trợ AutoML, GPU training, model monitoring và CI/CD cho mô hình AI.\n2. Amazon Comprehend\nDịch vụ NLP giúp phân tích, hiểu và phân loại ngôn ngữ tự nhiên.\nChức năng chính:\nPhân tích cảm xúc (Sentiment Analysis) Nhận dạng thực thể (Entity Recognition) Phân loại văn bản (Text Classification) Gắn nhãn dữ liệu tự động Phát hiện ngôn ngữ Trường hợp sử dụng thực tế:\nXử lý tài liệu thông minh Phân tích mail hàng loạt để phát hiện phản hồi tích cực/tiêu cực Phân tích cảm xúc và tâm lý khách hàng Hỗ trợ trung tâm liên lạc (Contact Center Analytics) Xác thực và trích xuất thông tin cá nhân 3. Amazon Translate\nDịch vụ dịch máy học (Neural Machine Translation).\nHỗ trợ hơn 75 ngôn ngữ với độ chính xác cao và dễ tích hợp.\nỨng dụng:\nLàm website đa ngôn ngữ Dịch nội dung tự động trong ứng dụng Hỗ trợ chatbot và phân tích dữ liệu đa ngôn ngữ 4. Amazon Textract\nTự động trích xuất văn bản và dữ liệu có cấu trúc từ hình ảnh, tài liệu, hoặc biểu mẫu. Ứng dụng trong các quy trình như: số hóa hồ sơ, xử lý hóa đơn, tự động nhập dữ liệu vào hệ thống. Tổng Quan Data Science Pipeline Trên AWS Thu thập \u0026amp; lưu trữ dữ liệu: Amazon S3, AWS Data Exchange Tiền xử lý dữ liệu: AWS Glue, Lambda, Athena Huấn luyện mô hình: SageMaker (train, tune, evaluate) Triển khai mô hình: SageMaker Endpoint / Lambda + API Gateway Giám sát \u0026amp; tối ưu: CloudWatch, Model Monitor Demo 1: Thiết kế Workflow AI Training bằng Giao Diện Kéo - Thả (No-Code/Low-Code) Mục tiêu: Giới thiệu cách xây dựng quy trình huấn luyện mô hình AI mà không cần viết nhiều code.\nCông cụ sử dụng: Amazon SageMaker Studio / SageMaker Canvas\nNội dung trình diễn:\nChuẩn bị dataset và tải lên Amazon S3.\nDùng giao diện kéo-thả của SageMaker để:\nChọn nguồn dữ liệu, thuật toán huấn luyện và tham số. Thiết kế toàn bộ pipeline gồm bước làm sạch dữ liệu, training, validation và deployment. Quan sát trực quan tiến trình training và kết quả mô hình (accuracy, confusion matrix, metrics, v.v.).\nThông điệp chính: Sinh viên, nhà phát triển có thể nhanh chóng tạo workflow AI mà không cần viết code phức tạp — giúp rút ngắn thời gian nghiên cứu và thử nghiệm mô hình.\nDemo 2: Triển khai AI Service và Truy Cập Qua API/Website Mục tiêu: Giới thiệu cách deploy mô hình AI để người dùng có thể truy cập và sử dụng thực tế.\nCông cụ sử dụng: Amazon SageMaker Endpoint, API Gateway, và Lambda.\nNội dung trình diễn:\nDeploy mô hình AI đã huấn luyện lên SageMaker Endpoint. Tích hợp endpoint với API Gateway để tạo REST API công khai. Tạo đường dẫn web hoặc API URL để người dùng có thể gửi yêu cầu (ví dụ: nhập câu văn để phân tích cảm xúc hoặc dịch ngôn ngữ). Minh họa cách hiển thị kết quả trực quan (UI demo hoặc Postman/API test). Thông điệp chính: Cho thấy cách AWS hỗ trợ triển khai mô hình AI từ giai đoạn nghiên cứu đến ứng dụng thực tế — dễ dàng chia sẻ, mở rộng, và thương mại hóa.\nThảo Luận: Hiệu Năng \u0026amp; Chi Phí (Cloud vs. On-premise) Tiêu chí Cloud (AWS) On-premise Khả năng mở rộng Dễ dàng mở rộng tài nguyên theo nhu cầu Giới hạn phần cứng cố định Chi phí Trả theo mức sử dụng (Pay-as-you-go) Chi phí đầu tư ban đầu cao Triển khai Tự động, nhanh chóng Thủ công, tốn thời gian Bảo trì AWS quản lý Người dùng tự chịu trách nhiệm Thích hợp cho sinh viên ✅ Có Free Tier, dễ học và thử nghiệm ❌ Khó tiếp cận, tốn kém Kết Luận AWS cung cấp hệ sinh thái AI toàn diện từ tầng hạ tầng đến tầng ứng dụng, phù hợp với mọi đối tượng — từ sinh viên mới học AI đến doanh nghiệp triển khai quy mô lớn. Trải nghiệm trong event Tham gia workshop “AI Services on AWS for Data Science” là một trải nghiệm rất bổ ích, giúp tôi hiểu rõ hơn về vai trò của Cloud trong Data Science và cách AWS hỗ trợ huấn luyện, triển khai, và truy cập mô hình AI.\nHọc hỏi từ các diễn giả có chuyên môn cao Diễn giả giới thiệu tầm quan trọng của Cloud trong xử lý dữ liệu và huấn luyện mô hình. Hiểu rõ 3 layer AI trên AWS: AI-managed services, ML services (SageMaker), và AI frameworks. Trải nghiệm kỹ thuật thực tế Demo 1: Thiết kế workflow AI bằng cách kéo thả trong SageMaker Canvas để train model mà không cần code. Demo 2: Triển khai mô hình AI thành service có thể truy cập qua API hoặc liên kết thực tế. Ứng dụng công cụ hiện đại Tìm hiểu các dịch vụ AI nổi bật: Amazon Comprehend, Translate, và Textract. Hiểu cách các dịch vụ này hỗ trợ NLP, dịch tự động, và trích xuất dữ liệu thông minh trong nhiều ngữ cảnh. Kết nối và trao đổi Giao lưu với chuyên gia và sinh viên cùng quan tâm đến AI \u0026amp; Cloud. Trao đổi về chi phí, hiệu năng (Cloud vs On-premise) và cách tối ưu sử dụng SageMaker. Bài học rút ra Cloud là nền tảng trọng yếu trong quy trình Data Science hiện đại. AWS cung cấp đầy đủ công cụ cho mọi cấp độ AI — từ không code đến tự triển khai. Hiểu rõ hơn cách đưa mô hình AI vào sản phẩm thực tế qua các dịch vụ AWS. Một số hình ảnh khi tham gia sự kiện "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/4-eventparticipated/4.4-event4/","title":"Event 4","tags":[],"description":"","content":"Bài thu hoạch “AWS Cloud Mastery Series #1: GENERATIVE AI, RAG \u0026amp; AWS AGENTIC AI” Mục Đích Của Sự Kiện Nắm vững nghệ thuật Prompt Engineering để điều khiển mô hình hiệu quả. Khám phá hệ sinh thái các dịch vụ AI có sẵn (Pretrained AI Services) trên AWS. Hiểu chuyên sâu về quy trình xây dựng ứng dụng AI với RAG (Retrieval-Augmented Generation). Cập nhật xu hướng mới nhất về Agentic AI và cách đưa AI Agent từ bản thử nghiệm (POC) ra thực tế (Production) với Amazon Bedrock AgentCore. Tiếp cận Framework Pipecat để xây dựng trợ lý ảo giao tiếp bằng giọng nói thời gian thực. Danh Sách Diễn Giả Lâm Tuấn Kiệt - Sr DevOps Engineer (FPT Software) Danh Hoàng Hiếu Nghị - AI Engineer (Renova Cloud) Đinh Lê Hoàng Anh - Cloud Engineer Trainee (First Cloud AI Journey) Nội Dung Nổi Bật 1. Prompt Engineering \u0026amp; Foundation Models (Nền Tảng Cốt Lõi) Trước khi đi vào các dịch vụ phức tạp, sự kiện nhấn mạnh tầm quan trọng của việc hiểu và giao tiếp với các mô hình nền tảng (Foundation Models) thông qua Amazon Bedrock.\nZero-shot / Few-shot Prompting: Kỹ thuật đưa ra yêu cầu trực tiếp hoặc cung cấp ví dụ mẫu để định hướng câu trả lời. Chain of Thought (CoT): Kỹ thuật yêu cầu mô hình \u0026ldquo;suy nghĩ từng bước\u0026rdquo; (Step-by-step), giúp giải quyết các bài toán logic phức tạp chính xác hơn. 2. Các Dịch Vụ AI Được Huấn Luyện Trước (AWS AI Services) Giới thiệu nhóm các API \u0026ldquo;mì ăn liền\u0026rdquo; giúp tích hợp tính năng thông minh mà không cần training model:\nXử lý hình ảnh/video: Amazon Rekognition. Xử lý ngôn ngữ: Amazon Translate, Comprehend, Textract (OCR). Âm thanh: Amazon Polly (Text-to-Speech), Transcribe (Speech-to-Text). 3. RAG - Retrieval Augmented Generation Quy trình giúp AI trả lời dựa trên dữ liệu doanh nghiệp, giảm ảo giác:\nEmbeddings: Sử dụng Amazon Titan Text Embeddings V2 để vector hóa văn bản, phục vụ tìm kiếm ngữ nghĩa. Knowledge Bases for Amazon Bedrock: Quản lý trọn gói quy trình từ Chunking -\u0026gt; Vector Store -\u0026gt; Retrieval -\u0026gt; Generation. 4. Sự Tiến Hóa Lên Agentic AI (Kỷ Nguyên AI Tác Vụ) Sự kiện giới thiệu bước tiến hóa tiếp theo của GenAI:\nGenAI Assistants: Tuân theo quy tắc, tự động hóa các tác vụ lặp lại. GenAI Agents: Hướng tới mục tiêu cụ thể (Goal-oriented), xử lý chuỗi tác vụ rộng hơn. Agentic AI Systems: Hệ thống đa tác vụ (Multi-agent), hoạt động hoàn toàn tự chủ (Fully autonomous) với sự giám sát tối thiểu của con người. Thách thức \u0026ldquo;Hố sâu ngăn cách\u0026rdquo; (The Prototype to Production Chasm): Việc đưa Agent từ bản thử nghiệm (POC) ra thực tế gặp nhiều trở ngại lớn về:\nPerformance \u0026amp; Scalability: Hiệu năng và khả năng mở rộng. Security \u0026amp; Governance: Bảo mật và quản trị dữ liệu. Complexity: Khó khăn trong việc quản lý bộ nhớ (Memory), kiểm soát quyền truy cập và kiểm toán (Audit) các tương tác của Agent. 5. Amazon Bedrock AgentCore: Giải Pháp Đưa Agent Ra Thị Trường Để giải quyết các thách thức trên, AWS giới thiệu AgentCore - nền tảng toàn diện để xây dựng và vận hành Agent:\nCác thành phần chính: Runtime \u0026amp; Memory: Môi trường chạy và khả năng \u0026ldquo;ghi nhớ\u0026rdquo; lịch sử tương tác/học tập của Agent. Identity \u0026amp; Gateway: Quản lý định danh và cổng kết nối an toàn. Code Interpreter: Cho phép Agent tự viết và chạy code để xử lý dữ liệu phức tạp. Observability: Khả năng quan sát, theo dõi hoạt động của Agent. Lợi ích: Giúp lập trình viên tập trung vào logic nghiệp vụ thay vì lo lắng về hạ tầng bảo mật hay cách lưu trữ ngữ cảnh hội thoại. 6. Pipecat: Framework Cho AI Voice Thời Gian Thực Một framework mã nguồn mở (Open Source) thú vị được giới thiệu để xây dựng các trợ lý ảo đa phương thức (Multimodal):\nĐặc điểm: Tối ưu hóa cho các tác vụ thời gian thực (Real-time) và luồng hội thoại (Streaming). Cơ chế hoạt động (Pipeline): WebRTC Input: Nhận tín hiệu âm thanh từ người dùng. STT (Speech-to-Text): Chuyển giọng nói thành văn bản. LLM Processing: Xử lý ngôn ngữ tự nhiên để sinh câu trả lời. TTS (Text-to-Speech): Chuyển văn bản thành giọng nói. Output: Phát lại âm thanh cho người dùng với độ trễ cực thấp. Trải nghiệm chi tiết trong Event Tham gia buổi workshop giúp tôi mở rộng tầm mắt từ những khái niệm cơ bản đến những công nghệ tiên tiến nhất đang định hình tương lai của AI.\n1. Sự chuyển dịch từ \u0026ldquo;Hỏi - Đáp\u0026rdquo; sang \u0026ldquo;Hành động\u0026rdquo; (Agentic AI) Điều ấn tượng nhất với tôi là khái niệm Agentic AI. Trước đây tôi chỉ nghĩ AI dùng để chat hoặc tóm tắt văn bản. Nhưng qua phần giới thiệu về AgentCore, tôi thấy tương lai là các \u0026ldquo;nhân viên ảo\u0026rdquo; có thể tự lên kế hoạch, tự dùng công cụ (như trình duyệt web, viết code) để giải quyết công việc phức tạp mà không cần con người cầm tay chỉ việc.\n2. Giải quyết bài toán \u0026ldquo;Production\u0026rdquo; Tôi rất tâm đắc với phần chia sẻ về \u0026ldquo;Hố sâu ngăn cách\u0026rdquo; giữa POC và Production. Các công cụ như Amazon Bedrock AgentCore thực sự là chìa khóa để doanh nghiệp dám tin tưởng giao việc cho AI, nhờ vào các lớp bảo mật (Identity) và kiểm soát (Observability) chặt chẽ mà AWS cung cấp.\n3. Tiềm năng của Voice AI với Pipecat Phần demo về Pipecat rất thú vị. Việc kết hợp WebRTC và các mô hình AI để tạo ra một cuộc hội thoại trôi chảy, độ trễ thấp mở ra vô vàn ứng dụng thực tế như: Tổng đài ảo thông minh, Trợ lý phỏng vấn, hay Giáo viên ngoại ngữ AI.\nKết Luận Buổi workshop “Generative AI \u0026amp; Agentic AI on AWS” là một bức tranh toàn cảnh giá trị:\nHiện tại: Chúng ta có RAG và Prompt Engineering để làm việc hiệu quả với dữ liệu. Tương lai: Chúng ta đang bước vào kỷ nguyên Agentic AI, nơi các hệ thống tự chủ (Autonomous Agents) sẽ thay đổi cách vận hành doanh nghiệp. Công cụ: Với hệ sinh thái AWS (Bedrock, AgentCore) và các Framework (Pipecat, LangChain), rào cản kỹ thuật đang dần được xóa bỏ để các kỹ sư có thể hiện thực hóa những ý tưởng đột phá. Một số hình ảnh khi tham gia sự kiện "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/4-eventparticipated/4.5-event5/","title":"Event 5","tags":[],"description":"","content":"Bài thu hoạch “AWS Cloud Mastery Series #2: Từ DevOps, IaC đến Container \u0026amp; Observability” Mục Đích Của Sự Kiện Chuẩn hóa tư duy (Mindset): Hiểu rõ vòng đời giá trị (Value Cycle) và vai trò của DevOps trong việc chuyển giao phần mềm liên tục, tin cậy. Hiện đại hóa hạ tầng (IaC): Chuyển dịch từ thao tác thủ công (ClickOps) sang quản lý hạ tầng bằng mã (Infrastructure as Code) với CloudFormation, Terraform và CDK. Tối ưu hóa ứng dụng (Containerization): Nắm vững kiến trúc và chiến lược lựa chọn nền tảng chạy Container phù hợp: App Runner, ECS hay EKS. Giám sát toàn diện (Observability): Xây dựng hệ thống giám sát chủ động, phát hiện lỗi và tối ưu hiệu năng bằng CloudWatch và X-Ray. Danh Sách Diễn Giả Đội ngũ chuyên gia AWS \u0026amp; Cloud Engineers: Chia sẻ về kiến trúc hệ thống, chiến lược Platform Engineering và demo kỹ thuật chuyên sâu. Nội Dung Chi Tiết 1. DevOps Mindset \u0026amp; CI/CD Pipeline (Nền Tảng Tư Duy) Sự kiện bắt đầu bằng việc xác định lại DevOps không đơn thuần là công cụ, mà là văn hóa tối ưu hóa dòng chảy giá trị.\nThe Value Cycle (Vòng Đời Giá Trị):\nQuy trình khép kín 5 bước: Insights \u0026amp; Analysis -\u0026gt; Portfolio \u0026amp; Backlog -\u0026gt; Continuous Integration -\u0026gt; Continuous Testing -\u0026gt; Continuous Delivery. Mục tiêu cốt lõi: Tăng tốc độ phát hành (Speed) để đáp ứng thị trường nhanh hơn, nhưng vẫn phải đảm bảo sự ổn định (Stability) và chất lượng hệ thống. Định nghĩa lại các khái niệm CI/CD:\nContinuous Integration (CI): Developer merge code thường xuyên (hàng ngày). Hệ thống tự động Build và chạy Unit Test. Mục tiêu là phát hiện lỗi sớm (Fail fast). Continuous Delivery: Tự động hóa quy trình deploy đến môi trường Staging/Pre-prod. Việc deploy ra Production cần sự chấp thuận của con người (Manual Trigger). Continuous Deployment: Tự động hóa hoàn toàn 100% từ lúc Commit code đến khi chạy trên Production (không cần can thiệp thủ công). Chiến lược Pipeline hiệu quả:\nCentralized CI: Xây dựng hệ thống CI tập trung để quản lý bảo mật và tài nguyên, nhưng phải đảm bảo quyền tự phục vụ (Self-service) cho Developer để tránh tắc nghẽn. Artifact Management (Quản lý thành phẩm): Áp dụng nguyên tắc \u0026ldquo;Build Once, Deploy Anywhere\u0026rdquo;. Mã nguồn chỉ được build một lần duy nhất thành gói Binary (Artifact). Các môi trường sau (Staging, Prod) sử dụng chính gói Artifact này để deploy, đảm bảo tính nhất quán tuyệt đối. Điều kiện đánh rớt Build: Pipeline cần được thiết lập để Fail ngay lập tức nếu vi phạm: Lỗi biên dịch, Vi phạm Code Style, Security scan phát hiện lỗ hổng, hoặc Test chạy quá chậm. Đo lường hiệu quả (Metrics):\nSử dụng Heatmap để theo dõi sức khỏe Pipeline của toàn bộ tổ chức. Các chỉ số vàng: Deployment Frequency (Tần suất deploy), Change Failure Rate (Tỷ lệ lỗi), MTTR (Thời gian phục hồi). 2. Infrastructure as Code (IaC) - Từ ClickOps Đến Code Phần này đi sâu vào việc loại bỏ thói quen thao tác tay (ClickOps) và chuyển sang tự động hóa hoàn toàn hạ tầng.\nVấn đề của \u0026ldquo;ClickOps\u0026rdquo;: Thao tác tay trên AWS Console dễ gây ra sai sót con người (Human Error), chậm chạp, khó mở rộng và thiếu sự nhất quán giữa Dev/Prod. Giải pháp IaC: Mang lại khả năng Tự động hóa (Automation), Khả năng mở rộng (Scalability), Tái tạo môi trường (Reproducibility) và Cộng tác (Collaboration). Phân tích chi tiết 3 công cụ IaC hàng đầu:\n1. AWS CloudFormation (Native Tool):\nSử dụng file văn bản (YAML hoặc JSON) để mô tả trạng thái mong muốn. Template Anatomy: Cấu trúc gồm Parameters (Tham số động), Mappings (Xử lý khác biệt vùng miền - ví dụ AMI ID khác nhau giữa các Region), và Resources (Tài nguyên cần tạo). Stack: Đơn vị quản lý vòng đời tài nguyên. Xóa Stack là xóa sạch tài nguyên liên quan. 2. Terraform (Multi-Cloud Powerhouse):\nCông cụ mã nguồn mở, sử dụng ngôn ngữ HCL (HashiCorp Configuration Language). Điểm mạnh: Hỗ trợ đa nền tảng (Multi-cloud: AWS, Azure, GCP\u0026hellip;). Quy trình (Workflow): Write (Viết code) -\u0026gt; Plan (Xem trước thay đổi - Preview) -\u0026gt; Apply (Thực thi). Bước Plan là cực kỳ quan trọng để kiểm tra an toàn. State File: File lưu trạng thái thực tế của hạ tầng để đồng bộ. 3. AWS CDK (Cloud Development Kit):\nCho phép viết hạ tầng bằng ngôn ngữ lập trình (Python, TypeScript, Java\u0026hellip;). Constructs (Khối xây dựng): L1 (Cfn Resources): Cấu hình chi tiết từng dòng (giống CloudFormation). L2 (Curated): Tự động áp dụng Best Practices và cấu hình mặc định an toàn. L3 (Patterns): Dựng cả một kiến trúc phức tạp (ví dụ: VPC + ALB + ECS) chỉ trong vài dòng code. Drift Detection: Tính năng quan trọng giúp phát hiện sự sai lệch cấu hình giữa Code và Thực tế (do ai đó sửa tay - ClickOps), giúp duy trì kỷ luật vận hành.\n3. Containerization - Chiến Lược Chạy Ứng Dụng Phân tích sâu về các nền tảng điều phối container (Orchestration):\nKubernetes (K8s):\nKiến trúc gồm Control Plane (API Server, etcd, Scheduler) và Worker Nodes (Kubelet, Pods). Mạnh mẽ, linh hoạt nhưng phức tạp trong vận hành. So sánh Amazon ECS vs. Amazon EKS:\nAmazon ECS: Đơn giản, tích hợp sâu với AWS (ALB, IAM). Phù hợp cho team muốn giảm tải vận hành, deploy nhanh. Amazon EKS: Dựa trên Kubernetes chuẩn. Mạnh mẽ, hệ sinh thái mở rộng lớn. Phù hợp cho Enterprise, hệ thống phức tạp hoặc Hybrid-cloud. Mô hình tính toán (Compute Options):\nEC2 Launch Type: Tự quản lý server (Patching, Scaling). Kiểm soát cao nhất nhưng tốn công vận hành. AWS Fargate (Serverless): Không cần quản lý server. AWS lo hạ tầng, người dùng chỉ cần định nghĩa CPU/RAM cho Task. An toàn và tiện lợi. AWS App Runner:\nGiải pháp \u0026ldquo;Zero-ops\u0026rdquo; cho Web App/API. Tự động hoàn toàn từ Source Code/Image -\u0026gt; Public URL (HTTPS) mà không cần cấu hình hạ tầng mạng hay server. 4. Observability - Giám Sát \u0026amp; Tối Ưu Hóa Khép kín vòng đời phát triển bằng khả năng quan sát sâu rộng để đảm bảo hệ thống vận hành ổn định.\nAmazon CloudWatch (Tai mắt của hệ thống):\nMetrics: Thu thập dữ liệu hiệu năng (CPU, Memory, Disk). Logs: Thu thập nhật ký ứng dụng tập trung. Dùng Logs Insights để truy vấn lỗi. Alarms: Tự động kích hoạt hành động (Auto Scaling, Restart Server, gửi thông báo) khi đạt ngưỡng cảnh báo. AWS X-Ray (Truy vết phân tán):\nGiải quyết bài toán \u0026ldquo;mò kim đáy bể\u0026rdquo; trong Microservices. Distributed Tracing: Theo dõi hành trình của một request đi qua nhiều service để tìm ra nút thắt cổ chai (Bottlenecks) và nguyên nhân gốc rễ (Root cause). AWS Observability Best Practices:\nSử dụng trang tài nguyên của AWS để tham khảo các Patterns (Mẫu thiết kế) và Recipes (Công thức cấu hình) chuẩn chỉnh. Phân biệt rõ: Logs (Sự kiện rời rạc) khác với Traces (Hành trình liên kết). Trải nghiệm chi tiết trong Event Tham gia chuyên đề này mang lại cho tôi những thay đổi lớn về nhận thức và kỹ năng kỹ thuật:\n1. Sự chuyển dịch từ \u0026ldquo;Ops\u0026rdquo; sang \u0026ldquo;Platform Engineering\u0026rdquo; Tôi nhận ra vai trò của DevOps hiện đại không phải là người chạy theo Developer để deploy code thủ công. DevOps là người kiến tạo ra \u0026ldquo;Đường cao tốc\u0026rdquo; (Pipeline \u0026amp; Platform). Một nền tảng tốt cho phép Developer tự phục vụ (Self-service) việc khởi tạo môi trường và deploy code một cách nhanh chóng, nhưng vẫn nằm trong khuôn khổ an toàn (Governance) mà đội ngũ DevOps đã thiết lập.\n2. Kỷ luật trong vận hành (Operational Discipline) Những bài học về Artifact Management và Drift Detection là những nguyên tắc vàng. Trong môi trường Enterprise, sự nhất quán (Consistency) là yếu tố sống còn. Tuyệt đối không được phép có sự khác biệt về cách build giữa các môi trường (Dev/Test/Prod) và không được phép sửa đổi thủ công (Manual changes) vào hệ thống đã được quản lý bằng Code.\n3. Chiến lược lựa chọn công cụ thông minh Không có công cụ \u0026ldquo;tốt nhất\u0026rdquo;, chỉ có công cụ \u0026ldquo;phù hợp nhất\u0026rdquo;:\nCần sự ổn định tuyệt đối và hỗ trợ sâu nhất các dịch vụ AWS mới: Chọn CloudFormation. Doanh nghiệp sử dụng Multi-cloud hoặc Hybrid-cloud: Terraform là lựa chọn tối ưu. Team Development mạnh về lập trình, cần xây dựng nhanh các kiến trúc phức tạp và tái sử dụng code: AWS CDK là vũ khí mạnh nhất. Với ứng dụng Web đơn giản: Dùng App Runner thay vì lãng phí nguồn lực để vận hành cụm Kubernetes. Kết Luận Chuyên đề \u0026ldquo;DevOps \u0026amp; IaC Mastery\u0026rdquo; đã cung cấp một tấm bản đồ hoàn chỉnh cho hành trình lên Cloud:\nVề Tư duy: Chuyển từ làm thủ công sang tự động hóa và đo lường bằng dữ liệu thực tế. Về Hạ tầng: Làm chủ IaC để hệ thống có thể mở rộng, tái tạo dễ dàng và kiểm soát được sự sai lệch. Về Vận hành: Kết hợp Containerization linh hoạt và Observability sâu rộng để đảm bảo hệ thống luôn ổn định, hiệu năng cao và có khả năng tự phục hồi. Đây là nền tảng kiến thức vững chắc để xây dựng các hệ thống phần mềm quy mô lớn, hiện đại trên AWS.\nMột số hình ảnh khi tham gia sự kiện "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/4-eventparticipated/4.6-event6/","title":"Event 6","tags":[],"description":"","content":"Bài thu hoạch “AWS Cloud Mastery Series #3” Mục Đích Của Chuỗi Chuyên Đề Chuỗi sự kiện này không chỉ giới thiệu các dịch vụ đơn lẻ mà là một hành trình tư duy hệ thống (System Thinking), giúp chuyển đổi từ cách quản lý hạ tầng truyền thống sang mô hình Cloud-Native Security. Mục tiêu cốt lõi bao gồm:\nKết nối cộng đồng (Community): Lan tỏa tinh thần học tập và phát triển kỹ năng qua AWS Cloud Clubs. Thiết lập nền móng quản trị (Governance): Quản lý quy mô lớn với hàng trăm tài khoản AWS mà vẫn đảm bảo tuân thủ. Phòng thủ nhiều lớp (Defense in Depth): Kết hợp Identity, Network và Data protection để không có điểm chết duy nhất. Tự động hóa phản ứng (Automated Response): Loại bỏ yếu tố con người chậm trễ trong quy trình xử lý sự cố. Danh Sách Diễn Giả Sự kiện quy tụ đội ngũ chuyên gia hàng đầu từ cộng đồng AWS, bao gồm các AWS Community Builders, Cloud Engineers và các thành viên nòng cốt của chương trình First Cloud Journey:\nĐại diện AWS Cloud Clubs: Các Captains từ HCMUTE, SGU, PTIT, HUFLIT (Le Vu Xuan An, Tran Duc Anh, Tran Doan Cong Ly, Danh Hoang Hieu Nghi). Mảng Identity \u0026amp; Governance: Huynh Hoang Long, Dinh Le Hoang Anh (AWS Community Builders). Mảng Detection \u0026amp; Monitoring: Tran Duc Anh, Nguyen Tuan Thinh, Nguyen Do Thanh Dat. Mảng Network Security: Kha Van (Cloud Security Engineer | AWS Community Builder). Mảng Data Protection: Thinh Lam, Viet Nguyen. Mảng Incident Response: Mendel Grabski (Long) - ex Head of Security \u0026amp; DevOps, Tinh Truong - Platform Engineer. Nội Dung Chi Tiết PHẦN 1: KHỞI ĐỘNG - AWS CLOUD CLUBS \u0026amp; CƠ HỘI PHÁT TRIỂN Hành trình bắt đầu bằng việc giới thiệu cộng đồng AWS Cloud Clubs, nơi ươm mầm các tài năng Cloud tương lai.\n1. Tầm nhìn (Vision):\nTrao quyền cho sinh viên khám phá và phát triển kỹ năng điện toán đám mây. Phát triển khả năng lãnh đạo kỹ thuật và xây dựng kết nối toàn cầu. 2. Lợi ích cốt lõi (Benefits):\nBuild Skills: Học qua dự án thực tế, tiếp cận AWS exam vouchers và tài khoản Udemy. Build Community: Kết nối với các chuyên gia AWS và diễn giả trong ngành. Build Opportunities: Nâng cao hồ sơ cá nhân, nhận AWS credits và hỗ trợ nghề nghiệp. 3. The Badging Journey:\nLộ trình phát triển được trò chơi hóa cho các thành viên nòng cốt và Captains. Các cấp độ từ Bronze, Silver, Gold, Platinum đến Diamond. Phần thưởng: AWS Credits ($200+), Voucher thi chứng chỉ, Swag kits độc quyền và cơ hội được phê duyệt trước cho Student Community Day. PHẦN 2: NỀN TẢNG ĐỊNH DANH VÀ QUẢN TRỊ (IDENTITY \u0026amp; GOVERNANCE) Bảo mật trên Cloud bắt đầu bằng việc kiểm soát \u0026ldquo;Ai được làm gì\u0026rdquo;.\n1. Tư duy IAM hiện đại:\nIdentity First: Trong môi trường Cloud, Định danh (Identity) là bức tường lửa mới. Credential Spectrum: Chuyển dịch tuyệt đối từ Long-term Credentials (Access Keys vĩnh viễn - rủi ro cao) sang Short-term Credentials (STS tokens - an toàn, tự hết hạn). Least Privilege: Áp dụng quyền tối thiểu. Không dùng dấu * trong Policy trừ khi thực sự cần thiết. 2. Quản trị quy mô lớn với AWS Organizations:\nCấu trúc phân tầng: Chia tổ chức thành các Organizational Units (OUs) như Security, Shared Services, Workloads (Prod/Dev) để cô lập rủi ro. Service Control Policies (SCPs): Đây là \u0026ldquo;Luật Hiến Pháp\u0026rdquo; của tổ chức. SCP thiết lập hàng rào bảo vệ (Guardrails) chặn các hành động nguy hiểm (ví dụ: cấm tắt CloudTrail, cấm rời khỏi Region chỉ định) mà ngay cả tài khoản Admin cũng không thể vượt qua. PHẦN 3: KHẢ NĂNG QUAN SÁT VÀ PHÁT HIỆN (VISIBILITY \u0026amp; DETECTION) Bạn không thể bảo vệ hệ thống nếu không biết chuyện gì đang xảy ra bên trong nó.\n1. Amazon GuardDuty - Trinh sát thông minh:\nSử dụng Machine Learning để phát hiện bất thường từ 3 nguồn dữ liệu nền tảng: CloudTrail (hành vi quản trị), VPC Flow Logs (lưu lượng mạng), và DNS Logs (truy vấn tên miền). Runtime Monitoring: Tính năng nâng cao giúp \u0026ldquo;nhìn sâu\u0026rdquo; vào bên trong hệ điều hành (thông qua Agent nhẹ) để phát hiện các tiến trình (Process) lạ, file bị sửa đổi hoặc hành vi leo thang đặc quyền. 2. AWS Security Hub - Trung tâm chỉ huy:\nGiải quyết bài toán \u0026ldquo;ngập lụt thông báo\u0026rdquo; bằng định dạng ASFF (AWS Security Finding Format). Nó chuẩn hóa cảnh báo từ GuardDuty, Inspector, Macie về cùng một ngôn ngữ JSON. Đóng vai trò quản lý tư thế bảo mật (CSPM), tự động kiểm tra xem hệ thống có tuân thủ các chuẩn CIS, PCI-DSS hay không. PHẦN 4: BẢO MẬT MẠNG LƯỚI (NETWORK SECURITY) Xây dựng \u0026ldquo;Pháo đài số\u0026rdquo; với chiến lược phòng thủ nhiều lớp từ biên vào lõi.\n1. Kiểm soát cơ bản (VPC Fundamentals):\nSecurity Groups (Stateful): Áp dụng kỹ thuật Micro-segmentation. Thay vì whitelist địa chỉ IP (dễ thay đổi), ta sử dụng Security Group Referencing (ví dụ: SG-DB chỉ cho phép traffic từ SG-App). NACLs (Stateless): Đóng vai trò lớp chặn thô tại biên giới Subnet, dùng để chặn các dải IP đen hoặc subnet không tin cậy. 2. Phòng thủ nâng cao (Advanced Filtering):\nDNS Firewall (Route 53 Resolver): Chặn đứng các kết nối đến máy chủ điều khiển (C2) của hacker ngay từ khi phân giải tên miền. Đây là chốt chặn quan trọng để chống lại mã độc (như case study Mélofée). AWS Network Firewall: Tường lửa thế hệ mới với khả năng kiểm tra gói tin sâu (Deep Packet Inspection). Stateless Engine: Lọc nhanh dựa trên 5-tuple (IP/Port). Stateful Engine: Sử dụng luật tương thích Suricata để phát hiện xâm nhập (IPS) và lọc tên miền (FQDN filtering) cho traffic đi ra Internet (Egress). 3. Kiến trúc mạng hiện đại:\nSử dụng AWS Transit Gateway tích hợp Native với Network Firewall để đơn giản hóa mô hình mạng, loại bỏ sự phức tạp của việc định tuyến qua \u0026ldquo;Inspection VPC\u0026rdquo;. Áp dụng Active Threat Defense: Tự động đồng bộ danh sách IP độc hại từ GuardDuty vào Network Firewall để chặn tức thì mà không cần can thiệp thủ công. PHẦN 5: BẢO VỆ DỮ LIỆU (DATA PROTECTION) Dữ liệu là tài sản tối thượng cần được bảo vệ bằng mã hóa.\n1. Mã hóa bao thư (Envelope Encryption):\nHiểu rõ cơ chế của AWS KMS: Master Key (nằm trong HSM) mã hóa Data Key, và Data Key mới là thứ mã hóa dữ liệu thật. Cơ chế này đảm bảo hiệu năng cao và tính bảo mật tuyệt đối. 2. Quản lý bí mật (Secrets Management):\nVấn đề: Hardcode mật khẩu trong code là lỗi sơ đẳng nhưng phổ biến. Giải pháp: Sử dụng AWS Secrets Manager để lưu trữ và quan trọng hơn là tự động xoay vòng (Automatic Rotation) mật khẩu Database bằng Lambda. Ứng dụng luôn lấy mật khẩu mới nhất qua API. 3. Hạ tầng mã hóa phần cứng:\nSử dụng AWS Nitro System: Các tác vụ mã hóa được đẩy xuống phần cứng chuyên biệt (Nitro Cards), giúp mã hóa dữ liệu mà không làm giảm hiệu năng CPU của máy chủ (Zero Performance Impact). PHẦN 6: ỨNG PHÓ SỰ CỐ (INCIDENT RESPONSE) Khi các lớp phòng thủ bị xuyên thủng, quy trình phản ứng sẽ quyết định mức độ thiệt hại.\n1. Chiến lược phòng ngừa (Prevention - Sleep Better):\nNguyên tắc vàng: Loại bỏ SSH/Key dài hạn, Chặn S3 Public, Private Subnets mặc định. Infrastructure as Code (IaC): Bắt buộc mọi thay đổi hạ tầng phải thông qua Code (Terraform/CDK) và quy trình phê duyệt (PR Review), loại bỏ hoàn toàn việc sửa tay (ClickOps) gây sai lệch cấu hình. 2. Quy trình 5 bước chuẩn mực:\nChuẩn bị (Preparation): Có sẵn công cụ và Playbook. Phát hiện (Detection): Dựa vào CloudTrail và GuardDuty. Cô lập (Containment): \u0026ldquo;Nhốt\u0026rdquo; tài nguyên bị nhiễm bằng cách đổi Security Group hoặc gỡ quyền IAM. Diệt trừ \u0026amp; Phục hồi (Eradication \u0026amp; Recovery): Xóa malware, khôi phục từ backup sạch. Hậu sự cố (Post-Incident): Rút kinh nghiệm. 3. Tự động hóa (Automation is King):\nCon người không thể chạy đua với tốc độ tấn công của máy. Các bài lab thực chiến đã chứng minh sự cần thiết của việc dùng EventBridge + Lambda để tự động cô lập EC2 bị nhiễm mã độc hoặc tự động khắc phục S3 bị public chỉ trong vài giây. Kết Luận Chuỗi chuyên đề \u0026ldquo;Cloud Security \u0026amp; Operations Mastery\u0026rdquo; đã cung cấp một bức tranh toàn cảnh về việc xây dựng hệ thống an toàn trên AWS thông qua các trụ cột chính:\nQuản trị \u0026amp; Định danh: Nền tảng của mọi hệ thống bảo mật bắt đầu từ việc quản lý người dùng và chính sách tổ chức chặt chẽ. Mạng lưới \u0026amp; Giám sát: Thiết lập các lớp phòng thủ chiều sâu và khả năng quan sát toàn diện để phát hiện các mối đe dọa tiềm tàng. Dữ liệu \u0026amp; Ứng phó: Bảo vệ tài sản số bằng mã hóa và sẵn sàng các quy trình phản ứng sự cố tự động hóa để đảm bảo tính liên tục của dịch vụ. "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/5-workshop/5.1-workshop-overview/5.1.1-whatisrag/","title":"Giải thích RAG","tags":[],"description":"","content":"Định nghĩa ngắn gọn RAG (viết tắt của Retrieval-Augmented Generation) là một kỹ thuật hoặc kiến trúc phần mềm trong lĩnh vực Trí tuệ nhân tạo (AI), được thiết kế để tối ưu hóa đầu ra của một Mô hình Ngôn ngữ Lớn (LLM).\nVề mặt bản chất, RAG là sự kết hợp giữa hai cơ chế:\nCơ chế truy xuất thông tin (Information Retrieval): Tìm kiếm dữ liệu từ một nguồn kiến thức bên ngoài (External Knowledge Base) có độ tin cậy cao. Cơ chế tạo sinh văn bản (Text Generation): Sử dụng khả năng hiểu và tổng hợp ngôn ngữ của LLM để tạo ra câu trả lời tự nhiên. Mục tiêu của RAG là cung cấp cho LLM thêm ngữ cảnh (context) chính xác, cập nhật và cụ thể, giúp mô hình vượt qua giới hạn của dữ liệu huấn luyện tĩnh (static training data).\nVì sao cần RAG? Các mô hình LLM truyền thống thường gặp 3 vấn đề lớn mà RAG có thể giải quyết:\nCập nhật thông tin (Freshness): LLM không cần huấn luyện lại (Re-training) hay tinh chỉnh (Fine-tuning) mà vẫn trả lời được các thông tin mới nhất, chỉ cần cập nhật vào cơ sở dữ liệu tìm kiếm. Sở hữu dữ liệu (Proprietary Data): Cho phép AI trả lời các câu hỏi về dữ liệu riêng tư của doanh nghiệp (tài liệu nội bộ, code base, thông tin khách hàng) mà mô hình gốc không hề biết. Tính xác thực (Grounding): Giảm thiểu \u0026ldquo;ảo giác\u0026rdquo; (Hallucination - AI bịa thông tin) bằng cách buộc AI phải trích dẫn hoặc dựa trên đoạn văn bản thực tế được tìm thấy. Kiến trúc hoạt động Quy trình xử lý một câu hỏi của RAG diễn ra như sau:\nBước Tên gọi Mô tả hành động 1 Retrieval (Truy xuất) Hệ thống tìm kiếm các đoạn văn bản liên quan nhất đến câu hỏi trong kho dữ liệu (thường dùng Vector Database). 2 Augmentation (Tăng cường) Ghép câu hỏi của người dùng + Dữ liệu vừa tìm được thành một \u0026ldquo;lời nhắc\u0026rdquo; (prompt) hoàn chỉnh. 3 Generation (Tạo sinh) Gửi prompt đó cho AI (LLM) để nó tổng hợp và viết ra câu trả lời cuối cùng cho người dùng. "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/5-workshop/5.1-workshop-overview/","title":"Giới thiệu","tags":[],"description":"","content":"Giới thiệu tổng quan Trong bài thực hành này, chúng ta sẽ tập trung xây dựng một trợ lý AI thông minh có khả năng \u0026ldquo;đọc hiểu\u0026rdquo; và trả lời câu hỏi dựa trên dữ liệu riêng của doanh nghiệp (kỹ thuật RAG).\nMục tiêu chính là thiết lập một quy trình xử lý dữ liệu hoàn toàn tự động và không máy chủ (Serverless), bao gồm các bước:\nIngestion (Nhập liệu): Đưa tài liệu gốc vào hệ thống. Indexing (Tạo chỉ mục): Chuyển đổi văn bản thành vector và lưu trữ để tra cứu. Retrieval \u0026amp; Generation (Truy xuất \u0026amp; Tạo sinh): Cấu hình mô hình AI để tìm kiếm thông tin liên quan và trả lời câu hỏi của người dùng. 💡 Điểm nổi bật: Giải pháp này giúp bạn không cần quản lý bất kỳ hạ tầng máy chủ nào, tối ưu hóa chi phí và thời gian vận hành.\nCác Bước Thực hiện Giải thích RAG Giới thiệu các dịch vụ "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/5-workshop/5.1-workshop-overview/5.1.2-services/","title":"Giới thiệu các dịch vụ","tags":[],"description":"","content":"Kiến trúc giải pháp được xây dựng dựa trên sự phối hợp của 4 thành phần dịch vụ chính sau đây:\nKnowledge Bases for Amazon Bedrock Đây là một khả năng được quản lý toàn diện (fully managed capability) giúp kết nối các Mô hình Nền tảng (Foundation Models) với nguồn dữ liệu nội bộ của doanh nghiệp.\nTự động hóa quy trình RAG: Quản lý toàn bộ luồng công việc từ đầu đến cuối (end-to-end), bao gồm nhập dữ liệu (ingestion), chia nhỏ văn bản (chunking), tạo vector (embedding) và truy xuất thông tin (retrieval). Kết nối ngữ cảnh: Giúp các ứng dụng AI trả lời câu hỏi dựa trên dữ liệu riêng tư thay vì chỉ dựa vào dữ liệu huấn luyện chung chung. Không cần quản lý hạ tầng: Loại bỏ nhu cầu tự xây dựng và duy trì các đường ống dữ liệu (data pipelines) phức tạp. Amazon Simple Storage Service (Amazon S3) Là dịch vụ lưu trữ đối tượng (object storage) với khả năng mở rộng, độ bền dữ liệu 99,999999999% (11 số 9) và bảo mật hàng đầu.\nVai trò nguồn dữ liệu (Data Source): Đóng vai trò là kho chứa \u0026ldquo;sự thật\u0026rdquo; (source of truth). Lưu trữ tài liệu: Chứa các tệp phi cấu trúc như PDF, Word, hoặc Text mà doanh nghiệp muốn AI học. Đồng bộ hóa: Knowledge Base sẽ định kỳ quét bucket S3 này để đồng bộ hóa và cập nhật kiến thức mới nhất. Amazon OpenSearch Serverless Là tùy chọn triển khai không máy chủ (serverless) của Amazon OpenSearch Service, giúp chạy khối lượng công việc tìm kiếm và phân tích mà không cần quản lý cụm (cluster).\nVai trò kho lưu trữ Vector (Vector Store): Lưu trữ các chỉ mục vector (vector embeddings) được tạo ra từ tài liệu gốc. Tìm kiếm ngữ nghĩa (Semantic Search): Thực hiện thuật toán tìm kiếm tương đồng (similarity search/k-NN) để xác định các đoạn văn bản có ý nghĩa gần nhất với câu hỏi của người dùng. Tự động mở rộng: Tự động điều chỉnh tài nguyên tính toán và lưu trữ dựa trên nhu cầu thực tế. Amazon Bedrock Foundation Models (FMs) Cung cấp quyền truy cập vào các mô hình AI hàng đầu thông qua API thống nhất. Trong kiến trúc này, chúng ta sử dụng hai loại mô hình với vai trò riêng biệt:\nEmbedding Model (Amazon Titan Embeddings v2): Chuyển đổi văn bản (tài liệu từ S3 và câu hỏi của người dùng) thành các vector số học. Giúp máy tính có thể so sánh mức độ tương đồng về ý nghĩa giữa các đoạn văn. Text Generation Model (Anthropic Claude 3): Đóng vai trò là \u0026ldquo;bộ não\u0026rdquo; suy luận. Nhận câu hỏi kèm theo thông tin ngữ cảnh đã được truy xuất từ Vector Store. Tổng hợp thông tin và sinh ra câu trả lời tự nhiên, chính xác, có kèm trích dẫn nguồn. "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/5-workshop/5.3-knowledge-base/5.3.1-create-kb/","title":"Khởi tạo Knowledge Base","tags":[],"description":"","content":"Mục tiêu Chúng ta sẽ sử dụng Amazon Bedrock Wizard để thiết lập toàn bộ kiến trúc RAG. Quá trình này sẽ kết nối nguồn dữ liệu S3, mô hình Embedding và tự động khởi tạo kho lưu trữ Vector (OpenSearch Serverless).\nCác Bước Thực hiện Đăng nhập vào AWS Management Console và truy cập dịch vụ Amazon Bedrock. Trong menu bên trái, chọn Knowledge bases. Nhấp vào nút Create knowledge base ở góc trên bên phải của màn hình. Chọn Knowledge Base with vector store Bước 1: Cấu hình Knowledge Base\nTrên màn hình cấu hình đầu tiên:\nKnowledge base name: Nhập tên knowledge-base-demo Knowledge Base description - optional: Nhập Knowledge Base from AWS Overview (Phần này bạn cần mô tả dữ liệu bạn đã upload lên S3 trước đó). IAM permissions: Chọn tùy chọn Create and use a new service role. Service role name: Giữ giá trị mặc định do AWS đề xuất (bắt đầu bằng AmazonBedrockExecutionRoleForKnowledgeBase_...). Nhấp Next. Bước 2: Cấu hình Nguồn Dữ liệu\nKết nối đến S3 Bucket chứa các tài liệu:\nData source name: Nhập knowledge-base-demo S3 URI: Nhấp vào nút Browse S3. Trong cửa sổ pop-up, chọn bucket rag-workshop-demo mà bạn đã tạo trong phần trước. Nhấp Choose. Giữ lại các cấu hình Default. Nhấp Next. Bước 3: Lưu trữ \u0026amp; Xử lý Đây là bước quan trọng nhất để xác định mô hình AI và vị trí lưu trữ vector:\nEmbeddings model:\nNhấp Select model. Chọn model: Titan Embeddings G1 - Text v2. Vector Store:\nVector store creation method: Chọn Quick create a new vector store - Recommended Vector store type - new: Chọn Amazon OpenSearch Serverless Lưu ý: Tùy chọn này cho phép AWS tự động tạo một cluster Amazon OpenSearch Serverless để lưu trữ dữ liệu, giúp bạn không phải quản lý cơ sở hạ tầng thủ công. Nhấp Next. Bước 4: Kiểm tra và Tạo Knowledge Base\nKiểm tra tất cả thông tin cấu hình trên trang Review. Đảm bảo các mục S3 URI và Model đều chính xác. Cuộn xuống cuối trang và nhấp vào nút Create knowledge base. Bước 5: Chờ Khởi tạo\nSau khi nhấp Create, hệ thống sẽ bắt đầu quá trình khởi tạo cơ sở hạ tầng nền cho Vector Store.\nThời gian chờ: Khoảng 2 - 5 phút. Lưu ý: Vui lòng không đóng trình duyệt trong thời gian này. Thành công: Khi màn hình hiển thị thông báo màu xanh \u0026ldquo;Knowledge base created successfully\u0026rdquo;, bạn đã hoàn thành bước này và sẵn sàng cho phần tiếp theo. "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/5-workshop/5.2-prerequiste/5.2.1-model-access/","title":"Kiểm tra truy cập Model","tags":[],"description":"","content":"Tổng quan Theo chính sách mới của AWS, các mô hình nền tảng (Foundation Models) thường được tự động kích hoạt. Tuy nhiên, đối với các mô hình của đối tác thứ ba như Anthropic (Claude), người dùng lần đầu tiên sử dụng tại một Region mới bắt buộc phải khai báo thông tin sử dụng (Use Case) mới có thể gọi được mô hình.\nĐảm bảo tài khoản AWS của bạn có quyền truy cập và sử dụng mô hình Anthropic Claude 3 Sonnet. Đây là bước bắt buộc để tránh lỗi AccessDenied khi Chatbot hoạt động sau này. Nếu đây là lần đầu tiên bạn sử dụng model này tại Region mới, bạn cần thực hiện khai báo mục đích sử dụng (Use Case).\nKiểm tra truy cập Chúng ta sẽ thực hiện một bài kiểm tra nhanh (Test Run) để đảm bảo tài khoản của bạn đã sẵn sàng.\nĐầu tiên ở thanh tìm kiếm, truy cập vào Amazon Bedrock.\nBước 1. Truy cập Chat Playground\nTại menu bên trái Bedrock Console, tìm mục Playgrounds. Click Chat. Bước 2. Chọn Model kiểm thử\nClick Select model (phía trên khung chat). Category: Chọn Anthropic. Model: Chọn Claude 3 Sonnet (hoặc Claude 3.5 Sonnet). Throughput: Chọn On-demand. Click Apply. Bước 3. Gửi tin nhắn kích hoạt\nTrong khung chat: Nhập Hello.\nClick Run.\nQuan sát kết quả:\nNếu AI trả lời: Thành công (Chuyển ngay sang phần 5.2.2). Nếu hiện lỗi màu đỏ hoặc popup \u0026ldquo;Submit use case details\u0026rdquo;: Cần khai báo thông tin (Làm tiếp bước 4 bên dưới).\nBước 4. Khai báo Use Case (Chỉ thực hiện nếu gặp lỗi ở bước 3)\nClick Submit use case details (trong thông báo lỗi). Điền biểu mẫu: Company Name: Nhập Personal Learning. Industry: Chọn Technology. Intended Use: Chọn Research \u0026amp; Development. Click Submit. Đợi 1 phút, quay lại khung chat, Click Run lại tin nhắn Hello để xác nhận thành công. "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/1-worklog/","title":"Nhật ký công việc","tags":[],"description":"","content":"Trong trang này bạn sẽ cần giới thiệu worklog của bạn như thế nào? Bạn hoàn thành chương trình trong vòng bao nhiêu tuần? Bạn đã làm gì trong các tuần đó?\nThông thường và cũng là tiêu chuẩn, một worklog được thực hiện trong khoảng 3 tháng (trong suốt thời gian thực tập) với nội dung các tuần như sau:\nTuần 1: Làm quen với các nền tảng AWS, Mạng VPC, Bảo mật và Thực hành Labs\nTuần 2: Thực hành AWS EC2, Auto Scaling, CloudWatch, Backup, S3, FSx, Storage Gateway\nTuần 3: Dịch vụ Bảo mật \u0026amp; Cơ sở dữ liệu trên AWS (IAM, Cognito, KMS, RDS, Aurora, Redshift, ElastiCache)\nTuần 4: Kỹ thuật dữ liệu AWS, Cơ sở dữ liệu NoSQL và Quy trình phát triển AI\nTuần 5: Khởi tạo Dự án, Tích hợp .NET \u0026amp; Kiến trúc Mạng Hybrid (VPC/DNS)\nTuần 6: Triển khai Kiến trúc Decoupled, ECS Orchestration \u0026amp; Secure API\nTuần 7: Củng cố Kiến trúc Hạ tầng: Network, Storage, Database \u0026amp; Compute\nTuần 8: Kiến trúc Serverless, Lý thuyết GenAI và Lab Xử lý ảnh Tự động\nTuần 9: Xây dựng Nền tảng .NET Aspire, Tích hợp AWS Cognito \u0026amp; Logic Quản lý Ví\nTuần 10: Xây dựng Transaction Logic nâng cao \u0026amp; Tích hợp RabbitMQ/MassTransit\nTuần 11: Hệ thống Báo cáo, Cảnh báo \u0026amp; Xử lý Tự động\nTuần 12: Tối ưu hóa Hệ thống, Tăng cường Bảo mật \u0026amp; Sẵn sàng Triển khai\n"},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/1-worklog/1.1-week1/","title":"Worklog Tuần 1","tags":[],"description":"","content":"Mục tiêu tuần 1: Hiểu các kiến thức cơ bản về điện toán đám mây và hạ tầng toàn cầu của AWS. Học cách quản lý dịch vụ AWS thông qua Management Console, CLI và SDK. Tìm hiểu bảo mật, IAM và quản lý chi phí AWS thông qua các bài thực hành. Xây dựng nền tảng kiến thức về mạng VPC và kết nối (Subnet, Route Table, IGW, NAT, Peering, Transit Gateway). Thực hành trực tiếp trên AWS với các bài Lab để củng cố lý thuyết bằng kỹ năng thực tế. Công việc thực hiện trong tuần này: Day Task Start Date Completion Date Reference Material 1 AWS Cloud Foundation \u0026amp; IAM Security - Cloud Essentials: Nghiên cứu các khái niệm điện toán đám mây cốt lõi và kiến trúc hạ tầng toàn cầu của AWS (Regions, AZs, Edge Locations). - Account Management: Tìm hiểu các mô hình định giá (Pricing) và các gói hỗ trợ (Support Plans). - Hands-on Lab: Thiết lập bảo mật tài khoản gốc (Root User), cấu hình IAM (Users, Groups, MFA) và thiết lập cảnh báo chi phí với AWS Budgets. 08/09/2025 08/09/2025 Module 01 2 Networking Fundamentals (VPC Architecture) - VPC Design: Phân tích kiến trúc mạng ảo Amazon VPC, quy hoạch địa chỉ IP (CIDR Blocks) và phân chia Subnet (Public/Private). - Routing Components: Tìm hiểu cơ chế định tuyến qua Route Tables, Internet Gateway (IGW) và NAT Gateway cho kết nối Internet. - Network Interfaces: Nghiên cứu về Elastic IP (EIP), ENI và các loại VPC Endpoints (Gateway \u0026amp; Interface) để tối ưu kết nối nội bộ. 09/09/2025 09/09/2025 Module 02 3 Network Security \u0026amp; Advanced Connectivity - Network Security: So sánh cơ chế bảo mật tầng Instance (Security Group) và tầng Subnet (Network ACL); giám sát lưu lượng với VPC Flow Logs. - Inter-Connectivity: Nghiên cứu các mô hình kết nối đa VPC (VPC Peering, Transit Gateway) và kết nối lai (VPN, Direct Connect). - Load Balancing: Tìm hiểu cơ chế phân tải ứng dụng sử dụng Elastic Load Balancing (ELB) (ALB, NLB, GWLB). 10/09/2025 10/09/2025 Module 02 4 Hands-on Lab: VPC Infrastructure Implementation - Infrastructure Setup: Triển khai thực tế mô hình VPC tiêu chuẩn: Tạo Subnets, IGW, cấu hình Route Table và Security Groups. - Compute \u0026amp; Connectivity: Khởi tạo EC2 Instance, thiết lập NAT Gateway cho Private Subnet truy cập Internet an toàn. - Operations: Thực hành giám sát tài nguyên EC2 qua CloudWatch và quản trị phiên kết nối an toàn không dùng SSH qua SSM Session Manager. 11/09/2025 11/09/2025 Module 02 5 Hands-on Lab: Advanced Networking Scenarios - Secure Access: Thực hành kỹ thuật Port Forwarding và quản lý logs tập trung với Session Manager. - VPC Peering: Cấu hình kết nối ngang hàng giữa các VPC khác Region/Account và cập nhật bảng định tuyến. - Transit Gateway: Triển khai mô hình mạng tập trung (Hub-and-Spoke) để đơn giản hóa định tuyến. - Hybrid DNS: Cấu hình Route 53 Resolver (Inbound/Outbound Endpoints) để phân giải tên miền lai. 12/09/2025 12/09/2025 Module 02 Thành tựu Tuần 1: Nắm vững kiến thức nền tảng về AWS và Điện toán đám mây\nHiểu khái niệm, lợi ích của cloud computing và hành trình chuyển đổi lên cloud. Nắm vững hạ tầng AWS: Region, AZ, Edge Location, Data Center. Thực hành công cụ quản lý AWS\nSử dụng thành thạo AWS Management Console, AWS CLI, AWS SDK. Tạo và quản lý IAM Users/Groups, kích hoạt MFA, cấu hình Access Keys. Quản lý chi phí và hỗ trợ AWS\nTạo và quản lý các loại Budget khác nhau. Tìm hiểu các gói Support Plans và thực hành mở case hỗ trợ. Kiến thức Networking \u0026amp; Security trên AWS\nXây dựng và cấu hình VPC, Subnet, Route Table, Internet Gateway, NAT Gateway. Triển khai Security Group, Network ACL, VPC Flow Logs. So sánh VPC Peering và Transit Gateway, tìm hiểu kết nối Hybrid (VPN, Direct Connect). Quản lý hệ thống trên AWS\nQuản lý EC2 bằng Session Manager thay vì SSH. Thực hành Port Forwarding và quản lý Session Logs. Bật giám sát bằng CloudWatch Monitoring \u0026amp; Alerts. Giải pháp nâng cao\nCấu hình VPC Peering và Transit Gateway để kết nối nhiều VPC. Thiết lập Hybrid DNS với Route 53 Resolver (Inbound/Outbound Endpoints). Thực hành với Elastic Load Balancer (ALB, NLB, CLB, GWLB). 👉 Kết quả: Sau Tuần 1, tôi đã xây dựng nền tảng vững chắc về AWS cơ bản và các khái niệm mạng ở mức trung cấp, đồng thời hoàn thành nhiều bài Lab trực tiếp trên AWS để rèn luyện kỹ năng thực hành.\n"},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/1-worklog/1.2-week2/","title":"Worklog Tuần 2","tags":[],"description":"","content":"Mục tiêu tuần 2: Học và thực hành dịch vụ Compute của AWS (EC2, AMI, EBS, Auto Scaling, ELB). Nắm vững kỹ năng giám sát và sao lưu với CloudWatch và AWS Backup. Tìm hiểu dịch vụ lưu trữ: S3, Storage Gateway, FSx. Thực hành triển khai, mở rộng và host website tĩnh. Công việc thực hiện trong tuần này: Day Task Start Date Completion Date Reference Material 1 AWS Compute \u0026amp; EC2 Administration - Compute Theory: Nghiên cứu kiến trúc Amazon EC2, hệ thống ảo hóa Nitro Hypervisor, các loại hình Instance và chiến lược tối ưu chi phí (Spot, Reserved, Savings Plans). - Storage for Compute: Phân biệt EBS (Block storage) và Instance Store (Ephemeral storage); quản lý AMI và Snapshots. - Hands-on Lab 04: + Khởi tạo hạ tầng EC2 (Linux \u0026amp; Windows) trong môi trường VPC. + Thực hành kết nối an toàn qua SSH (Linux) và RDP (Windows). + Triển khai ứng dụng Node.js (CRUD User Management) trực tiếp trên EC2. 14/09/2025 15/09/2025 Module 03 2 High Availability \u0026amp; Monitoring Operations - Scaling \u0026amp; Load Balancing (Lab 06): + Cấu hình Auto Scaling Group để đảm bảo khả năng mở rộng tự động. + Triển khai Elastic Load Balancer (ELB) phân phối tải ứng dụng. - Observability (Lab 08): Thiết lập Amazon CloudWatch để thu thập Metrics, Logs và tạo Alarms cảnh báo bất thường hệ thống. - Data Protection (Lab 13): Xây dựng chiến lược sao lưu tự động với AWS Backup cho EC2, RDS và EFS dựa trên RPO/RTO. 16/09/2025 16/09/2025 Module 03\nModule 06 3 AWS Storage Fundamentals (Amazon S3) - Object Storage Architecture: Nghiên cứu kiến trúc S3, tính chất bất biến của Object và độ bền dữ liệu (11 số 9). - Storage Classes: Phân tích các lớp lưu trữ (Standard, Intelligent-Tiering, Glacier) để tối ưu chi phí theo tần suất truy cập. - Security \u0026amp; Management: Cấu hình Bucket Policy, ACLs, tính năng Versioning (chống ghi đè) và Lifecycle Policy (vòng đời dữ liệu). - Archive Strategy: Tìm hiểu quy trình lưu trữ dài hạn giá rẻ với Amazon S3 Glacier và Deep Archive. 17/09/2025 17/09/2025 Module 04 4 Hybrid Cloud Storage (Storage Gateway) - Hybrid Architecture: Tìm hiểu giải pháp mở rộng lưu trữ on-premises lên Cloud thông qua AWS Storage Gateway. - Hands-on Lab 24 (File Gateway): + Triển khai EC2 mô phỏng Appliance Gateway. + Cấu hình NFS File Share ánh xạ tới S3 Bucket backend. + Thực hành mount ổ đĩa mạng từ Cloud về máy trạm local (mô phỏng). 18/09/2025 18/09/2025 Module 04 5 Managed File Systems \u0026amp; Static Hosting - Amazon FSx (Lab 25): Triển khai hệ thống file share Windows native (SMB) sử dụng Amazon FSx for Windows File Server tích hợp Active Directory. - Static Website Hosting (Lab 57): + Host website tĩnh trực tiếp trên S3 Bucket (HTML/CSS/JS). + Tối ưu hiệu năng và bảo mật nội dung thông qua Amazon CloudFront (CDN) và OAI (Origin Access Identity). + Cấu hình DNS và quyền truy cập công khai (Public Access/CORS). 19/09/2025 19/09/2025 Module 04 Thành tựu Tuần 2: Tính toán \u0026amp; Triển khai\nHiểu rõ kiến thức về Amazon EC2, kiến trúc và các thành phần liên quan (AMI, Snapshot, Key Pair, EBS). Triển khai và quản lý thành công EC2 cho cả Linux và Windows. Thực hành triển khai ứng dụng thực tế Node.js CRUD trên EC2. Nắm được các kỹ thuật tự động hóa với User Data, Meta Data, AWS Systems Manager. Khả năng mở rộng \u0026amp; Tính sẵn sàng cao\nTriển khai EC2 Auto Scaling Group để tự động điều chỉnh năng lực theo nhu cầu. Cấu hình Elastic Load Balancer (ELB) để phân phối lưu lượng. Tích hợp Auto Scaling với Load Balancer nhằm đảm bảo high availability và tối ưu chi phí. Giám sát \u0026amp; Quan sát hệ thống\nSử dụng Amazon CloudWatch để giám sát hạ tầng và ứng dụng. Tạo metrics, dashboards, alarms để theo dõi tình trạng hệ thống theo thời gian thực. Quản lý log tập trung với CloudWatch Logs, thiết lập chính sách lưu trữ và phát hiện bất thường. Thực hành thiết lập giám sát tự động qua CloudFormation. Bảo vệ \u0026amp; Sao lưu dữ liệu\nThiết kế AWS Backup Plans cho nhiều dịch vụ (EBS, RDS, DynamoDB, EFS). Áp dụng các mục tiêu RTO/RPO trong chiến lược khôi phục dữ liệu. Cấu hình SNS notifications để nhận thông báo trạng thái sao lưu và phục hồi. Lưu trữ \u0026amp; Quản lý dữ liệu\nHiểu rõ Amazon S3 là dịch vụ lưu trữ đối tượng với lifecycle policies và storage classes. Thực hành các tính năng: versioning, ACL, Bucket Policy, CORS. Cấu hình S3 Static Website Hosting và kiểm tra truy cập công khai. Tích hợp với CloudFront để tăng tốc độ phân phối nội dung và bảo mật bằng OAI. Tìm hiểu Amazon FSx for Windows File Server: kiến trúc, tích hợp Windows, và dịch vụ lưu trữ file được quản lý hoàn toàn. "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/1-worklog/1.3-week3/","title":"Worklog Tuần 3","tags":[],"description":"","content":"Mục tiêu tuần 3: Hiểu triết lý bảo mật AWS (“Security is Job Zero”) và Mô hình Trách nhiệm chia sẻ. Thành thạo các dịch vụ Quản lý danh tính \u0026amp; truy cập: IAM Users, Groups, Roles, Policies, Permission Boundaries, Organizations, Identity Center, Cognito. Ứng dụng AWS KMS để mã hóa dữ liệu, tích hợp CloudTrail và phân tích logs bằng Athena. Nắm vững các dịch vụ cơ sở dữ liệu AWS: RDS, Aurora, Redshift, ElastiCache và các khái niệm cơ bản SQL, NoSQL, OLTP, OLAP. Triển khai Amazon RDS với Multi-AZ, subnet groups, backup/restore để đảm bảo tính sẵn sàng và khả năng phục hồi. Công việc thực hiện trong tuần này: Day Task Start Date Completion Date Reference Material 1 AWS Security \u0026amp; Identity Management - Security Fundamentals: Nghiên cứu Mô hình Trách nhiệm chung (Shared Responsibility Model) và nguyên tắc \u0026ldquo;Security is Job Zero\u0026rdquo;. - Identity Management: Phân tích chuyên sâu về IAM (Users, Groups, Roles, Policies) và quản lý truy cập tập trung qua AWS Organizations \u0026amp; Identity Center. - App Security: Tìm hiểu Amazon Cognito (User/Identity Pools) cho xác thực ứng dụng. - Compliance: Khám phá mã hóa dữ liệu với AWS KMS và giám sát tuân thủ qua Security Hub. 22/09/2025 22/09/2025 Module 05 2 Hands-on Lab: IAM Policy \u0026amp; Role Configuration - IAM Basics (Lab 02): Thực hành tạo User/Group và áp dụng nguyên tắc đặc quyền tối thiểu (Least Privilege). - Advanced Roles (Lab 44): Cấu hình IAM Role với các điều kiện (Conditions) nâng cao (IP, thời gian) để kiểm soát quyền truy cập chặt chẽ. - Instance Profile (Lab 48): Cấu hình IAM Role cho EC2 Instance, loại bỏ việc hardcode Access Keys trong mã nguồn ứng dụng. 23/09/2025 23/09/2025 Module 05 3 Hands-on Lab: Advanced Security Implementation - Federated Identity (Lab 18): Cấu hình Amazon Cognito để liên kết danh tính và xác thực người dùng từ Identity Provider bên ngoài. - Permission Boundaries (Lab 30): Thiết lập ranh giới quyền hạn (Permissions Boundaries) để giới hạn quyền tối đa cho User/Role. - Data Encryption (Lab 33): Quản lý khóa mã hóa (CMK) với AWS KMS và tích hợp CloudTrail để kiểm toán hoạt động truy xuất khóa. 24/09/2025 24/09/2025 Module 05 4 AWS Database Services Fundamentals - Database Concepts: Phân biệt các mô hình cơ sở dữ liệu: Quan hệ (RDBMS) vs Phi quan hệ (NoSQL), OLTP vs OLAP. - Managed RDBMS: Nghiên cứu Amazon RDS (Multi-AZ, Read Replicas) và Amazon Aurora (Cloud-native, Serverless). - Specialized DBs: Tìm hiểu Amazon Redshift cho kho dữ liệu (Data Warehousing) và Amazon ElastiCache cho bộ nhớ đệm (Caching). 25/09/2025 25/09/2025 Module 06 5 Hands-on Lab: Deploying \u0026amp; Managing Amazon RDS - Infrastructure Setup: Thiết lập mạng VPC, Subnet Groups và Security Groups tách biệt cho tầng Database (Lab 05). - Deployment: Khởi tạo Amazon RDS Instance (Multi-AZ) và kết nối an toàn từ Web Server (EC2). - Operations: Thực hành quy trình Backup \u0026amp; Restore, quản lý Snapshots và khôi phục dữ liệu theo thời điểm (Point-in-Time Recovery). 26/09/2025 26/09/2025 Module 06 Thành tựu Tuần 3: Dịch vụ bảo mật:\nÁp dụng thực tế Mô hình Trách nhiệm chia sẻ. Quản lý IAM với Users, Groups, Roles, Policies, Conditions và Permission Boundaries. Tích hợp IAM Role với EC2 để loại bỏ rủi ro khi dùng Access Keys cố định. Thực hành Liên kết danh tính (Identity Federation) với Cognito (Google, Facebook, SAML). Quản lý tập trung nhiều tài khoản bằng AWS Organizations và Identity Center. Mã hóa \u0026amp; Giám sát:\nTạo và quản lý KMS CMK cho việc mã hóa. Mã hóa dữ liệu trong S3 bằng KMS. Ghi lại hoạt động khóa với CloudTrail và phân tích bằng Athena. Dịch vụ cơ sở dữ liệu:\nHiểu sự khác biệt giữa RDBMS và NoSQL, OLTP và OLAP. Triển khai Amazon RDS với Multi-AZ, subnet groups, backup tự động, snapshots, và phục hồi theo thời gian (point-in-time recovery). Nghiên cứu Aurora (Backtrack, Global DB, Cloning), Redshift (MPP, Spectrum), và ElastiCache (Redis, Memcached). Thực hành:\nHoàn thành nhiều bài lab: IAM Basics, IAM Roles \u0026amp; Conditions, IAM Roles for Applications, Cognito Federation, IAM Permission Boundaries, KMS Encryption, RDS Deployment. Xây dựng được môi trường RDS an toàn với khả năng backup và phục hồi dữ liệu. "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/1-worklog/1.4-week4/","title":"Worklog Tuần 4","tags":[],"description":"","content":"Mục tiêu tuần 4: Mục tiêu của tuần này là củng cố hiểu biết về các dịch vụ dữ liệu và AI của AWS — từ xây dựng kiến trúc DataLake có khả năng mở rộng đến làm việc với cơ sở dữ liệu NoSQL serverless (DynamoDB) và khám phá quản lý vòng đời phát triển AI. Ngoài ra, tuần này còn nhằm nâng cao kỹ năng dịch thuật kỹ thuật và kỹ năng giao tiếp thông qua các lab thực hành, dịch blog và tham gia các sự kiện của AWS. Công việc thực hiện trong tuần này: Day Task Start Date Completion Date Reference Material 1 Xây dựng Data Lake trên AWS - Data Lake Concepts: Tìm hiểu kiến trúc Data Lake tập trung cho phân tích dữ liệu đa dạng (batch, real-time). - AWS Glue (ETL): Nghiên cứu Glue Crawlers để tự động phát hiện schema và xây dựng Data Catalog từ S3. - Amazon Athena: Truy vấn dữ liệu S3 trực tiếp bằng SQL chuẩn, không cần server (Serverless). - Amazon QuickSight: Trực quan hóa dữ liệu thông qua Dashboard và Analysis từ dataset đã xử lý. - Hands-on Lab 35: Triển khai hạ tầng Data Lake, sử dụng Kinesis Firehose đẩy dữ liệu vào S3, chạy Glue Crawler và truy vấn kết quả bằng Athena. 29/09/2025 29/09/2025 Module 07 2 Tối ưu hóa Truy vấn \u0026amp; Phân tích Chi phí (Lab 40) - ETL Workflow: Thực hành quy trình chuẩn: Upload Raw Data -\u0026gt; Glue Crawler -\u0026gt; Transform (Parquet) -\u0026gt; Query (Athena). - Cost Analysis: Sử dụng SQL trong Athena để phân tích chi phí AWS (Top services, Cost allocation tags). - Optimization Techniques: Học cách giảm chi phí Athena bằng định dạng Parquet (nén), giới hạn kết quả (LIMIT) và phân vùng dữ liệu (Partitioning). 30/09/2025 30/09/2025 Module 07 3 Cơ sở dữ liệu NoSQL với Amazon DynamoDB (Lab 60) - DynamoDB Fundamentals: Nghiên cứu kiến trúc Serverless NoSQL, khả năng tự động mở rộng và các chế độ Capacity (On-demand vs Provisioned). - Data Modeling: Hiểu sâu về Primary Key (Partition Key + Sort Key) và Indexing (Global/Local Secondary Indexes). - Consistency Models: So sánh Eventual Consistency (nhanh, rẻ) và Strong Consistency (chính xác tuyệt đối). - Implementation: Thực hành tạo bảng, thêm/xóa items và truy vấn dữ liệu thông qua AWS Console và AWS SDK (Boto3). 01/10/2025 01/10/2025 Module 06 4 Nghiên cứu \u0026amp; Dịch thuật Blog Kỹ thuật AWS - Generative AI: Dịch và nghiên cứu về quản lý vòng đời GenAI với MLflow trên SageMaker. - Industry Application: Tìm hiểu ứng dụng Deep Learning trong vẽ bản đồ hạ tầng ngầm. - Contact Center AI: Nghiên cứu tối ưu hóa Amazon Connect với các tính năng AI. - Skill Development: Nâng cao vốn từ vựng chuyên ngành Cloud/AI và hiểu biết sâu về SageMaker, Batch, ParallelCluster. 02/10/2025 02/10/2025 5 Tham dự Sự kiện AWS: AI Development Lifecycle \u0026amp; Kiro - AI Lifecycle: Nắm bắt toàn trình phát triển AI trên AWS: Chuẩn bị dữ liệu -\u0026gt; Training -\u0026gt; Deploy -\u0026gt; Monitor. - AWS AI Ecosystem: Tìm hiểu vai trò của SageMaker, Bedrock và CodeWhisperer trong quy trình DevSecOps cho AI. - New Tooling (Kiro): Khám phá giải pháp Kiro giúp thống nhất quy trình quản lý AI workflow. - Real-world Use Cases: Học hỏi từ các case study thực tế về tự động hóa và tối ưu hóa mô hình AI trong sản xuất. 03/10/2025 03/10/2025 Thành tựu Tuần 4: Xây dựng pipeline DataLake trên AWS tích hợp Glue, Athena và QuickSight, có kinh nghiệm thực hành trong ingest, chuyển đổi và trực quan hóa dữ liệu. Cấu hình AWS Glue Crawlers và truy vấn Athena cho phân tích chi phí và tự động hóa schema, áp dụng các chiến lược tối ưu chi phí (ví dụ: Parquet, partitioning, giới hạn truy vấn). Nắm vững các kiến thức cơ bản về DynamoDB, bao gồm khóa chính/khóa hợp nhất, index (GSI, LSI), mô hình nhất quán đọc và chế độ dung lượng. Nâng cao kỹ năng dịch và hiểu nội dung kỹ thuật bằng cách dịch các bài blog kỹ thuật về AI, MLflow và HPC, nắm vững các dịch vụ như SageMaker, Batch, ParallelCluster và Connect. Tham gia một sự kiện AWS tập trung vào AI Development Lifecycle và Kiro, thu nhận kiến thức về quản lý phiên bản mô hình, theo dõi thử nghiệm và best practice triển khai. Cải thiện vốn từ kỹ thuật và hiểu biết thực tiễn về thiết kế kiến trúc dữ liệu, quản trị mô hình AI và cloud computing trong hệ sinh thái AWS. "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/1-worklog/1.5-week5/","title":"Worklog Tuần 5","tags":[],"description":"","content":"Mục tiêu tuần 5: Khởi tạo Dự án: Xác định đề tài, phân tích yêu cầu và lên kế hoạch phát triển cho dự án Personal Finance Management App v2. Tích hợp .NET \u0026amp; AWS: Nghiên cứu và thực hành tích hợp AWS SDK vào kiến trúc Microservices sử dụng .NET. Làm chủ Networking: Hiểu sâu về kiến trúc mạng VPC, bảo mật mạng và kết nối lai (Hybrid Connectivity) qua VPN và DNS. Compute Fundamentals: Nắm vững các khái niệm cốt lõi của Amazon EC2 để lựa chọn tài nguyên tính toán phù hợp. Công việc thực hiện trong tuần này: Day Task Start Date Completion Date Reference Material 1 Nghiên cứu Đề tài \u0026amp; Tích hợp AWS SDK với .NET - Project Proposal: Thảo luận nhóm, đánh giá tính khả thi và lựa chọn đề tài dự án tập trung vào kiến trúc Microservices. - Tech Stack Integration: Nghiên cứu cách tích hợp AWS SDK vào .NET. - Coding Practice: Viết code mẫu C# thực hiện các tác vụ cơ bản: upload dữ liệu lên S3, truy xuất DynamoDB và gọi Lambda function. 06/10/2025 06/10/2025 2 Lập Kế hoạch Dự án \u0026amp; Ước tính Chi phí - Requirements Analysis: Phân tích yêu cầu ứng dụng Quản lý Tài chính Cá nhân v2. - Agile Planning: Viết 20 User Stories, chia thành 8 Epics (Wallet, Transaction, AI Voice, OCR\u0026hellip;). Lên kế hoạch 2 Sprints. - Cost Estimation: Lựa chọn dịch vụ (Cognito, Transcribe, SQS\u0026hellip;) và tính toán chi phí vận hành (Free Tier vs Paid) để tối ưu ngân sách. 07/10/2025 07/10/2025 Project Documentation 3 AWS Networking: VPC \u0026amp; Site-to-Site VPN (Lab 03) - VPC Architecture: Cấu hình Custom VPC, chia Subnets, Route Tables, IGW và NAT Gateway. - Network Security: Phân biệt và cấu hình Security Groups (Stateful) vs Network ACLs (Stateless). - Hybrid Connectivity: Thiết lập AWS Site-to-Site VPN (VGW, CGW) và giám sát kết nối bằng VPC Flow Logs và Reachability Analyzer. 08/10/2025 08/10/2025 Module Re-hand-on 4 Amazon EC2 \u0026amp; Quản lý Hạ tầng Tính toán - EC2 Fundamentals: Nghiên cứu các loại Instance (T, M, R series) và lựa chọn cấu hình phù hợp (Intel/AMD/Graviton). - Image Management: Tìm hiểu về AMI (Amazon Machine Images) để chuẩn hóa môi trường server. - Backup Strategy: Xây dựng chiến lược sao lưu dữ liệu sử dụng EBS Snapshots. 09/10/2025 09/10/2025 Module Review 5 Hybrid DNS với Route 53 Resolver - Hybrid DNS Concepts: Tìm hiểu mô hình phân giải tên miền thống nhất giữa On-premise và AWS. - Route 53 Resolver: Cấu hình Outbound Endpoints (forward query từ AWS ra ngoài) và Inbound Endpoints (nhận query từ on-premise vào AWS). - Resolver Rules: Thiết lập các quy tắc chuyển tiếp DNS (Forwarding rules) cho các domain cụ thể. 10/10/2025 10/10/2025 Module Review Thành tựu tuần 5: Hoàn thiện kế hoạch dự án: Đã xây dựng bộ User Stories (20 stories/8 Epics), chia Sprint và ước tính chi phí hạ tầng AWS cho dự án FinTech. Kiểm chứng kỹ thuật (PoC): Đã viết code mẫu tích hợp thành công AWS SDK với .NET (kết nối S3, DynamoDB). Cấu hình mạng nâng cao: Thiết lập thành công VPC với Public/Private subnets và mô hình kết nối Site-to-Site VPN. Kiến trúc Hybrid DNS: Hiểu và thiết kế được luồng phân giải tên miền lai giữa On-premise và AWS sử dụng Route 53 Resolver. "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/1-worklog/1.6-week6/","title":"Worklog Tuần 6","tags":[],"description":"","content":"Mục tiêu tuần 6: Containerization Mastery: Làm chủ quy trình đóng gói và vận hành ứng dụng trên nền tảng Container (Docker) và điều phối quy mô lớn với Amazon ECS. Automation \u0026amp; Optimization: Tự động hóa quy trình phát triển phần mềm (CI/CD) và tối ưu hóa trải nghiệm người dùng toàn cầu thông qua CDN. Decoupled Architecture: Hiểu và triển khai kiến trúc Event-driven/Decoupled sử dụng các dịch vụ hàng đợi và thông báo của AWS. Modern Backend Development: Xây dựng các API hiệu năng cao, bảo mật và dễ bảo trì sử dụng Framework hiện đại FastAPI (Python). Công việc thực hiện trong tuần này: Day Task Start Date Completion Date Reference Material 1 Containerization \u0026amp; Orchestration (Docker \u0026amp; ECS) - Docker Deployment: Đóng gói ứng dụng full-stack (Frontend/Backend/DB) vào container. Quản lý Images với Docker Hub và Amazon ECR. Cấu hình Nginx làm Reverse Proxy. - Amazon ECS: Triển khai quản lý container trên quy mô lớn. Phân biệt EC2 Launch Type và AWS Fargate (Serverless). - Deployment Strategies: Thực hành các chiến lược triển khai trên ECS: Rolling Update (giảm thiểu downtime) và Blue/Green (chuyển đổi lưu lượng an toàn). 13/10/2025 13/10/2025 Module Re-hand-on 2 Content Delivery \u0026amp; CI/CD Automation - CDN Optimization (Lab 9.4): Tích hợp Amazon CloudFront với S3 Static Hosting, giảm độ trễ truy cập toàn cầu (từ ~200ms xuống ~30ms) và thiết lập bảo mật SSL/Custom Domain. - Serverless CI/CD (Lab 8.4): Xây dựng quy trình tự động hóa với AWS CodePipeline. + CI: Tự động build và test code (CodeBuild). + CD: Tự động triển khai artifacts lên môi trường Staging/Production (CodeDeploy). 14/10/2025 14/10/2025 Module Re-hand-on 3 Decoupled Architecture (SQS \u0026amp; SNS) - Amazon SQS (Message Queue): Thiết kế hệ thống xử lý đơn hàng phân tán, sử dụng Standard Queue (high throughput) và FIFO Queue (đảm bảo thứ tự) để tách biệt các thành phần hệ thống. - Amazon SNS (Pub/Sub): Cấu hình cơ chế thông báo bất đồng bộ (Fan-out pattern) tới nhiều endpoints (Lambda, SQS, Email/SMS). - Integration: Kết hợp SNS và SQS để xây dựng kiến trúc Event-driven tin cậy và có khả năng mở rộng cao. 15/10/2025 15/10/2025 Module Re-hand-on 4 Modern API Development với FastAPI (Part 1) - Framework Fundamentals: Làm quen với FastAPI (Python), tận dụng kiến trúc ASGI cho hiệu năng cao và tự động sinh tài liệu (Swagger UI/ReDoc). - Modular Design: Cấu trúc dự án sử dụng APIRouter để phân chia module (Users, Items, Auth) giúp dễ dàng bảo trì. - Data Validation: Sử dụng Pydantic schemas để định nghĩa và kiểm tra dữ liệu đầu vào/đầu ra tự động. - Database Setup: Tích hợp SQLAlchemy, thiết lập kết nối cơ sở dữ liệu và quản lý Sessions. 16/10/2025 16/10/2025 5 Advanced FastAPI Implementation (Part 2) - Security \u0026amp; Auth: Triển khai cơ chế xác thực bảo mật sử dụng OAuth2 với Password Flow và JWT Tokens (Access/Refresh tokens). - Database Operations: Xây dựng đầy đủ các API CRUD, xử lý quan hệ dữ liệu (Relationships) trong SQLAlchemy. - Testing \u0026amp; CI/CD: Viết Unit/Integration tests với pytest. Thiết lập pipeline (GitHub Actions) để tự động test và deploy ứng dụng (Zero-downtime). 17/10/2025 17/10/2025 Thành tựu tuần 6: Vận hành ECS thành thạo: Đã đóng gói và triển khai thành công ứng dụng Full-stack lên Amazon ECS, nắm vững các chiến lược deployment (Rolling/Blue-Green). Tối ưu hóa quy trình DevOps: Xây dựng thành công pipeline CI/CD không máy chủ và giảm độ trễ truy cập ứng dụng từ 200ms xuống 30ms nhờ CloudFront. Kiến trúc hệ thống tin cậy: Thiết kế hệ thống xử lý tin nhắn bất đồng bộ, đảm bảo tính tách biệt và khả năng mở rộng giữa các thành phần. Xây dựng Secure API: Hoàn thiện Backend với FastAPI bao gồm đầy đủ các tính năng: Xác thực JWT, kết nối Database qua ORM và kiểm thử tự động. "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/1-worklog/1.7-week7/","title":"Worklog Tuần 7","tags":[],"description":"","content":"Mục tiêu tuần 7: Ôn tập và củng cố kiến thức lý thuyết về các dịch vụ cốt lõi của AWS và nguyên tắc kiến trúc tốt nhất. Luyện làm các câu hỏi thi AWS Cloud Practitioner hàng ngày để cải thiện khả năng nhận diện dịch vụ và phân tích tình huống. Tăng cường hiểu biết về bảo mật AWS, thiết kế mạng, chiến lược lưu trữ, các lựa chọn compute và mô hình sẵn sàng của cơ sở dữ liệu. Xây dựng khả năng lựa chọn dịch vụ AWS phù hợp dựa trên yêu cầu doanh nghiệp, chi phí và kỳ vọng vận hành. Công việc thực hiện trong tuần này: Day Task Start Date Completion Date Reference Material 1 Cloud Concepts \u0026amp; Well-Architected Framework - Cloud Value: Nghiên cứu lợi ích của Cloud: chuyển đổi CapEx sang OpEx, khả năng co giãn (Elasticity) và đổi mới nhanh chóng. - Performance Services: Phân biệt kịch bản sử dụng: CloudFront (Caching content), Global Accelerator (Routing qua AWS backbone), và Route 53 (DNS Management). - Well-Architected Framework: Ôn tập 6 trụ cột (Operational Excellence, Security, Reliability, Performance, Cost, Sustainability) và các từ khóa liên quan. - Infrastructure as Code: Hiểu vai trò của CloudFormation (Automated deployment) và AWS Service Catalog (Quản lý danh mục dịch vụ). 20/10/2025 20/10/2025 Module Review 2 Networking, VPC Components \u0026amp; Hybrid Connectivity - VPC Structure: Ôn tập CIDR, Subnet isolation và quy hoạch mạng Public/Private. - Hybrid Connectivity: So sánh AWS Site-to-Site VPN (Internet, encrypted) và AWS Direct Connect (Dedicated, low latency). - Gateways: Phân biệt Internet Gateway (Inbound/Outbound cho Public subnet) và NAT Gateway (Outbound only cho Private subnet). - Security Layers: So sánh Security Groups (Stateful, cấp Instance) và Network ACLs (Stateless, cấp Subnet). - Routing: Nghiên cứu các chính sách Route 53: Failover, Weighted, Geolocation. 21/10/2025 21/10/2025 Module Review 3 Databases, High Availability \u0026amp; Migration - Amazon RDS: Phân biệt Multi-AZ (High Availability/Disaster Recovery) và Read Replicas (Scaling read workloads). - Security: Tìm hiểu mã hóa Database (KMS) và xác thực bằng IAM Auth cho MySQL/PostgreSQL. - Migration Tools: Sử dụng DMS cho việc di chuyển dữ liệu liên tục và SCT để chuyển đổi schema giữa các engine khác nhau. - Use Cases: Phân biệt DynamoDB (NoSQL, micro-second latency) và Redshift (Analytics, Petabyte-scale). 22/10/2025 22/10/2025 Module Review 4 S3 Storage Architecture \u0026amp; Security Controls - Storage Classes: Lựa chọn lớp lưu trữ tối ưu: Standard, Intelligent-Tiering (tự động tối ưu chi phí), Glacier/Deep Archive (lưu trữ lâu dài). - Storage Comparison: Phân biệt S3 (Object), EFS/FSx (Shared File), và EBS (Block storage cho EC2). - Access Control: Phân biệt IAM Policies (User-based) và S3 Bucket Policies (Resource-based). Cấu hình Block Public Access. - Disaster Recovery: Tìm hiểu tính năng Cross-Region Replication (CRR) để đảm bảo an toàn dữ liệu cấp vùng. 23/10/2025 23/10/2025 Module Review 5 Compute, Pricing \u0026amp; Operational Efficiency - EC2 Pricing Models: Lựa chọn mô hình giá: On-Demand (ngắn hạn, không đoán trước), Reserved/Savings Plans (dài hạn, ổn định), Spot (linh hoạt, giá rẻ). - Architecture: Thiết kế kiến trúc HA với Elastic Load Balancer kết hợp Auto Scaling Group. - Serverless: Ôn tập AWS Lambda cho các tác vụ event-driven và tối ưu chi phí vận hành. - Operational Tools: Sử dụng EC2 Image Builder để tạo AMI chuẩn và Compute Optimizer để gợi ý tối ưu tài nguyên. 24/10/2025 24/10/2025 Module Review Thành tựu tuần 7: Hoàn thành 2–3 bộ đề luyện thi AWS Cloud Practitioner mỗi ngày với sự tiến bộ đều đặn về hiệu suất. Ôn lại lý thuyết và các tình huống thực tế liên quan các miền chính của AWS bao gồm Compute, Storage, Networking, Security và Databases. Cải thiện khả năng phân biệt các dịch vụ AWS có chức năng tương tự như: Elastic Load Balancing vs Route 53 vs Global Accelerator, S3 storage classes vs EBS vs EFS, Multi-AZ vs Read Replicas trong RDS. Hiểu sâu cơ sở lý thuyết về các lựa chọn tối ưu hóa chi phí (On-Demand, Reserved Instances, Savings Plans, Spot Instances). Củng cố kiến thức lý thuyết về quản lý danh tính và truy cập: IAM users, roles, policies, MFA, nguyên tắc least privilege. Nâng cao hiểu biết về AWS Well-Architected Framework và sáu trụ cột của nó cho các câu hỏi yêu cầu trong kỳ thi. "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/1-worklog/1.8-week8/","title":"Worklog Tuần 8","tags":[],"description":"","content":"Mục tiêu tuần 8: Nghiên cứu Serverless: Hiểu sâu lý thuyết về AWS Lambda, cơ chế Event-driven và tầm quan trọng của Lambda Layers. Nghiên cứu GenAI: Tìm hiểu tổng quan về Amazon Bedrock, các mô hình Foundation Models (FM) và các use-case cơ bản. Kiến trúc API: Nắm vững lý thuyết về Amazon API Gateway và vai trò của nó trong kiến trúc Microservices. Thực hành Lab (Weekend): Xây dựng thành công luồng xử lý ảnh tự động: Upload S3 -\u0026gt; Trigger Lambda (kèm Layer xử lý ảnh) -\u0026gt; Resize -\u0026gt; Lưu S3 đích. Công việc thực hiện trong tuần này: Day Task Start Date Completion Date Reference Material 1 AWS Lambda Core Concepts (Research) - Execution Model: Tìm hiểu vòng đời của Lambda (Init, Invoke, Shutdown) và khái niệm Cold Start. - Resource Model: Hiểu mối quan hệ giữa Memory và CPU (tăng RAM = tăng CPU power). - Billing: Nghiên cứu cách tính phí: số lần request + thời gian chạy (GB-seconds). - Concurrency: Phân biệt Reserved Concurrency (đảm bảo tài nguyên) và Provisioned Concurrency (giảm Cold Start). 27/10/2025 27/10/2025 AWS Lambda Docs 2 Amazon Bedrock \u0026amp; GenAI Overview (Research) - Key Concepts: Tìm hiểu về Foundation Models (Claude, Titan, Stable Diffusion), Tokens, và Inference parameters (Temperature, Top P). - Bedrock Features: Nghiên cứu lý thuyết về Knowledge Bases (RAG) để train dữ liệu riêng và Agents để thực thi tác vụ. - Security: Tìm hiểu cam kết bảo mật của Bedrock (dữ liệu khách hàng không dùng để train lại model của AWS). - Use Cases: Đọc case study về tóm tắt văn bản và tạo ảnh. 28/10/2025 28/10/2025 Bedrock User Guide 3 API Gateway Fundamentals (Research) - Architecture: Tìm hiểu vai trò của API Gateway: Authentication, Throttling, Caching. - Types: So sánh REST API (Feature-rich) vs HTTP API (Low-cost/Low-latency) vs WebSocket API (Real-time). - Integration: Nghiên cứu lý thuyết về Lambda Proxy Integration (cách API GW chuyển nguyên event object cho Lambda). - Endpoint Types: Phân biệt Edge-optimized (toàn cầu), Regional (trong vùng), và Private endpoints (nội bộ VPC). 29/10/2025 29/10/2025 API Gateway Concepts 4 S3 Event Notifications \u0026amp; IAM Preparation (Pre-Lab) - Event Patterns: Tìm hiểu cơ chế S3 Event Notifications (cụ thể là s3:ObjectCreated:*) để kích hoạt Lambda function. - IAM Permissions: Soạn thảo chính sách (IAM Policy) cần thiết: Lambda cần quyền s3:GetObject (bucket nguồn), s3:PutObject (bucket đích) và logs:CreateLogGroup. - Library Research: Tìm hiểu về thư viện Pillow (PIL) của Python để xử lý ảnh và quy trình đóng gói thư viện này vào Lambda Layer (do môi trường Lambda mặc định không có). 30/10/2025 30/10/2025 S3 Event Notifications 5 Lab: Serverless Image Resizer (Implementation) - Lambda Layer: Thực hiện tạo và upload Layer chứa thư viện Pillow (tương thích Python 3.x runtime). - Coding: Viết Lambda function (Python/Boto3) để lấy ảnh từ sự kiện S3, resize về thumbnail (ví dụ 128x128) và lưu sang bucket đích. - Configuration: Cấu hình S3 Bucket Trigger để tự động chạy hàm khi có file mới upload vào folder /raw. - Testing \u0026amp; Debug: Upload ảnh test, kiểm tra kết quả trong bucket đích và xem CloudWatch Logs để fix lỗi import hoặc permission. 31/10/2025 01/11/2025 Serverless Image Resizing Thành tựu tuần 8: Nắm vững lý thuyết Serverless \u0026amp; AI: Hiểu rõ bức tranh tổng thể về Serverless (Lambda, API Gateway) và xu hướng Generative AI (Bedrock) thông qua việc đọc tài liệu chuyên sâu. Hiểu sâu về Lambda Environment: Nhận thức được tầm quan trọng của Lambda Layers khi làm việc với các thư viện ngoại lai như Pillow hay Pandas, tránh việc code quá nặng. Thực hành thành công Event-Driven: Xây dựng hoàn chỉnh ứng dụng thực tế đầu tiên: hệ thống xử lý ảnh tự động (Image Processing Pipeline) không cần máy chủ. Kỹ năng IAM \u0026amp; Debug: Biết cách cấp quyền tối thiểu (Least Privilege) cho Lambda và sử dụng CloudWatch Logs để truy vết lỗi trong quá trình thực thi code. "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/1-worklog/1.9-week9/","title":"Worklog Tuần 9","tags":[],"description":"","content":"Mục tiêu tuần 9: Hoàn thành thiết lập kiến trúc Microservice bằng .NET Aspire và xây dựng toàn bộ Shared Libraries cốt lõi. Triển khai hoàn chỉnh User Service với tích hợp xác thực AWS Cognito và logic tự động tạo user/profile. Triển khai hoàn chỉnh Wallet Service với logic quản lý số dư, quản lý Money Jar (Hũ tiền), Goals Tracking, và cơ chế Jar Expiry Processing. Thiết lập API Gateway, cấu hình Polly, và hoàn tất Integration Testing cho luồng End-to-End (User-Wallet). Công việc thực hiện trong tuần này: Day Task Start Date Completion Date Reference Material 1 Thiết lập Kiến trúc Microservice \u0026amp; Thư viện Chia sẻ - Khởi tạo giải pháp .NET Aspire và cấu trúc hóa 6 Microservices (User, Wallet, Transaction, Report, Notification, AI Integration Service). - Cấu hình Service Discovery và Docker Compose cho môi trường phát triển cục bộ. - Xây dựng các Shared Libraries cốt lõi: Common.DTOs (với ApiResponse\u0026lt;T\u0026gt;), Common.Authentication (JWT), Common.Messaging (MassTransit/RabbitMQ), Common.Repositories (UoW Pattern), và Common.Middlewares (Rate Limiting, Correlation ID). 03/11/2025 03/11/2025 Day 1 Docs 2 Triển khai User Service \u0026amp; Tích hợp Xác thực - Thiết lập PostgreSQL Database (user_service_db) và thiết kế Entity User (sử dụng Guid.CreateVersion7(), Soft Delete Filter). - Tích hợp xác thực AWS Cognito (JWT Bearer Authentication) và tạo middleware trích xuất CognitoSub. - Triển khai logic tự động tạo user record khi đăng nhập lần đầu tiên. - Triển khai Core APIs: GET /api/users/me (Lấy/Tạo profile), PUT /api/users/me (Cập nhật), và POST /api/users/complete-profile. 04/11/2025 04/11/2025 Day 2 Docs 3 Wallet Service - Phần 1: Quản lý Ví \u0026amp; Logic Phân bổ - Thiết lập PostgreSQL Database (wallet_service_db) và thiết kế Entities Wallet, MoneyJar, BudgetPeriod. - Triển khai Message Consumer để tự động tạo Wallet khi nhận sự kiện UserCreated, đồng thời tạo hũ \u0026ldquo;Thu nhập\u0026rdquo; mặc định. - Triển khai các Wallet APIs cốt lõi: Deposit, Withdraw (chỉ từ Available Balance), Reconcile (Đồng bộ số dư tổng), và Soft Delete/Archive Wallet. - Triển khai Money Jar CRUD APIs cơ bản. 05/11/2025 05/11/2025 Day 3 Docs 4 Wallet Service - Phần 2: Money Jar, Goals \u0026amp; Budget - Hoàn thành CRUD cho Money Jar, bao gồm logic tính toán lại AvailableBalance khi update AllocatedAmount. - Tích hợp Goals Tracking (tính ProgressPercent) và logic phát sự kiện GoalAchieved. - Triển khai Jar Operations: Deposit, Withdraw, Transfer giữa các hũ, và Reconcile Jar Balance. - Triển khai Budget Threshold \u0026amp; Over-Budget Logic (phát events cảnh báo) và Jar Expiry Processing Service (xử lý Income Jar auto-reset, Expense Jar Grace Period/Auto-Return). 06/11/2025 06/11/2025 Day 4 Docs 5 Tích hợp End-to-End \u0026amp; Thử nghiệm - Thiết lập API Gateway (Routing, CORS, Rate Limiting). - Cấu hình giao tiếp Service-to-Service với HTTP Client Factory và Polly (Retry Policy, Circuit Breaker). - Thực hiện Integration Testing cho luồng End-to-End: New User Onboarding, Jar Creation, Wallet/Jar Operations (Deposit/Withdraw/Transfer/Reconcile), và Goal Achievement. - Thử nghiệm Security (JWT Expiration, Authorization) và Concurrency (Balance Updates). 07/11/2025 07/11/2025 Day 5 Docs Thành tựu Tuần 9: Kiến trúc Nền tảng Microservice Đã Thiết lập: Sử dụng .NET Aspire để định hình kiến trúc Microservice cho 6 dịch vụ. Hoàn thiện bộ Shared Libraries cốt lõi, bao gồm cả cấu hình MassTransit/RabbitMQ. User Service Đã Hoàn thiện: Tích hợp thành công AWS Cognito cho cơ chế xác thực JWT. Triển khai logic tự động tạo user profile và API hoàn thiện hồ sơ. Wallet Service Đã Hoàn thiện: Triển khai logic quản lý số dư ba thành phần: TotalBalance, AllocatedBalance, AvailableBalance. Hoàn thành Money Jar Management với Goals Tracking (Target, Progress) và phát sự kiện GoalAchieved. Logic Nghiệp vụ Phức tạp Đã triển khai: Hoàn thiện các nghiệp vụ như Wallet/Jar Reconciliation (Đồng bộ số dư) và Jar Expiry Processing (cho phép Income Jar auto-reset và Expense Jar có grace period). Hệ thống Ổn định và Đã Tích hợp: API Gateway và cơ chế chịu lỗi Polly (Retry, Circuit Breaker) đã được cấu hình. Toàn bộ luồng nghiệp vụ chính đã được Integration Testing thành công (từ Cognito -\u0026gt; User Service -\u0026gt; Wallet Service). "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/2-proposal/","title":"Bản đề xuất","tags":[],"description":"","content":"Ứng dụng quản lý tài chính cá nhân (Vicobi) Bạn có thể đọc toàn bộ proposal ở đây: Vicobi Proposal 1. Tóm tắt điều hành Dự án Vicobi (Personal Finance Management App) hướng đến việc cung cấp một nền tảng quản lý tài chính cá nhân thông minh, hiện đại và mang tính tự động hóa cao. Vicobi đơn giản hóa việc quản lý tài chính qua 4 trụ cột chính:\nGhi chép thông minh (Smart Recording): Nhập liệu bằng giọng nói và quét hóa đơn, loại bỏ rào cản nhập liệu thủ công. Lập ngân sách theo mục tiêu (Goal-based Budgeting): Tự động hóa tạo và quản lý các hũ tiền (money jars) linh hoạt. Phân tích \u0026amp; Kiểm soát: Cung cấp báo cáo trực quan và hệ thống cảnh báo thông minh. Trợ lý tài chính (AI Chatbot): Tích hợp Chatbot AI đóng vai trò tư vấn viên, hỗ trợ giải đáp và nâng cao kiến thức tài chính. Về mặt công nghệ, Vicobi được xây dựng trên kiến trúc Microservices sử dụng .NET Aspire và FastAPI, triển khai trên AWS Cloud, đảm bảo tính linh hoạt và an toàn dữ liệu. Quy trình phát triển tuân theo mô hình Agile/Scrum (2 tuần/sprint trong giai đoạn phát triển chính), với mục tiêu hoàn thành MVP trong 2 tháng thực thi.\n2. Tuyên bố vấn đề Vấn đề hiện tại Trong thị trường năng động hiện nay, người dùng gặp khó khăn trong việc kiểm soát tài chính do \u0026ldquo;sức ỳ hành vi\u0026rdquo; — ngại ghi chép thủ công từng giao dịch. Các ứng dụng hiện có (như Money Lover, Misa Money Keeper) vẫn dựa nhiều vào nhập liệu bằng tay, gây ra tình trạng \u0026ldquo;mệt mỏi khi nhập liệu\u0026rdquo; (input fatigue) và tỷ lệ bỏ cuộc cao.\nGiải pháp Vicobi giải quyết vấn đề bằng cách tự động hóa cao độ quy trình nhập liệu thông qua AWS Cloud và Microservices:\nCông nghệ lõi: Tích hợp AI xử lý giọng nói tiếng Việt (Voice-to-Text) và nhận diện hóa đơn (OCR) chi tiết. Kiến trúc tối ưu: Sử dụng AWS ECS Fargate chạy mô hình Multi-container Task (gộp Backend .NET và AI Service) để giảm chi phí hạ tầng nhưng vẫn đảm bảo giao tiếp liền mạch. Frontend hiện đại: Sử dụng Next.js được lưu trữ trên Amazon S3 và phân phối toàn cầu qua Amazon CloudFront. Lợi ích và hoàn vốn đầu tư (ROI) Giải pháp mang lại lợi thế cạnh tranh rõ rệt:\nGiá trị người dùng: Giảm hơn 70% thao tác thủ công. Độ chính xác nhận diện giọng nói đạt 90% và trích xuất hóa đơn đạt 80%. Hiệu quả kinh tế: Tận dụng tối đa AWS Free Tier (S3, CloudFront, Cognito). Ngân sách vận hành tinh gọn khoảng ~$60/tháng cho hạ tầng và ~$15/tháng cho AI compute. Hoàn vốn: Dự kiến đạt ROI trong 6–12 tháng nhờ tiết kiệm thời gian và tăng hiệu suất. Khả năng mở rộng: Kiến trúc Microservices sẵn sàng cho việc tích hợp Mobile App hoặc Open Banking. 3. Kiến trúc giải pháp Hệ thống được thiết kế theo mô hình Microservices phân tán, sử dụng API Gateway làm điểm nhập duy nhất.\nChi tiết Tech Stack: Thành phần Công nghệ Chi tiết Frontend Next.js 16 App Router, TypeScript, Tailwind CSS, Zustand, React Query. Backend Core .NET Aspire Điều phối Microservices (User, Wallet, Transaction, Report, Notification). AI Service FastAPI (Python) Xử lý Voice (PhoWhisper), OCR (Bedrock), Chatbot (RAG). Database Polyglot PostgreSQL, MongoDB, Elasticsearch, Qdrant (Vector DB). Messaging RabbitMQ Giao tiếp bất đồng bộ giữa các service. Luồng hoạt động trên AWS: Truy cập: Người dùng truy cập qua Route 53, được bảo vệ bởi AWS WAF và tăng tốc bởi CloudFront. Xác thực: Amazon Cognito quản lý định danh và cấp phát JWT Token. Xử lý API: Request đi qua API Gateway, kết nối an toàn qua AWS PrivateLink tới Application Load Balancer (ALB). Compute: ALB phân phối tải tới các container trong ECS Fargate (nằm trong Private Subnet). DevOps: Quy trình CI/CD tự động hóa hoàn toàn bằng GitLab, build image đẩy lên Amazon ECR và update task trên ECS. 4. Triển khai kỹ thuật Các giai đoạn triển khai Dự án kéo dài 4 tháng (bao gồm thực tập):\nTháng 0 (Pre-internship): Lên ý tưởng và kế hoạch tổng thể. Tháng 1 (Foundation): Học AWS, nâng cấp kỹ năng .NET/Next.js/AI. Thiết lập VPC, IAM. Tháng 2 (Design): Thiết kế kiến trúc High-level \u0026amp; Detailed trên AWS. Tháng 3-4 (Realization): Coding, Integration Testing, Deploy lên AWS Production, thiết lập Monitoring. Sau tháng 5: Nghiên cứu phát triển Mobile App. Yêu cầu kỹ thuật chi tiết: Frontend: Triển khai Next.js 16 trên S3 + CloudFront. Sử dụng Origin Access Control (OAC) để bảo mật bucket. Backend: Sử dụng .NET Aspire để quản lý cấu hình Cloud-native. Database-per-service: PostgreSQL \u0026amp; MongoDB. Elasticsearch cho tìm kiếm giao dịch phức tạp. Background Jobs: Sử dụng Hangfire. AI Service Pipelines: Voice: Tiền xử lý bằng Pydub, Model PhoWhisper-small (VinAI) cho tiếng Việt. OCR: Amazon Bedrock (Claude 3.5 Sonnet Multimodal) để trích xuất thông tin hóa đơn chính xác. Chatbot (RAG): Knowledge Base lưu trong Qdrant, sinh câu trả lời qua Amazon Bedrock (Claude 3.5 Sonnet). Bảo mật: Mã hóa dữ liệu đường truyền (HTTPS/TLS 1.2+) và lưu trữ (AES-256). Quản lý bí mật (Secrets) chưa tích hợp sâu (đang ở mức MVP), sẽ nâng cấp lên AWS Secrets Manager trong tương lai. 5. Lộ trình \u0026amp; Mốc triển khai (Sprints) Giai đoạn thực thi chính được chia thành 4 Sprint:\nSprint 1: Core Foundation Xác thực (Cognito), Quản lý Ví (Wallets), Hũ chi tiêu (Spending Jars). Sprint 2: Core Features Giao dịch (CRUD), Xử lý giọng nói AI (Voice Processing). Sprint 3: Analytics Báo cáo/Biểu đồ, Hệ thống thông báo (SES), Message Broker. Sprint 4: Stabilization Kiểm thử tích hợp (Integration Testing), Tinh chỉnh UI, Deploy lên AWS ECS \u0026amp; CloudFront. Testing \u0026amp; Go-live: Cấu hình Domain, SSL, Monitoring Dashboard, UAT và bảo vệ đồ án. 6. Ước tính ngân sách Dựa trên bảng dự toán chi tiết cho giai đoạn MVP.\nBạn có thể xem chi tiết bảng dự toán chi phí bằng cách tải về các tệp sau: 📊 Tệp định dạng CSV 💾 Tệp định dạng JSON\nDịch vụ AWS Thành phần / Sử dụng Chi Phí (USD/tháng) Elastic Load Balancing Application Load Balancer $18.98 Amazon ECS Fargate (vCPU \u0026amp; Memory) $17.30 Amazon VPC VPC Endpoints \u0026amp; NAT $10.49 AWS WAF Web ACL \u0026amp; Requests $7.20 Amazon API Gateway API Calls \u0026amp; Data Transfer $2.50 Amazon CloudFront Data Transfer Out $2.00 Amazon ECR Storage $1.00 Amazon Route 53 Hosted Zones $0.54 Amazon S3 Standard Storage $0.34 TỔNG CHI PHÍ AWS ~$60.35 Chi phí khác:\nHạng mục Chi tiết Chi Phí (USD/tháng) AI Compute / Tooling Gemini API, Amazon Bedrock ~$15.00 TỔNG CỘNG DỰ ÁN ~$75.35 / tháng (Dựa trên giá On-Demand khu vực Singapore - ap-southeast-1)\n7. Đánh giá rủi ro Rủi ro chính: Lộ thông tin người dùng (Impact: High), Mất kết nối AWS Region (Impact: High), AI nhận diện sai (Impact: Medium). Chiến lược giảm thiểu: Bảo mật: Mã hóa AES-256, HTTPS, IAM Least Privilege, AWS WAF. High Availability: Triển khai Multi-AZ cho ECS và ALB. AI: Cải thiện model liên tục với dữ liệu thực tế. Resilience: Sử dụng RabbitMQ nội bộ để xử lý bất đồng bộ và retry. Kế hoạch dự phòng (Disaster Recovery): Sử dụng IaC (Infrastructure as Code) để khôi phục nhanh hạ tầng. 8. Kết quả kỳ vọng \u0026amp; Đội ngũ Kết quả mong đợi của dự án Nhập liệu tài chính tự động: Ứng dụng giúp người dùng tránh nhập liệu thủ công, chỉ cần chụp ảnh hóa đơn hoặc ghi âm giọng nói để hệ thống tự động phân loại chi tiêu. Quản lý tài chính trực quan: Người dùng có thể xem biểu đồ chi tiêu, báo cáo hàng tháng và nhận đề xuất tiết kiệm dựa trên hành vi tiêu dùng. Trải nghiệm người dùng tối thiểu: Giao diện web thân thiện, thiết kế hiện đại, được tối ưu hóa cho thiết bị di động và phù hợp với người mới bắt đầu quản lý tài chính. Hệ thống ổn định, có khả năng mở rộng: Kiến trúc microservices giúp dễ dàng thêm các tính năng mới như nhắc nhở chi tiêu, phân tích dự đoán AI hoặc mở rộng sang ứng dụng di động. Nâng cao kỹ năng nhóm phát triển: Các thành viên dự án có quyền truy cập thực tế vào các quy trình DevOps, triển khai CI/CD và tối ưu hóa ứng dụng trên nền tảng đám mây. Hạn chế của dự án Mô hình AI Việt Nam còn hạn chế: Khả năng nhận dạng giọng nói vùng miền hoặc hóa đơn viết tay vẫn chưa đạt độ chính xác cao.\nKhông có ứng dụng di động riêng biệt: Phiên bản MVP chỉ hỗ trợ nền tảng web, không có ứng dụng di động gốc.\nĐội ngũ thực hiện (Team): Họ tên Vai trò Email Lê Vũ Phương Hòa Backend Developer (Leader) hoalvpse181951@fpt.edu.vn Nguyễn Văn Anh Duy AI Developer (Member) duynvase181823@fpt.edu.vn Uông Tuấn Vũ Frontend Developer (Member) vuutse180241@fpt.edu.vn Trần Huỳnh Bảo Minh AI Developer (Member) baominhbrthcs@gmail.com Mentor Support:\nNguyễn Gia Hưng - Head of Solution Architects Văn Hoàng Kha - Cloud Security Engineer "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/5-workshop/5.2-prerequiste/5.2.2-prepare-data/","title":"Chuẩn bị dữ liệu nguồn","tags":[],"description":"","content":"Tổng quan Khởi tạo một kho lưu trữ đối tượng (S3 Bucket) để chứa các tài liệu gốc (PDF, Word, Text). Đây đóng vai trò là \u0026ldquo;nguồn sự thật\u0026rdquo; (Source of Truth) mà Knowledge Base sẽ truy cập để đọc hiểu, phân tích và đồng bộ hóa kiến thức cho AI. Bạn có thể lưu trữ kiến thức liên quan đến lĩnh vực của bạn sử dụng trong việc tạo trợ lý cá nhân hoặc Chatbot cho riêng bạn.\nChuẩn bị dữ liệu Chúng ta sẽ tạo một S3 Bucket để lưu trữ tài liệu gốc, đóng vai trò là nguồn tri thức cho Chatbot.\nBước 1. Tạo S3 Bucket\nTruy cập dịch vụ S3 từ thanh tìm kiếm. AWS Region: Chọn United States (N. Virginia us-east-1). Click Create bucket. Cấu hình thông tin Bucket: Bucket Type: Chọn General purpose Bucket name: Nhập rag-workshop-demo Object Ownership: Giữ mặc định ACLs disabled. Block Public Access settings: Giữ mặc định (Đã chọn Block all public access). Kéo xuống cuối trang, Click Create bucket. Kiểm tra tạo S3 Bucket thành công. Bước 2. Tải lên tài liệu mẫu\nĐây tài liệu mẫu, liên quan để tổng quan về kiến thức điện toán đám mây của AWS. Bạn có thể sử dụng để chạy demo hoặc upload dữ liệu của bạn. Tệp định dạng PDF\nTại danh sách Buckets, Click vào tên bucket bạn vừa tạo. Click Upload. Tại giao diện Upload: Click Add files. Chọn file tài liệu mẫu đính kèm ở phần trên hoặc file từ máy tính của bạn (Khuyên dùng file PDF hoặc Word có nhiều nội dung văn bản). Khi upload file xong, chọn file vừa upload, kéo xuống cuối trang, Click Upload. Khi thấy thông báo màu xanh \u0026ldquo;Upload succeeded\u0026rdquo;, Click Close. "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/5-workshop/5.2-prerequiste/","title":"Chuẩn bị môi trường","tags":[],"description":"","content":"Mục tiêu Trước khi bắt tay vào xây dựng ứng dụng, chúng ta cần thiết lập một nền tảng vững chắc. Giống như việc chuẩn bị nguyên liệu trước khi nấu ăn, phần này đảm bảo rằng tài khoản AWS của bạn đã sẵn sàng với đầy đủ quyền hạn và dữ liệu cần thiết.\nTrong phần này, chúng ta sẽ hoàn thành 3 mục tiêu khởi tạo quan trọng:\nChọn Region (Vùng): Thiết lập môi trường làm việc tại vùng United States N. Virginia (us-east-1) để tối ưu hóa tốc độ kết nối và đảm bảo tính sẵn sàng của dịch vụ. Kích hoạt Model (Model Access): Kiểm tra và đảm bảo tài khoản có quyền gọi model Anthropic Claude 3 – \u0026ldquo;bộ não\u0026rdquo; ngôn ngữ chính của hệ thống. Chuẩn bị Dữ liệu (Data Setup): Khởi tạo kho lưu trữ (S3 Bucket) và tải lên tài liệu nguồn để phục vụ cho quá trình nạp kiến thức (Ingestion) sau này. Các thành phần chính Trong phần chuẩn bị này, chúng ta sẽ tương tác với các thành phần sau:\nAWS Management Console (Region Selector): Giao diện quản lý chung để chuyển đổi Region làm việc sang United States N. Virginia. Amazon Bedrock (Model Access \u0026amp; Playground): Nơi quản lý quyền truy cập các mô hình nền tảng (Foundation Models) và công cụ chat để kiểm tra nhanh khả năng phản hồi của AI. Amazon S3 (Simple Storage Service): Dịch vụ lưu trữ đối tượng, nơi chúng ta sẽ tạo Bucket để chứa các file tài liệu gốc (PDF, Word, Text). Các Bước Thực hiện Kiểm tra truy cập Model Chuẩn bị dữ liệu nguồn "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/5-workshop/5.3-knowledge-base/5.3.2-sync-data/","title":"Kiểm tra Vector Store và Đồng bộ Dữ liệu","tags":[],"description":"","content":"Mục tiêu Trước khi AI có thể trả lời, dữ liệu phải được nhập vào kho lưu trữ vector (Vector Store). Chúng ta sẽ thực hiện kiểm tra \u0026ldquo;Trước và Sau\u0026rdquo; để thấy rõ cách Bedrock tự động mã hóa và lưu trữ dữ liệu vào OpenSearch.\nCác Bước Thực hiện Bước 1: Kiểm tra Vector Store (Trạng thái Rỗng)\nChúng ta sẽ truy cập trực tiếp vào Amazon OpenSearch Serverless để xác nhận rằng chưa có dữ liệu nào tồn tại.\nTrong thanh tìm kiếm AWS Console, gõ Amazon OpenSearch Service và chọn Amazon OpenSearch Service. Trong menu bên trái, ở phần Serverless, chọn Collections. Nhấp vào tên Collection mới được tạo bởi Bedrock (thường có tên dạng bedrock-knowledge-data...). Trên trang chi tiết Collection, nhấp vào nút Open Dashboard (nằm ở góc trên bên phải màn hình).\nLưu ý: Nếu được yêu cầu đăng nhập, hãy sử dụng thông tin đăng nhập AWS hiện tại của bạn. Trong giao diện OpenSearch Dashboard: Nhấp vào biểu tượng Menu (3 đường ngang) ở góc trên bên trái. Chọn Dev Tools (thường nằm ở cuối danh sách menu). Trong ngăn Console (bên trái), nhập lệnh sau để kiểm tra dữ liệu: GET _search { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} } } Nhấp vào nút Play (Run) (tam giác nhỏ bên cạnh dòng lệnh). Kết quả: Quan sát ngăn bên phải, hits -\u0026gt; total -\u0026gt; value là 0. Bước 2: Đồng bộ Dữ liệu\nBây giờ chúng ta sẽ kích hoạt Bedrock để đọc các file từ S3 và tải chúng vào OpenSearch.\nQuay lại tab Amazon Bedrock trên trình duyệt. Chọn Knowledge bases trong menu bên trái và nhấp vào tên KB bạn vừa tạo. Cuộn xuống phần Data source, đánh dấu vào ô (tick) bên cạnh tên nguồn dữ liệu (s3-datasource). Nhấp vào nút Sync (Màu cam). Chờ đợi: Quá trình này sẽ mất 5 - 10 phút tùy thuộc vào kích thước tài liệu mẫu. Chờ cho đến khi cột Sync status chuyển từ Syncing sang Available. Bước 3: Kiểm tra lại Vector Store (Đã có Dữ liệu)\nSau khi Bedrock báo hoàn tất Sync, chúng ta quay lại kho lưu trữ để xác minh dữ liệu đã được nhập thành công.\nChuyển sang tab OpenSearch Dashboard (vẫn còn mở từ Bước 1). Trong Dev Tools, nhấp lại nút Play (Run) với lệnh cũ: GET _search { \u0026#34;query\u0026#34;: { \u0026#34;match_all\u0026#34;: {} } } Kết quả: Phần hits -\u0026gt; total -\u0026gt; value sẽ lớn hơn 0 (ví dụ: 10, 20\u0026hellip; tùy thuộc vào số lượng đoạn văn bản). Bạn sẽ thấy chi tiết các vector (mảng số) và nội dung văn bản được lưu trữ trong trường _source. Chúc mừng! Bạn đã hoàn thành việc xây dựng \u0026ldquo;bộ não\u0026rdquo; cho AI. Dữ liệu đã được mã hóa và nằm an toàn trong Vector Database, sẵn sàng cho việc truy xuất.\n"},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/1-worklog/1.10-week10/","title":"Worklog Tuần 10","tags":[],"description":"","content":"Mục tiêu tuần 10: Hoàn thành việc triển khai Transaction Service (Tạo, Đọc, Cập nhật, Xóa) với luồng dòng tiền được kiểm soát chặt chẽ qua Wallet Service (kiểm tra và trừ số dư). Triển khai các tính năng nâng cao cho Transaction: Lọc nâng cao, Tìm kiếm toàn văn, Tags, và hỗ trợ AI Metadata. Thiết lập hoàn chỉnh Kiến trúc hướng sự kiện (Event-Driven Architecture) sử dụng RabbitMQ/MassTransit để đồng bộ dữ liệu giữa các dịch vụ (User, Wallet, Transaction). Hoàn tất Integration Testing và tối ưu hóa hiệu năng cho các luồng nghiệp vụ cốt lõi. Công việc thực hiện trong tuần này: Day Task Start Date Completion Date Reference Material 1 Thiết lập Kiến trúc Microservice \u0026amp; Thư viện Chia sẻ - Khởi tạo giải pháp .NET Aspire và cấu trúc hóa 6 Microservices (User, Wallet, Transaction, Report, Notification, AI Integration Service). - Cấu hình Service Discovery và Docker Compose cho môi trường phát triển cục bộ. - Xây dựng các Shared Libraries cốt lõi: Common.DTOs (với ApiResponse\u0026lt;T\u0026gt;), Common.Authentication (JWT), Common.Messaging (MassTransit/RabbitMQ), Common.Repositories (UoW Pattern), và Common.Middlewares (Rate Limiting, Correlation ID). 10/11/2025 10/11/2025 Day 1 Docs 2 Triển khai User Service \u0026amp; Tích hợp Xác thực - Thiết lập PostgreSQL Database (user_service_db) và thiết kế Entity User (sử dụng Guid.CreateVersion7(), Soft Delete Filter). - Tích hợp xác thực AWS Cognito (JWT Bearer Authentication) và tạo middleware trích xuất CognitoSub. - Triển khai logic tự động tạo user record khi đăng nhập lần đầu tiên. - Triển khai Core APIs: GET /api/users/me (Lấy/Tạo profile), PUT /api/users/me (Cập nhật), và POST /api/users/complete-profile. 11/11/2025 11/11/2025 Day 2 Docs 3 Wallet Service - Phần 1: Quản lý Ví \u0026amp; Logic Phân bổ - Thiết lập PostgreSQL Database (wallet_service_db) và thiết kế Entities Wallet, MoneyJar, BudgetPeriod. - Triển khai Message Consumer để tự động tạo Wallet khi nhận sự kiện UserCreated, đồng thời tạo hũ \u0026ldquo;Thu nhập\u0026rdquo; mặc định. - Triển khai các Wallet APIs cốt lõi: Deposit, Withdraw (chỉ từ Available Balance), Reconcile (Đồng bộ số dư tổng), và Soft Delete/Archive Wallet. - Triển khai Money Jar CRUD APIs cơ bản. 12/11/2025 12/11/2025 Day 3 Docs 4 Wallet Service - Phần 2: Money Jar, Goals \u0026amp; Budget - Hoàn thành CRUD cho Money Jar, bao gồm logic tính toán lại AvailableBalance khi update AllocatedAmount. - Tích hợp Goals Tracking (tính ProgressPercent) và logic phát sự kiện GoalAchieved. - Triển khai Jar Operations: Deposit, Withdraw, Transfer giữa các hũ, và Reconcile Jar Balance. - Triển khai Budget Threshold \u0026amp; Over-Budget Logic (phát events cảnh báo) và Jar Expiry Processing Service (xử lý Income Jar auto-reset, Expense Jar Grace Period/Auto-Return). 13/11/2025 13/11/2025 Day 4 Docs 5 Tích hợp End-to-End \u0026amp; Thử nghiệm - Thiết lập API Gateway (Routing, CORS, Rate Limiting). - Cấu hình giao tiếp Service-to-Service với HTTP Client Factory và Polly (Retry Policy, Circuit Breaker). - Thực hiện Integration Testing cho luồng End-to-End: New User Onboarding, Jar Creation, Wallet/Jar Operations (Deposit/Withdraw/Transfer/Reconcile), và Goal Achievement. - Thử nghiệm Security (JWT Expiration, Authorization) và Concurrency (Balance Updates). 14/11/2025 14/11/2025 Day 5 Docs Thành tựu Tuần 10: Transaction Service Hoàn thiện: Đã triển khai đầy đủ CRUD, luồng dòng tiền chặt chẽ, và cơ chế hoàn tiền tự động khi xóa. Hỗ trợ Tính năng Nâng cao: Lọc đa chiều và Tìm kiếm hiệu quả đã được tích hợp. Hỗ trợ Transaction Tags và lưu trữ AI Metadata (JSONB). Kiến trúc Hướng Sự kiện Ổn định: RabbitMQ/MassTransit đã hoạt động, đảm bảo sự đồng bộ số dư Jar giữa Transaction Service và Wallet Service. Đã xử lý thành công các sự kiện tạo giao dịch tự động. Hệ thống Ổn định và Được Kiểm thử: Toàn bộ Sprint đã được kiểm thử tích hợp (Integration Testing) và tối ưu hóa hiệu năng. "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/1-worklog/1.11-week11/","title":"Worklog Tuần 11","tags":[],"description":"","content":"Mục tiêu tuần 11: Hoàn thành việc triển khai Report Service sử dụng kiến trúc CQRS để tách biệt luồng đọc/ghi, đảm bảo hiệu năng cao cho các báo cáo phức tạp. Triển khai các tính năng phân tích nâng cao: Xu hướng chi tiêu, So sánh Ngân sách vs Thực tế, và tính năng Xuất báo cáo Excel đa sheet. Xây dựng Notification Service toàn diện hỗ trợ đa kênh: Email (qua AWS SES) và In-App (qua SignalR), cho phép người dùng tùy chỉnh cấu hình nhận tin. Thiết lập quy trình Tự động hóa cuối kỳ (Period End Automation) để xử lý tiền dư và chuẩn bị Backend sẵn sàng cho tích hợp AI (OCR/Voice). Công việc thực hiện trong tuần này: Day Task Start Date Completion Date Reference Material 1 Report Service Foundation \u0026amp; CQRS Setup - Khởi tạo Report Service, thiết lập Database PostgreSQL (report_service_db) và các Read Model entities (TransactionSummary, JarAnalytics). - Triển khai mẫu CQRS: Xử lý các sự kiện từ Transaction Service (TransactionCreated, Updated, Deleted) để cập nhật dữ liệu báo cáo theo thời gian thực. - Xây dựng các Basic Report APIs để lấy tóm tắt kỳ và thống kê cơ bản theo hũ. 17/11/2025 17/11/2025 Day 11 Docs 2 Advanced Analytics \u0026amp; Excel Export - Phát triển các API phân tích nâng cao: Xu hướng chi tiêu (ngày/tuần/tháng), so sánh ngân sách thực tế (Budget vs Actual), và tiến độ mục tiêu. - Tích hợp thư viện Excel (EPPlus/ClosedXML) để xuất báo cáo Multi-sheet (Lịch sử giao dịch, Phân tích hũ, Phân tích danh mục). - Cấu hình Caching cho các báo cáo để tối ưu hiệu năng truy vấn. 18/11/2025 18/11/2025 Day 12 Docs 3 Notification Service \u0026amp; Email Integration - Khởi tạo Notification Service kết nối MongoDB (UserPreferences, EmailHistory). - Tích hợp AWS SES và tạo template email cho các cảnh báo quan trọng (Vượt ngân sách, Số dư thấp, Đạt mục tiêu tiết kiệm). - Xây dựng API quản lý Preferences cho phép người dùng tùy chọn tần suất nhận tin (Daily/Weekly) và loại thông báo. 19/11/2025 19/11/2025 Day 13 Docs 4 Period End Automation \u0026amp; In-App Alerts - Thiết lập Job Scheduler (Hangfire/Quartz) để tự động hóa quy trình cuối kỳ: Tính toán tiền dư, hoàn về ví chính và tạo báo cáo tổng kết. - Triển khai hệ thống thông báo In-App thời gian thực qua SignalR Hub. - Xây dựng API đánh dấu đã đọc (mark-as-read) và quản lý số lượng thông báo chưa đọc (badge count). 20/11/2025 20/11/2025 Day 14 Docs 5 AI Service Integration (Backend Side) - Cập nhật Transaction Entity bổ sung các trường metadata AI (AiExtracted, ConfidenceScore, OriginalText). - Phát triển API Batch Transaction (POST /batch) hỗ trợ xử lý hóa đơn OCR nhiều món trong một lần gọi. - Cập nhật luồng xử lý để Backend nhận dữ liệu đã được người dùng review từ Client thay vì tự động tạo từ sự kiện AI. 21/11/2025 21/11/2025 Day 15 Docs Thành tựu Tuần 11: Report Service \u0026amp; Analytics Toàn diện: Đã vận hành ổn định hệ thống báo cáo với mẫu CQRS, cung cấp số liệu phân tích theo thời gian thực. Tính năng Xuất Excel hoạt động hoàn hảo với nhiều sheet chi tiết (Lịch sử giao dịch, Phân tích hũ, Phân tích danh mục). Hệ thống Thông báo Đa kênh: AWS SES đã được tích hợp để gửi email cảnh báo (Vượt ngân sách, Số dư thấp). Hệ thống SignalR hoạt động ổn định cho các thông báo thời gian thực ngay trên ứng dụng. Tự động hóa \u0026amp; Sẵn sàng cho AI: Job xử lý cuối kỳ đã hoạt động tự động: tính toán tiền dư và hoàn về ví chính chính xác. Backend đã hoàn tất API hỗ trợ Batch Transaction và lưu trữ AI Metadata (Confidence Score, Original Text). "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/1-worklog/1.12-week12/","title":"Worklog Tuần 12","tags":[],"description":"","content":"Mục tiêu tuần 12: Hoàn tất Kiểm thử tích hợp toàn hệ thống (End-to-End), đảm bảo các luồng nghiệp vụ phức tạp (đăng ký, giao dịch, chuyển tiền giữa các hũ) hoạt động trơn tru. Thực hiện Tối ưu hóa hiệu năng toàn diện: Đánh chỉ mục Database, Caching API và thực hiện Load Testing hỗ trợ 100 người dùng đồng thời. Tăng cường Bảo mật hệ thống: Rà soát xác thực/phân quyền, quản lý secrets qua biến môi trường và thiết lập HTTPS. Đóng gói và Tài liệu hóa: Hoàn thiện Docker hóa các dịch vụ, viết tài liệu Swagger đầy đủ và sẵn sàng kịch bản triển khai lên AWS. Công việc thực hiện trong tuần này: Day Task Start Date Completion Date Reference Material 1 Integration Testing - Full System - Thực hiện kiểm thử luồng End-to-End: Từ đăng ký User, tạo Wallet, Budget đến Giao dịch và Xử lý cuối kỳ. - Kiểm thử hệ thống sự kiện (Event-Driven): Xác minh tính toàn vẹn dữ liệu qua RabbitMQ và khả năng xử lý lỗi (retry, dead letter). - Kiểm thử các kịch bản lỗi (Error Scenarios): Token không hợp lệ, mất kết nối DB/RabbitMQ. 24/11/2025 24/11/2025 Day 16 Docs 2 Performance Optimization - Tối ưu hóa Database: Thêm Index cho các truy vấn chậm, cấu hình Connection Pooling. - Tối ưu hóa API: Áp dụng Response Caching, nén Gzip và phân trang cho dữ liệu lớn. - Thực hiện Load Testing (k6/JMeter): Mô phỏng 50-100 người dùng đồng thời, đảm bảo response time \u0026lt; 2s. 25/11/2025 25/11/2025 Day 17 Docs 3 Security Hardening - Rà soát bảo mật (Security Audit): Kiểm tra phân quyền (Authorization), validate đầu vào và chống SQL Injection. - Quản lý Secrets: Chuyển toàn bộ thông tin nhạy cảm sang biến môi trường và .NET User Secrets. - Cấu hình HTTPS: Thiết lập SSL self-signed cho local và cập nhật chính sách CORS. 26/11/2025 26/11/2025 Day 18 Docs 4 Bug Fixes \u0026amp; Code Quality - Sửa lỗi (Bug Fixing): Tập trung xử lý triệt để các lỗi P0, P1 phát hiện trong quá trình test. - Cải thiện chất lượng Code: Refactor các hàm phức tạp, thêm XML documentation và Unit tests cho logic quan trọng. - Nâng cấp Logging: Tích hợp Serilog với cấu trúc log chuẩn (Structured Logging) và Correlation IDs. 27/11/2025 27/11/2025 Day 19 Docs 5 Documentation \u0026amp; Deployment Prep - Hoàn thiện tài liệu API: Cập nhật Swagger đầy đủ ví dụ request/response và xuất Postman Collection. - Chuẩn bị triển khai: Viết Dockerfile cho từng service, file docker-compose.yml - Demo \u0026amp; Bàn giao: Cập nhật README, sơ đồ kiến trúc và thực hiện demo toàn bộ quy trình cho team. 28/11/2025 28/11/2025 Day 20 Docs Thành tựu Tuần 12: Chất lượng hệ thống được đảm bảo: Đã vượt qua các bài kiểm thử tích hợp (Integration Tests) bao gồm cả các kịch bản lỗi và xử lý sự kiện bất đồng bộ. Các lỗi nghiêm trọng (P0/P1) đã được xử lý triệt để, Code coverage đạt mục tiêu \u0026gt; 80%. Hiệu năng và Bảo mật tối ưu: Thời gian phản hồi API đạt mục tiêu \u0026lt; 2s nhờ tối ưu hóa Database và áp dụng Caching. Hệ thống được bảo vệ với Rate limiting, Input validation và cấu hình CORS chặt chẽ. Sẵn sàng triển khai (Deployment Ready): Toàn bộ 6 microservices đã có Dockerfile và chạy ổn định trên môi trường local với docker-compose. Tài liệu kỹ thuật (Architecture diagram, Swagger, Postman) đã hoàn tất. "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/3-blogstranslated/","title":"Các bài blogs đã dịch","tags":[],"description":"","content":"Blog 1 - Tăng tốc phát triển Generative AI với MLflow 3.0 được quản lý hoàn toàn trên Amazon SageMaker AI Bài viết giới thiệu MLflow 3.0 được quản lý hoàn toàn trên Amazon SageMaker AI, giúp tăng tốc phát triển Generative AI bằng cách hợp nhất theo dõi thí nghiệm, giám sát hành vi và quản lý vòng đời mô hình trong một công cụ duy nhất. Phiên bản mới bổ sung khả năng tracing và version tracking, cho phép ghi lại input, output, metadata của ứng dụng AI để dễ dàng truy vết lỗi và tối ưu hiệu năng. Với giao diện trực quan và tích hợp sâu với Amazon Bedrock cùng SageMaker HyperPod, MLflow 3.0 giúp nhóm phát triển cải thiện khả năng quan sát, gỡ lỗi và đưa mô hình AI vào sản xuất nhanh hơn, hiệu quả hơn.\nBlog 2 - Ánh xạ Cơ sở hạ tầng Dưới lòng đất được Cải tiến bằng AI trên AWS Bài viết giới thiệu cách S2 Labs, Empact AI, và Kraken Robotics ứng dụng AI kết hợp vật lý trên AWS HPC để cải thiện bản đồ hạ tầng ngầm. Phương pháp này dùng magnetic imaging và deep learning (mô hình U-Net) để tái tạo hình ảnh chính xác các đường ống, bồn chứa dưới lòng đất hoặc đáy biển. Nhờ sức mạnh xử lý song song của AWS Batch, EC2, và S3, hệ thống đạt độ chính xác cao trong phát hiện cấu trúc ngầm sâu đến 40 m, vượt trội hơn các phương pháp truyền thống.\nBlog 3 - Khai mở toàn bộ tiềm năng của Amazon Connect Bài viết chia sẻ cách khai thác tối đa tiềm năng của Amazon Connect, nền tảng trung tâm liên hệ dựa trên AI và AWS. Tác giả nhấn mạnh tầm quan trọng của việc quản trị thay đổi: xác định đúng bên liên quan, có nhà tài trợ cấp lãnh đạo, xây dựng đại sứ thay đổi, và đo lường chỉ số hiệu quả thực tế. Thành công đến từ việc hiểu rõ nhu cầu kinh doanh, đào tạo đúng đối tượng và truyền thông nội bộ tốt. Nếu được triển khai đúng cách, Amazon Connect giúp tối ưu vận hành, tự động hóa và nâng cao trải nghiệm khách hàng.\n"},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/5-workshop/5.3-knowledge-base/","title":"Tạo và Cấu hình Knowledge Base","tags":[],"description":"","content":"Mục tiêu Sau khi hoàn thành việc chuẩn bị môi trường và dữ liệu, bước tiếp theo là thiết lập thành phần cốt lõi của kiến trúc RAG. Trong phần này, chúng ta sẽ khởi tạo Knowledge Base, đóng vai trò là cơ chế trung gian thông minh kết nối các nguồn dữ liệu phi cấu trúc với khả năng suy luận của các foundation models.\nChúng ta sẽ thực hiện 3 mục tiêu kỹ thuật chính:\nThiết lập Pipeline Tự động: Cấu hình Knowledge Base để tự động hóa toàn bộ quy trình xử lý dữ liệu RAG (bao gồm trích xuất, phân đoạn văn bản và tạo vector) nhằm loại bỏ các tác vụ xử lý thủ công. Khởi tạo Vector Store: Triển khai một collection trên Amazon OpenSearch Serverless để lưu trữ các vector ngữ nghĩa, phục vụ việc truy xuất thông tin chính xác và hiệu quả. Đồng bộ hóa Dữ liệu (Data Ingestion): Thực hiện quy trình nhập dữ liệu ban đầu, chuyển đổi các tài liệu tĩnh từ S3 thành các vector có thể tìm kiếm trong hệ thống. Các Thành phần Chính Trong quá trình cấu hình này, chúng ta sẽ tương tác và kết nối các dịch vụ sau:\nKnowledge Bases for Amazon Bedrock: Dịch vụ được quản lý đóng vai trò là bộ điều phối luồng dữ liệu, kết nối các nguồn thông tin và thực thi các truy vấn ngữ nghĩa. Amazon Titan Embeddings G1 - Text v2: Mô hình chuyên dụng để chuyển đổi dữ liệu văn bản thành các vector số (Embeddings) với độ chính xác cao và hỗ trợ đa ngôn ngữ. Amazon OpenSearch Serverless: Cơ sở dữ liệu vector được quản lý hoàn toàn, chịu trách nhiệm lưu trữ và thực thi các thuật toán tìm kiếm tương đồng (k-NN). Các Bước Thực hiện Khởi tạo Knowledge Base Kiểm tra Vector Store và Đồng bộ Dữ liệu "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/4-eventparticipated/","title":"Các events đã tham gia","tags":[],"description":"","content":"Trong quá trình thực tập, em đã tham gia 6 events, với mỗi event là một trải nghiệm đáng nhớ với những kiến thức mới, hay và bổ ích, cùng với đó là nhứng món quà và những khoảnh khắc rất tuyệt vời.\nEvent 1 Tên sự kiện: Vietnam Cloud Day 2025 - Ho Chi Minh City Connect Edition for Builders (Track 1: GenAI \u0026amp; Data)\nThời gian: 09:00 ngày 18/09/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 2 Tên sự kiện: Vòng đời phát triển theo hướng AI: Tái định hình kỹ thuật phần mềm\nThời gian: 14:00 ngày 03/10/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 3 Tên sự kiện: WORKSHOP KHOA HỌC DỮ LIỆU TRÊN AWS\nThời gian: 09:30 ngày 16/10/2025\nĐịa điểm: Đại học FPT, Đường D1, Khu Công nghệ cao, Phường Tăng Nhơn Phú, TP. Hồ Chí Minh.\nVai trò trong sự kiện: Người tham dự\nEvent 4 Tên sự kiện: AWS Cloud Mastery Series #1\nThời gian: 08:30 ngày 15/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 5 Tên sự kiện: AWS Cloud Mastery Series #2\nThời gian: 08:30 ngày 17/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 6 Tên sự kiện: AWS Cloud Mastery Series #3\nThời gian: 08:30 ngày 29/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\n"},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/5-workshop/5.4-test-chatbox/","title":"Kiểm thử Chatbot (RAG)","tags":[],"description":"","content":"Mục tiêu Sau khi đã nhập dữ liệu thành công vào Vector Store, đã đến lúc xác minh kết quả. Trong phần này, bạn sẽ đóng vai trò là người dùng cuối, đặt câu hỏi cho Chatbot trực tiếp trong giao diện AWS Console để quan sát cách hệ thống RAG hoạt động.\nChúng ta sẽ tập trung vào 2 yếu tố:\nĐộ chính xác: AI có trả lời đúng dựa trên tài liệu không? Tính minh bạch: AI có thể trích dẫn nguồn (Citation) của thông tin không? Các Bước Thực hiện Bước 1: Cấu hình cửa sổ kiểm thử\nĐể bắt đầu trò chuyện, chúng ta cần chọn một Foundation Model sẽ đóng vai trò là \u0026ldquo;người trả lời\u0026rdquo;.\nTrong giao diện chi tiết Knowledge Base của bạn, hãy xem bảng điều khiển bên phải có tiêu đề Test knowledge base. Nhấp vào nút Select model.\nTrong bảng điều khiển lựa chọn xuất hiện: Category: Chọn Anthropic. Model: Chọn Claude 3 Sonnet (hoặc Claude 3.5 Sonnet / Haiku tùy thuộc vào model bạn đã kích hoạt). Throughput: Giữ nguyên On-demand. Nhấp Apply. Bước 2: Tiến hành hội thoại (Chat)\nBây giờ, hãy thử đặt một câu hỏi liên quan đến nội dung tài liệu bạn đã tải lên.\nTrong ô nhập liệu (Message input), gõ câu hỏi của bạn. Ví dụ: Nếu bạn đã tải lên tài liệu \u0026ldquo;Tổng quan về AWS\u0026rdquo;, hãy hỏi: \u0026ldquo;Bạn có thể giải thích cho tôi EC2 là gì không?\u0026rdquo;. Nhấp Run. Quan sát kết quả: AI sẽ suy nghĩ trong vài giây (truy vấn Vector Store). Sau đó, nó sẽ trả lời bằng ngôn ngữ tự nhiên, tóm tắt thông tin tìm được. Bước 3: Xác minh nguồn dữ liệu\nĐây là tính năng quan trọng nhất của RAG giúp phân biệt với ChatGPT thông thường: khả năng chứng minh nguồn thông tin.\nTrong câu trả lời của AI, hãy chú ý đến các số nhỏ (chú thích) hoặc văn bản Show source details. Nhấp vào các số đó hoặc nút chi tiết. Một cửa sổ Source details sẽ xuất hiện, hiển thị: Source chunk: Đoạn văn bản gốc chính xác mà AI tìm thấy trong tài liệu. Score: Điểm tương đồng (mức độ liên quan). S3 Location: Đường dẫn đến file gốc. Việc nhìn thấy đoạn văn bản gốc này chứng minh rằng AI không \u0026ldquo;ảo tưởng\u0026rdquo; mà đang thực sự đọc tài liệu của bạn.\nBước 4: Kiểm thử với câu hỏi không liên quan (Tùy chọn)\nĐể xem hệ thống phản ứng như thế nào khi không tìm thấy thông tin.\nĐặt một câu hỏi hoàn toàn không liên quan đến tài liệu. Ví dụ: \u0026ldquo;Hãy giải thích cho tôi một số kiến thức về tài chính cá nhân?\u0026rdquo; (Trong khi tài liệu của bạn là về Điện toán đám mây). Kết quả mong đợi: AI có thể trả lời dựa trên kiến thức tổng quát của nó (nếu không bị hạn chế). HOẶC AI sẽ trả lời \u0026ldquo;Xin lỗi, tôi không thể trả lời câu hỏi của bạn dựa trên dữ liệu truy xuất được\u0026rdquo; - Đây là hành vi lý tưởng cho một ứng dụng RAG doanh nghiệp. "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/5-workshop/5.5-client-integration/","title":"Tích hợp ứng dụng Client (Tùy chọn)","tags":[],"description":"","content":"Mục tiêu Bạn sẽ biến dòng code Python thành một Giao diện Web Chatbot (GUI) chuyên nghiệp, thân thiện với người dùng cuối (tương tự như giao diện ChatGPT) chỉ trong vài phút.\nChúng ta sử dụng:\nBackend: Python. Frontend: Streamlit. AI Model: Claude 3.5 Sonnet. Các Bước Thực hiện Phần I: Cấu hình AWS Credentials\nBước 1: Cài đặt AWS CLI\nMở Terminal trên máy tính của bạn.\n# macOS brew install awscli # Linux curl \u0026#34;https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\u0026#34; -o \u0026#34;awscliv2.zip\u0026#34; unzip awscliv2.zip sudo ./aws/install Bước 2: Cấu hình credentials\naws configure Nhập thông tin khi được hỏi:\nAWS Access Key ID: YOUR_ACCESS_KEY AWS Secret Access Key: YOUR_SECRET_KEY Default region name: us-east-1 Default output format: json Bước 3: Kiểm tra cấu hình\n# Kiểm tra credentials aws sts get-caller-identity # Kiểm tra kết nối Bedrock aws bedrock-agent-runtime list-knowledge-bases --region ap-southeast-1 Lưu ý bảo mật:\nKHÔNG commit credentials vào Git KHÔNG share credentials với người khác Sử dụng IAM roles khi có thể Rotate credentials định kỳ Permissions cần thiết:\nIAM User cần có các quyền sau:\nbedrock:InvokeModel bedrock:RetrieveAndGenerate bedrock:Retrieve s3:GetObject (cho Knowledge Base) Troubleshooting:\nLỗi \u0026ldquo;Unable to locate credentials\u0026rdquo;:\nKiểm tra file ~/.aws/credentials tồn tại Kiểm tra format file đúng Thử chạy aws configure lại Lỗi \u0026ldquo;AccessDeniedException\u0026rdquo;:\nKiểm tra IAM permissions Đảm bảo region đúng (ap-southeast-1) Kiểm tra Knowledge Base ID đúng Lỗi \u0026ldquo;ExpiredToken\u0026rdquo;:\nCredentials đã hết hạn Cần tạo credentials mới từ AWS Console Phần II: Clone Project từ GitHub đã tạo sẵn\nBước 1: Truy cập vào link GitHub sau\nBạn hãy tải về và mở folder trên bằng Visual Studio Code:\nhttps://github.com/DazielNguyen/chatbot_with_bedrock.git\nBước 2: Tải các thư viện và môi trường Python\nTải môi trường:\nMacOS: python3 -m venv .venv Win: python -m venv .venv Kích hoạt môi trường:\nMacOS: source .venv/bin/activate Win: .venv\\Scripts\\activate Tải thư viện:\nMacOS/ Win: pip install -r requirements.txt Bước 3: Lấy ID của Knowledge Base đã tạo\nTruy cập Amazon Bedrock -\u0026gt; Knowledge Base -\u0026gt; knowledge-base-demo Cập nhật \u0026ldquo;KB_ID=\u0026ldquo;YOUR_KNOWLEDGE_BASE_ID\u0026rdquo;\u0026rdquo; Bước 4: Chạy Streamlit - UI của Chatbot và Trải nghiệm\nRun Terminal: streamlit run start.py Khi chạy xong lệnh sẽ xuất hiện trang sau: Hãy thử hỏi một số câu hỏi bạn đã upload lên Knowledge Base trước đó. Kết quả Chabot đã trả về kết quả dựa trên file dữ liệu mà bạn đã cung cấp, có trích nguồn của dữ liệu của bạn. Kết luận Chúc mừng bạn đã xây dựng thành công một Web Chatbot được xây dựng từ Amazon Bedrock\n"},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/5-workshop/","title":"Workshop","tags":[],"description":"","content":"Xây dựng ứng dụng RAG sử dụng Knowledge Bases cho Amazon Bedrock Tổng quan Knowledge Bases for Amazon Bedrock là một tính năng được quản lý hoàn toàn giúp bạn triển khai kỹ thuật RAG (Retrieval-Augmented Generation) bằng cách kết nối các Foundation Models với nguồn dữ liệu nội bộ của bạn để cung cấp các phản hồi chính xác, có trích dẫn và phù hợp với ngữ cảnh.\nRAG là một kỹ thuật để tối ưu hóa đầu ra của Large Language Model (LLM) bằng cách truy xuất thông tin từ cơ sở dữ liệu bên ngoài đáng tin cậy (Retrieval) và thêm nó vào ngữ cảnh (Augmentation) trước khi tạo ra câu trả lời (Generation). Phương pháp này giúp khắc phục những hạn chế về dữ liệu huấn luyện lỗi thời và đảm bảo AI trả lời dựa trên thông tin thực tế được cung cấp.\nTrong bài lab này, chúng ta sẽ học cách xây dựng một trợ lý AI có khả năng \u0026ldquo;đọc và hiểu\u0026rdquo; các tài liệu doanh nghiệp độc quyền. Bạn sẽ thực hiện quy trình từ việc nhập dữ liệu và tạo chỉ mục vector đến cấu hình mô hình để trả lời câu hỏi dựa trên những tài liệu đó mà không cần quản lý bất kỳ máy chủ nào.\nChúng ta sẽ sử dụng ba thành phần chính để thiết lập quy trình xử lý RAG hoàn chỉnh:\nNguồn dữ liệu (Amazon S3) - Đóng vai trò là kho lưu trữ \u0026ldquo;sự thật\u0026rdquo;. Bạn sẽ tải các tài liệu (PDF, Word, Text) lên một S3 bucket. Knowledge Base sẽ sử dụng nguồn này để đồng bộ hóa dữ liệu. Vector Store (OpenSearch Serverless) - Nơi lưu trữ các embeddings vector (dữ liệu được mã hóa bằng số). Khi người dùng đặt câu hỏi, hệ thống sẽ thực hiện tìm kiếm ngữ nghĩa tại đây để trích xuất các đoạn văn bản liên quan nhất thay vì tìm kiếm từ khóa tiêu chuẩn. Foundation Model (Claude 3) - Large Language Model đóng vai trò là bộ não xử lý. Nó nhận câu hỏi của người dùng cùng với thông tin tìm thấy từ Vector Store, sau đó tổng hợp và tạo ra câu trả lời tự nhiên, chính xác kèm theo trích dẫn nguồn. Kết quả đạt được Khi kết thúc workshop, bạn sẽ có một hệ thống Chatbot thực tế, hoạt động với các tính năng sau:\nTrò chuyện hỏi đáp về nội dung tài liệu độc quyền. Câu trả lời chính xác, không có ảo giác (hallucinations). Trích dẫn nguồn (biết chính xác câu trả lời đến từ trang nào). Triển khai nhanh chóng mà không cần viết mã xử lý dữ liệu phức tạp. Nội dung Tổng quan về Workshop Chuẩn bị môi trường Tạo và cấu hình Knowledge Base Kiểm tra Chatbot (RAG) Tích hợp ứng dụng Client (Tùy chọn) Cập nhật dữ liệu Dọn dẹp tài nguyên "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/5-workshop/5.6-update-data/","title":"Cập nhật dữ liệu","tags":[],"description":"","content":"Mục tiêu Một trong những lợi thế lớn nhất của RAG so với Fine-tuning (huấn luyện lại) mô hình là khả năng cập nhật dữ liệu nhanh chóng. Khi doanh nghiệp có quy định mới, bạn chỉ cần nhập chúng vào Knowledge Base, và AI sẽ \u0026ldquo;học\u0026rdquo; chúng ngay lập tức.\nTrong phần này, chúng ta sẽ mô phỏng kịch bản sau:\nHỏi AI về một thông tin không tồn tại (AI sẽ trả lời là không biết). Cung cấp thông tin đó cho hệ thống bằng cách tải lên file mới. Hỏi lại câu hỏi tương tự để chứng kiến AI trả lời đúng ngay lập tức. Các Bước Thực hiện Bước 1: Xác minh \u0026ldquo;thiếu kiến thức\u0026rdquo; ban đầu\nChúng ta cần xác nhận rằng AI hiện tại không biết gì về thông tin bí mật mà chúng ta sắp tạo.\nQuay lại giao diện Streamlit Chatbot (được tạo trong Phần 5) hoặc sử dụng cửa sổ Test Knowledge Base trên Console. Đặt một câu hỏi về thông tin giả định không có thật. Ví dụ: \u0026ldquo;Mã kích hoạt cho Dự án Omega là gì?\u0026rdquo; Quan sát kết quả: AI sẽ trả lời rằng không thể tìm thấy thông tin trong các tài liệu được cung cấp hoặc sẽ cố gắng đưa ra câu trả lời chung chung (nếu không bị hạn chế). Bước 2: Tạo dữ liệu mới\nChúng ta sẽ tạo một file văn bản chứa \u0026ldquo;bí mật\u0026rdquo; này để nhập vào hệ thống.\nTrên máy tính của bạn, mở Notepad (Windows) hoặc TextEdit (Mac). Sao chép và dán nội dung sau vào file: THÔNG BÁO MẬT: Dự án Omega bí mật chính thức khởi động vào ngày 01/12/2025. Mã kích hoạt là: \u0026#34;AWS-ROCKS-2025-SINGAPORE\u0026#34;. Người Quản lý Dự án là Ông Robot. Vui lòng giữ thông tin này tuyệt đối bí mật. Lưu file với tên: secret-project.txt. Bạn có thể tải file tại đây: Tệp định dạng TXT\nBước 3: Tải lên và Đồng bộ\nBây giờ, chúng ta sẽ cung cấp kiến thức mới này vào \u0026ldquo;bộ não\u0026rdquo; của AI.\nTruy cập S3 Console, điều hướng đến bucket cũ của bạn (rag-workshop-demo).\nNhấp Upload -\u0026gt; Add files -\u0026gt; Chọn file secret-project.txt -\u0026gt; Upload.\nChuyển sang Amazon Bedrock Console -\u0026gt; Chọn Knowledge bases từ menu bên trái. Nhấp vào tên Knowledge Base của bạn. Cuộn xuống phần Data source, chọn nguồn dữ liệu (s3-datasource). Nhấp vào nút Sync (Màu cam). Chờ đợi: Chờ khoảng 30 giây đến 1 phút cho đến khi cột Status chuyển từ Syncing sang Available. Bước 4: Xác minh lại (Khoảnh khắc \u0026ldquo;Wow\u0026rdquo;)\nHệ thống hiện đã có kiến thức mới. Hãy thách thức AI một lần nữa.\nQuay lại giao diện Streamlit Chatbot (Không cần tải lại trang hoặc khởi động lại server). Hỏi chính xác câu hỏi tương tự như trước: \u0026ldquo;Mã kích hoạt cho Dự án Omega là gì?\u0026rdquo; Kết quả mong đợi: AI trả lời chính xác: \u0026ldquo;Mã kích hoạt là AWS-ROCKS-2025-SINGAPORE\u0026rdquo;. AI trích dẫn nguồn là file secret-project.txt. Kết luận Bạn vừa chứng kiến sức mạnh thực sự của RAG!\nKhông cần chỉnh sửa code. Không cần huấn luyện lại mô hình. Chỉ cần Sync dữ liệu. Chatbot của bạn đã trở nên thông minh hơn và cập nhật với thông tin mới nhất chỉ trong vài bước đơn giản. Đây chính là lý do tại sao các doanh nghiệp chọn giải pháp này để xây dựng trợ lý ảo nội bộ.\n"},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/6-self-evaluation/","title":"Tự đánh giá","tags":[],"description":"","content":"Trong suốt thời gian thực tập tại AWS/First cloud journey program từ 08/08/2025 đến 12/12/2025, tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế.\nTôi đã tham gia vào việc học tập dịch vụ của AWS, cũng như áp dụng các kiến thức đã được học vào dự án nhóm với chủ đề FinTech, qua đó cải thiện kỹ năng làm việc nhóm, phân bổ công việc cho các thành viên trong nhóm, và đặc biệt đã đạt được các kĩ năng mong muốn như Docker, Devops, và áp dụng các dịch vụ AWS hỗ trợ công việc lập trình.\nVề tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ nội quy, và tích cực trao đổi với đồng nghiệp để nâng cao hiệu quả công việc.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ✅ ☐ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ✅ ☐ ☐ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ✅ ☐ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Cần cải thiện Nâng cao tính kỹ luật, chấp hành nghiêm chỉnh nội quy của công ty hoặc bất kỳ trong một tổ chức nào Rèn luyện cho bản thân tính kiên trì một việc cụ thể thay vì lan man với những vấn đề khác gây sao nhãng công việc Cải thiện trong cách tư duy giải quyết vấn đề Cải thiệt kĩ năng giao tiếp và diễn đạt vấn đề của bàn thân đang mắc phải cho các anh Mentors cũng như đồng đội Cần tìm hiểu và học hỏi thêm các công nghệ mới, và học để áp dụng thay vì học để biết Hỗ trợ các thành viên trong nhóm nhiều hơn trong công việc cũng như học tập "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/7-feedback/","title":"Chia sẻ, đóng góp ý kiến","tags":[],"description":"","content":"Đánh giá chung 1. Môi trường làm việc\nMôi trường làm việc chuyên nghiệp, các thành viên trong cộng đồng FCJ rất thân thiện và cởi mở, đặc biệt là các anh FCJ khóa trên cũng như các bạn FCJ cùng khóa với mình luôn sẵn sàng hỗ trợ, giải đáp các thắc mắc khi mình và nhóm gặp khó khăn trong các khâu thiết kế và sử dụng các dịch vụ của AWS. Vì những sự giúp đỡ đó đã giúp cho bản thân mình nhận ra những sai lầm sớm hơn, thay vì phải trải một số tiền lớn thì nhờ những sự giúp đỡ đó đã giúp mình có thêm nhiều kiến thức với sự đánh đổi chỉ bằng những câu hỏi. Không gian làm việc gọn gàng, thoải mái cũng như với tinh thần học hỏi của các bạn đã truyền động lực cho mình tập trung hơn, quyết tâm hơn với những mục tiêu đã đặt ra.\nTuy nhiên mình nghĩ lần tới nếu được thì nên có một lịch cố định cho các bạn cùng nhóm có thể lên văn phòng dễ dàng hơn thay vì cạnh tranh như hiện tại, để mọi người trong nhóm dễ dàng tiếp cận và trao đổi trực tiếp hơn vì có một số bạn chưa kịp làm quen bên ngoài lúc đầu mà chỉ có thể làm quen qua online.\n2. Sự hỗ trợ của mentor / team admin\nCác anh Mentors cực kì tâm huyết và tậm tâm không chỉ chất lượng mà còn số lượng các anh Mentors cực kì nhiều, sẵn sàng hỗ trợ tụi mình cực kì nhiều, không cần biết thời gian khi nào, thậm chí đôi lần 2-3 giờ sáng các anh vẫn còn đưa ra những feedback để tụi mình chỉnh sửa kịp thời deadline. Không dừng lại ở việc hỗ trợ các anh còn chia sẻ những kiến thức bổ ích được tích góp qua kinh nghiệm làm việc của các anh và đó cũng là những bài học vô giá mà FCJ đem lại cho mình. Việc mình thích ở các anh đó là khơi gợi lên sự tò mò cũng như các lỗi sai mà mình mắc phải trong quá trình học tập và làm việc, thay vì đưa ra đáp án thì các anh đưa mình đến với những tài liệu chính thống để mình tự tìm ra câu trả lời cũng như khắc cốt ghi tâm các sai lầm đó để không mắc phải lần sau.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nCông việc của mình thực hiện giống như mảnh ghép thiếu còn sót khi mình học ở trường, việc phát triển các sản phẩm chỉ nằm ở local khác với việc phát triển một sản phẩm hướng đến người dùng nhiều hơn, cần phải xử lý nhiều vấn đề hơn đặc biệt về bảo mật cũng như tính thống nhất của phần mềm. Việc làm những công việc khó hơn và nâng cao hơn trong mảng học của mình đã giúp mình không còn \u0026ldquo;ngại\u0026rdquo; việc phải làm việc với nó nữa. Nhờ vậy mình vừa củng cố kiến thức lập trình vừa học được các kĩ năng devops và các kĩ năng mềm khác như làm việc nhóm, giao tiếp, \u0026hellip; đã giúp mình phát triển rất nhiều ở hiện tại, thậm chí cả tương lai sau này.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình học được nhiều kĩ năng mới không chỉ về chuyên ngành mình đang học mà còn các kĩ năng mềm khác, mình được làm việc với những người mới, với những người không cùng chuyên ngành, qua đó mình có được những góc nhìn khác nhau của từng chuyên ngành cũng như kĩ năng thông qua việc chia sẻ giữa các thành viên trong nhóm. Mình tham dự được nhiều sự kiện hay ho của các anh đã có kinh nghiệm nhiều ở các tập đoàn lớn, học được cách các anh vận dụng AI vào công việc cũng như các kĩ năng nâng cao khác của lập trình giúp mình định hướng tốt hơn cho sự nghiệp mình đang theo đuổi\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa công ty rất tích cực, mọi người trong công ty đều hỗ trợ tận tình với tinh thần học hỏi và chia sẻ các kiến thức là chính, trong quá trình làm việc mọi người làm việc cực kì tập trung nhưng cũng có những lúc cực kì vui vẻ. Khi tới deadline thì mọi người đều cùng nhau cố gắng, hỗ trợ nhau không phân biệt vị trí nào, người nào xong việc thì hỗ trợ những người chưa xong, người biết hỗ trợ người không biết, chỉ cần có vấn đề là sẽ được mọi người hỗ trợ giải quyết vấn đề đó nhanh và hiệu quả nhất. Điều này giúp mình dễ dàng hòa đồng với mọi người dù chỉ ở vai trò là thực tập sinh\nMột số câu hỏi khác Điều mình hài lòng nhất trong khoảng thời gian thực tập đó là tinh thần của các FCJer, một tinh thần sẵn sàng chia sẻ tất cả mọi thứ nằm trong tầm hiểu biết của người đó, không bỏ ai ở lại phía sau cả. Với một tinh thần như thế giúp mình phần nào hiểu được FCJ không phải là một chương trình mà đó là cả một cộng đồng ham học, sẵn sàng chia sẻ các kiến thức mới đến với các bạn thực tập sinh không chỉ mình mà còn rất nhiều người chưa được tiếp cận với nó. "},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/5-workshop/5.7-cleanup/","title":"Dọn dẹp Tài nguyên","tags":[],"description":"","content":"Mục tiêu Để tránh phát sinh chi phí không mong muốn sau khi hoàn thành bài thực hành, chúng ta cần xóa các tài nguyên đã tạo.\n⚠️ CẢNH BÁO: Xóa Knowledge Base KHÔNG tự động xóa Vector Store (OpenSearch Serverless). Bạn phải xóa thủ công OpenSearch Serverless Collection vì đây là dịch vụ tốn chi phí nhất trong Lab này.\nCác Bước Thực hiện Bước 1: Xóa Knowledge Base\nTruy cập Amazon Bedrock Console -\u0026gt; Knowledge bases.\nChọn nút radio bên cạnh tên Knowledge Base của bạn.\nNhấp vào nút Delete.\nHộp thoại xuất hiện, nhập tên Knowledge Base để xác nhận (hoặc gõ delete).\nNhấp Delete. Quá trình này mất 10-15 phút mới xóa thành công. Nên bạn thư giản nhé\nBước 2: Xóa Vector Store\nTruy cập Amazon OpenSearch Service. Trong menu bên trái, ở phần Serverless, chọn Collections. Bạn sẽ thấy một Collection có tên dạng bedrock-knowledge-base-.... Chọn nút radio bên cạnh tên Collection đó. Nhấp vào nút Delete. Gõ confirm hoặc tên collection để xác nhận xóa. Nhấp Delete. Bước 3: Xóa Dữ liệu trên S3\nTruy cập dịch vụ Amazon S3. Chọn bucket rag-workshop-demo. Nhấp vào nút Empty trước tiên. Gõ permanently delete để xác nhận xóa tất cả các file bên trong. Sau khi bucket rỗng, quay lại danh sách Buckets. Chọn lại bucket đó và nhấp vào nút Delete. Nhập tên bucket để xác nhận. Hoàn thành Chúc mừng bạn đã hoàn thành đầy đủ Workshop \u0026ldquo;Xây dựng Ứng dụng RAG với Amazon Bedrock\u0026rdquo;. Hệ thống của bạn đã được dọn dẹp và an toàn!\n"},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://danielleit241.github.io/aws-fcj-report/vi/tags/","title":"Tags","tags":[],"description":"","content":""}]