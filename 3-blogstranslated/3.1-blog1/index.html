<!doctype html><html lang=en class="js csstransforms3d"><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo 0.134.3"><meta name=description content><meta name=author content="thienlh@thienlu.com"><link rel=icon href=../../images/favicon.png type=image/png><title>Blog 1 :: Internship Report</title>
<link href=../../css/nucleus.css?1765243145 rel=stylesheet><link href=../../css/fontawesome-all.min.css?1765243145 rel=stylesheet><link href=../../css/hybrid.css?1765243145 rel=stylesheet><link href=../../css/featherlight.min.css?1765243145 rel=stylesheet><link href=../../css/perfect-scrollbar.min.css?1765243145 rel=stylesheet><link href=../../css/auto-complete.css?1765243145 rel=stylesheet><link href=../../css/atom-one-dark-reasonable.css?1765243145 rel=stylesheet><link href=../../css/theme.css?1765243145 rel=stylesheet><link href=../../css/hugo-theme.css?1765243145 rel=stylesheet><link href=../../css/theme-workshop.css?1765243145 rel=stylesheet><script src=../../js/jquery-3.3.1.min.js?1765243145></script><style>:root #header+#content>#left>#rlblock_left{display:none!important}</style></head><body data-url=../../3-blogstranslated/3.1-blog1/><nav id=sidebar class=showVisitedLinks><div id=header-wrapper><div id=header><a id=logo href=../../><svg id="Layer_1" data-name="Layer 1" viewBox="0 0 60 30" width="30%"><defs><style>.cls-1{fill:#fff}.cls-2{fill:#f90;fill-rule:evenodd}</style></defs><title>AWS-Logo_White-Color</title><path class="cls-1" d="M14.09 10.85a4.7 4.7.0 00.19 1.48 7.73 7.73.0 00.54 1.19.77.77.0 01.12.38.64.64.0 01-.32.49l-1 .7a.83.83.0 01-.44.15.69.69.0 01-.49-.23 3.8 3.8.0 01-.6-.77q-.25-.42-.51-1a6.14 6.14.0 01-4.89 2.3 4.54 4.54.0 01-3.32-1.19 4.27 4.27.0 01-1.22-3.2 4.28 4.28.0 011.46-3.4A6.06 6.06.0 017.69 6.46a12.47 12.47.0 011.76.13q.92.13 1.91.36V5.73a3.65 3.65.0 00-.79-2.66A3.81 3.81.0 007.86 2.3a7.71 7.71.0 00-1.79.22 12.78 12.78.0 00-1.79.57 4.55 4.55.0 01-.58.22h-.26q-.35.0-.35-.52V2a1.09 1.09.0 01.12-.58 1.2 1.2.0 01.47-.35A10.88 10.88.0 015.77.32 10.19 10.19.0 018.36.0a6 6 0 014.35 1.35 5.49 5.49.0 011.38 4.09zM7.34 13.38a5.36 5.36.0 001.72-.31A3.63 3.63.0 0010.63 12 2.62 2.62.0 0011.19 11a5.63 5.63.0 00.16-1.44v-.7a14.35 14.35.0 00-1.53-.28 12.37 12.37.0 00-1.56-.1 3.84 3.84.0 00-2.47.67A2.34 2.34.0 005 11a2.35 2.35.0 00.61 1.76A2.4 2.4.0 007.34 13.38zm13.35 1.8a1 1 0 01-.64-.16 1.3 1.3.0 01-.35-.65L15.81 1.51a3 3 0 01-.15-.67.36.36.0 01.41-.41H17.7a1 1 0 01.65.16 1.4 1.4.0 01.33.65l2.79 11 2.59-11A1.17 1.17.0 0124.39.6a1.1 1.1.0 01.67-.16H26.4a1.1 1.1.0 01.67.16 1.17 1.17.0 01.32.65L30 12.39 32.88 1.25A1.39 1.39.0 0133.22.6a1 1 0 01.65-.16h1.54a.36.36.0 01.41.41 1.36 1.36.0 010 .26 3.64 3.64.0 01-.12.41l-4 12.86a1.3 1.3.0 01-.35.65 1 1 0 01-.64.16H29.25a1 1 0 01-.67-.17 1.26 1.26.0 01-.32-.67L25.67 3.64l-2.56 10.7a1.26 1.26.0 01-.32.67 1 1 0 01-.67.17zm21.36.44a11.28 11.28.0 01-2.56-.29 7.44 7.44.0 01-1.92-.67 1 1 0 01-.61-.93v-.84q0-.52.38-.52a.9.9.0 01.31.06l.42.17a8.77 8.77.0 001.83.58 9.78 9.78.0 002 .2 4.48 4.48.0 002.43-.55 1.76 1.76.0 00.86-1.57 1.61 1.61.0 00-.45-1.16A4.29 4.29.0 0043 9.22l-2.41-.76A5.15 5.15.0 0138 6.78a3.94 3.94.0 01-.83-2.41 3.7 3.7.0 01.45-1.85 4.47 4.47.0 011.19-1.37 5.27 5.27.0 011.7-.86A7.4 7.4.0 0142.6.0a8.87 8.87.0 011.12.07q.57.07 1.08.19t.95.26a4.27 4.27.0 01.7.29 1.59 1.59.0 01.49.41.94.94.0 01.15.55v.79q0 .52-.38.52a1.76 1.76.0 01-.64-.2 7.74 7.74.0 00-3.2-.64 4.37 4.37.0 00-2.21.47 1.6 1.6.0 00-.79 1.48 1.58 1.58.0 00.49 1.18 4.94 4.94.0 001.83.92L44.55 7a5.08 5.08.0 012.57 1.6A3.76 3.76.0 0147.9 11a4.21 4.21.0 01-.44 1.93 4.4 4.4.0 01-1.21 1.47 5.43 5.43.0 01-1.85.93A8.25 8.25.0 0142.05 15.62z"/><path class="cls-2" d="M45.19 23.81C39.72 27.85 31.78 30 25 30A36.64 36.64.0 01.22 20.57c-.51-.46-.06-1.09.56-.74A49.78 49.78.0 0025.53 26.4 49.23 49.23.0 0044.4 22.53C45.32 22.14 46.1 23.14 45.19 23.81z"/><path class="cls-2" d="M47.47 21.21c-.7-.9-4.63-.42-6.39-.21-.53.06-.62-.4-.14-.74 3.13-2.2 8.27-1.57 8.86-.83s-.16 5.89-3.09 8.35c-.45.38-.88.18-.68-.32C46.69 25.8 48.17 22.11 47.47 21.21z"/></svg></a></div><div class=searchbox><label for=search-by><i class="fas fa-search"></i></label>
<input data-search-input id=search-by type=search placeholder=Search...>
<span data-search-clear><i class="fas fa-times"></i></span></div><script type=text/javascript src=../../js/lunr.min.js?1765243145></script><script type=text/javascript src=../../js/auto-complete.js?1765243145></script><script type=text/javascript>var baseurl="https://danielleit241.github.io/aws-fcj-report/"</script><script type=text/javascript src=../../js/search.js?1765243145></script></div><div class=highlightable><ul class=topics><li data-nav-id=/1-worklog/ title=Worklog class=dd-item><a href=../../1-worklog/><b>1. </b>Worklog
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/1-worklog/1.1-week1/ title="Week 1 Worklog" class=dd-item><a href=../../1-worklog/1.1-week1/><b>1.1. </b>Week 1 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.2-week2/ title="Week 2 Worklog" class=dd-item><a href=../../1-worklog/1.2-week2/><b>1.2. </b>Week 2 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.3-week3/ title="Week 3 Worklog" class=dd-item><a href=../../1-worklog/1.3-week3/><b>1.3. </b>Week 3 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.4-week4/ title="Week 4 Worklog" class=dd-item><a href=../../1-worklog/1.4-week4/><b>1.4. </b>Week 4 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.5-week5/ title="Week 5 Worklog" class=dd-item><a href=../../1-worklog/1.5-week5/><b>1.5. </b>Week 5 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.6-week6/ title="Week 6 Worklog" class=dd-item><a href=../../1-worklog/1.6-week6/><b>1.6. </b>Week 6 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.7-week7/ title="Week 7 Worklog" class=dd-item><a href=../../1-worklog/1.7-week7/><b>1.7. </b>Week 7 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.8-week8/ title="Week 8 Worklog" class=dd-item><a href=../../1-worklog/1.8-week8/><b>1.8. </b>Week 8 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.9-week9/ title="Week 9 Worklog" class=dd-item><a href=../../1-worklog/1.9-week9/><b>1.9. </b>Week 9 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.10-week10/ title="Week 10 Worklog" class=dd-item><a href=../../1-worklog/1.10-week10/><b>1.10. </b>Week 10 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.11-week11/ title="Week 11 Worklog" class=dd-item><a href=../../1-worklog/1.11-week11/><b>1.11. </b>Week 11 Worklog
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/1-worklog/1.12-week12/ title="Week 12 Worklog" class=dd-item><a href=../../1-worklog/1.12-week12/><b>1.12. </b>Week 12 Worklog
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/2-proposal/ title=Proposal class=dd-item><a href=../../2-proposal/><b>2. </b>Proposal
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/3-blogstranslated/ title="Translated Blogs" class="dd-item
parent"><a href=../../3-blogstranslated/><b>3. </b>Translated Blogs
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/3-blogstranslated/3.1-blog1/ title="Blog 1" class="dd-item
active"><a href=../../3-blogstranslated/3.1-blog1/><b>3.1. </b>Blog 1
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/3-blogstranslated/3.2-blog2/ title="Blog 2" class=dd-item><a href=../../3-blogstranslated/3.2-blog2/><b>3.2. </b>Blog 2
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/3-blogstranslated/3.3-blog3/ title="Blog 3" class=dd-item><a href=../../3-blogstranslated/3.3-blog3/><b>3.3. </b>Blog 3
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/4-eventparticipated/ title="Events Participated" class=dd-item><a href=../../4-eventparticipated/><b>4. </b>Events Participated
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/4-eventparticipated/4.1-event1/ title="Event 1" class=dd-item><a href=../../4-eventparticipated/4.1-event1/><b>4.1. </b>Event 1
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/4-eventparticipated/4.2-event2/ title="Event 2" class=dd-item><a href=../../4-eventparticipated/4.2-event2/><b>4.2. </b>Event 2
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/4-eventparticipated/4.3-event3/ title="Event 3" class=dd-item><a href=../../4-eventparticipated/4.3-event3/><b>4.3. </b>Event 3
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/4-eventparticipated/4.4-event4/ title="Event 4" class=dd-item><a href=../../4-eventparticipated/4.4-event4/><b>4.4. </b>Event 4
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/4-eventparticipated/4.5-event5/ title="Event 5" class=dd-item><a href=../../4-eventparticipated/4.5-event5/><b>4.5. </b>Event 5
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/4-eventparticipated/4.6-event6/ title="Event 6" class=dd-item><a href=../../4-eventparticipated/4.6-event6/><b>4.6. </b>Event 6
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/5-workshop/ title=Workshop class=dd-item><a href=../../5-workshop/><b>5. </b>Workshop
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/5-workshop/5.1-workshop-overview/ title=Introduction class=dd-item><a href=../../5-workshop/5.1-workshop-overview/><b>5.1. </b>Introduction
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/5-workshop/5.1-workshop-overview/5.1.1-whatisrag/ title="What is Retrieval-Augmented Generation (RAG)" class=dd-item><a href=../../5-workshop/5.1-workshop-overview/5.1.1-whatisrag/><b>5.1.1 </b>What is Retrieval-Augmented Generation (RAG)
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.1-workshop-overview/5.1.2-services/ title=Services class=dd-item><a href=../../5-workshop/5.1-workshop-overview/5.1.2-services/><b>5.1.2 </b>Services
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/5-workshop/5.2-prerequiste/ title=Prerequiste class=dd-item><a href=../../5-workshop/5.2-prerequiste/><b>5.2. </b>Prerequiste
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/5-workshop/5.2-prerequiste/5.2.1-model-access/ title="Verify Model Access" class=dd-item><a href=../../5-workshop/5.2-prerequiste/5.2.1-model-access/><b>5.2.1 </b>Verify Model Access
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.2-prerequiste/5.2.2-prepare-data/ title="Prepare source data" class=dd-item><a href=../../5-workshop/5.2-prerequiste/5.2.2-prepare-data/><b>5.2.2 </b>Prepare source data
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/5-workshop/5.3-knowledge-base/ title="Create and Configure Knowledge Base" class=dd-item><a href=../../5-workshop/5.3-knowledge-base/><b>5.3. </b>Create and Configure Knowledge Base
<i class="fas fa-check read-icon"></i></a><ul><li data-nav-id=/5-workshop/5.3-knowledge-base/5.3.1-create-kb/ title="Initialize Knowledge Base" class=dd-item><a href=../../5-workshop/5.3-knowledge-base/5.3.1-create-kb/><b>5.3.1 </b>Initialize Knowledge Base
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.3-knowledge-base/5.3.2-sync-data/ title="Check Vector Store and Data Synchronization" class=dd-item><a href=../../5-workshop/5.3-knowledge-base/5.3.2-sync-data/><b>5.3.2 </b>Check Vector Store and Data Synchronization
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/5-workshop/5.4-test-chatbox/ title="Testing Chatbot (RAG)" class=dd-item><a href=../../5-workshop/5.4-test-chatbox/><b>5.4. </b>Testing Chatbot (RAG)
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.5-client-integration/ title="Client Application Integration (Optional)" class=dd-item><a href=../../5-workshop/5.5-client-integration/><b>5.5. </b>Client Application Integration (Optional)
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.6-update-data/ title="Update data" class=dd-item><a href=../../5-workshop/5.6-update-data/><b>5.6. </b>Update data
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/5-workshop/5.7-cleanup/ title="Clean Resources" class=dd-item><a href=../../5-workshop/5.7-cleanup/><b>5.7. </b>Clean Resources
<i class="fas fa-check read-icon"></i></a></li></ul></li><li data-nav-id=/6-self-evaluation/ title=Self-Assessment class=dd-item><a href=../../6-self-evaluation/><b>6. </b>Self-Assessment
<i class="fas fa-check read-icon"></i></a></li><li data-nav-id=/7-feedback/ title="Sharing and Feedback" class=dd-item><a href=../../7-feedback/><b>7. </b>Sharing and Feedback
<i class="fas fa-check read-icon"></i></a></li></ul><section id=shortcuts><h3>More</h3><ul><li><a class=padding href=https://www.facebook.com/groups/awsstudygroupfcj/><i class='fab fa-facebook'></i> AWS Study Group</a></li></ul></section><section id=prefooter><hr><ul><li><a class=padding><i class="fas fa-language fa-fw"></i><div class=select-style><select id=select-language onchange="location=this.value"><option id=en value=https://danielleit241.github.io/aws-fcj-report/3-blogstranslated/3.1-blog1/ selected>English</option><option id=vi value=https://danielleit241.github.io/aws-fcj-report/vi/3-blogstranslated/3.1-blog1/>Tiếng Việt</option></select><svg id="Capa_1" xmlns:xlink="http://www.w3.org/1999/xlink" width="255" height="255" viewBox="0 0 255 255" style="enable-background:new 0 0 255 255"><g><g id="arrow-drop-down"><polygon points="0,63.75 127.5,191.25 255,63.75"/></g></g></svg></div></a></li><li><a class=padding href=# data-clear-history-toggle><i class="fas fa-history fa-fw"></i> Clear History</a></li></ul></section><section id=footer><left><b>Workshop</b><br><img src="https://hitwebcounter.com/counter/counter.php?page=7920860&style=0038&nbdigits=9&type=page&initCount=0" title=Migrate alt="web counter" border=0></a><br><b><a href=https://cloudjourney.awsstudygroup.com/>Cloud Journey</a></b><br><img src="https://hitwebcounter.com/counter/counter.php?page=7830807&style=0038&nbdigits=9&type=page&initCount=0" title="Total CLoud Journey" alt="web counter" border=0>
</left><left><br><br><b>Last Updated</b><br><i><span id=lastUpdated style=color:orange></span>
</i><script>const today=new Date,formattedDate=today.toLocaleDateString("en-GB");document.getElementById("lastUpdated").textContent=formattedDate</script></left><left><br><br><b>Team</b><br><i><a href=https://www.facebook.com/groups/660548818043427 style=color:orange>First Cloud Journey</a><br></i></left><script async defer src=https://buttons.github.io/buttons.js></script></section></div></nav><section id=body><div id=overlay></div><div class="padding highlightable"><div><div id=top-bar><div id=breadcrumbs itemscope itemtype=http://data-vocabulary.org/Breadcrumb><span id=sidebar-toggle-span><a href=# id=sidebar-toggle data-sidebar-toggle><i class="fas fa-bars"></i>
</a></span><span id=toc-menu><i class="fas fa-list-alt"></i></span>
<span class=links><a href=../../>Internship Report</a> > <a href=../../3-blogstranslated/>Translated Blogs</a> > Blog 1</span></div><div class=progress><div class=wrapper><nav id=TableOfContents><ul><li><a href=#get-started><strong>Get started</strong></a></li><li><a href=#prerequisites><strong>Prerequisites</strong></a></li><li><a href=#configure-your-environment-to-use-the-sagemaker-managed-mlflow-tracking-server><strong>Configure your environment to use the SageMaker-managed MLflow tracking server</strong></a><ul><li><a href=#configuration-steps><strong>Configuration steps:</strong></a></li></ul></li><li><a href=#images3-blogstranslated31-blog1image1png><img src=../../images/3-BlogsTranslated/3.1-Blog1/image1.png alt></a></li><li><a href=#implement-tracing-and-version-tracking-for-generative-ai-applications><strong>Implement tracing and version tracking for Generative AI applications</strong></a></li><li><a href=#images3-blogstranslated31-blog1image2png><img src=../../images/3-BlogsTranslated/3.1-Blog1/image2.png alt></a></li><li><a href=#images3-blogstranslated31-blog1image3png><img src=../../images/3-BlogsTranslated/3.1-Blog1/image3.png alt></a></li><li><a href=#images3-blogstranslated31-blog1image4png><img src=../../images/3-BlogsTranslated/3.1-Blog1/image4.png alt></a></li><li><a href=#images3-blogstranslated31-blog1image5png><img src=../../images/3-BlogsTranslated/3.1-Blog1/image5.png alt></a></li><li><a href=#using-mlflow-tracing-for-generative-ai><strong>Using MLflow tracing for Generative AI</strong></a></li><li><a href=#images3-blogstranslated31-blog1image6png><img src=../../images/3-BlogsTranslated/3.1-Blog1/image6.png alt></a></li><li><a href=#images3-blogstranslated31-blog1image7png><img src=../../images/3-BlogsTranslated/3.1-Blog1/image7.png alt></a></li><li><a href=#clean-up-resources><strong>Clean up resources</strong></a></li><li><a href=#conclusion><strong>Conclusion</strong></a></li><li><a href=#about-the-authors><strong>About the authors</strong></a></li></ul></nav></div></div></div></div><div id=head-tags></div><div id=body-inner><h1>Blog 1</h1><h1 id=accelerate-generative-ai-development-with-fully-managed-mlflow-30-on-amazon-sagemaker-ai><strong>Accelerate Generative AI development with fully managed MLflow 3.0 on Amazon SageMaker AI</strong></h1><p><em>By Ram Vittal, Amit Modi, Rahul Easwar, and Sandeep Raveesh-Babu on 10 JUL 2025 in <a href=https://aws.amazon.com/blogs/machine-learning/category/artificial-intelligence/sagemaker/amazon-sagemaker-ai/>Amazon SageMaker AI</a>, <a href=https://aws.amazon.com/blogs/machine-learning/category/post-types/announcements/>Announcements</a>, <a href=https://aws.amazon.com/vi/blogs/machine-learning/category/post-types/technical-how-to/>Technical How-to</a></em></p><p><a href=https://aws.amazon.com/sagemaker/>Amazon SageMaker</a> now offers fully managed support for <strong>MLflow 3.0</strong>, simplifying AI experimentation and accelerating your <a href=https://aws.amazon.com/generative-ai/><strong>Generative AI</strong></a> journey from idea to production. This release turns <strong>managed MLflow</strong> from an experiment-tracking tool into an <strong>end-to-end observability</strong> solution, reducing time to market for Generative AI.</p><p>As customers across industries accelerate Generative AI development, they need experiment tracking, behavior observability, and performance evaluation for <strong>models</strong> and <strong>AI applications</strong>. <strong>Data scientists</strong> and <strong>developers</strong> often struggle to analyze model and application performance from experimentation to production, making root-cause analysis and remediation difficult. Teams spend significant time integrating tools instead of improving the quality of their <strong>models</strong> or <strong>generative AI applications</strong>.</p><p>With the launch of <strong>fully managed MLflow 3.0 on <a href=https://aws.amazon.com/sagemaker-ai/>Amazon SageMaker AI</a></strong>, you can speed up Generative AI development by tracking experiments and observing model and application behavior with a single tool. MLflow 3.0’s <strong>tracing capabilities</strong> let customers record <strong>inputs, outputs, and metadata</strong> at every step of a Generative AI application, helping developers quickly identify the origin of errors or unexpected behavior. By keeping a history of each model and application version, MLflow 3.0 provides <strong>traceability</strong>, connecting AI feedback back to the underlying components. This lets developers trace issues back to the exact <strong>code, data, or parameters</strong> that caused them.</p><p>Customers using <a href=https://aws.amazon.com/sagemaker/hyperpod/><strong>Amazon SageMaker HyperPod</strong></a> to train and deploy <a href=https://aws.amazon.com/what-is/foundation-models/><strong>foundation models</strong></a> (FMs) can now use managed MLflow to track experiments, monitor training, gain deeper insights into model and application behavior, and manage the <a href=https://aws.amazon.com/ai/machine-learning/><strong>ML lifecycle</strong></a> at scale. This reduces troubleshooting time and allows teams to focus more on innovation.</p><p>This post introduces core concepts of <strong>fully managed MLflow 3.0 on SageMaker</strong> and provides technical guidance so you can leverage the new features to accelerate your next Generative AI application.</p><h2 id=get-started><strong>Get started</strong></h2><p>You can get started with <strong>fully managed MLflow 3.0 on Amazon SageMaker</strong> to track experiments, manage models, and optimize the <strong>Generative AI/ML</strong> lifecycle via the <a href=https://aws.amazon.com/console/><strong>AWS Management Console</strong></a>, the <a href=https://aws.amazon.com/cli/>AWS CLI</a>, or the <strong>API</strong>.</p><h2 id=prerequisites><strong>Prerequisites</strong></h2><p>To get started you need:</p><ul><li><p>An <strong>AWS account</strong> with billing enabled</p></li><li><p>An <a href=https://aws.amazon.com/sagemaker-ai/studio/><strong>Amazon SageMaker Studio</strong></a> <strong>AI domain</strong> (see the guide: <a href=https://docs.aws.amazon.com/sagemaker/latest/dg/gs.html>Guide to getting set up with Amazon SageMaker AI</a>)</p></li></ul><h2 id=configure-your-environment-to-use-the-sagemaker-managed-mlflow-tracking-server><strong>Configure your environment to use the SageMaker-managed MLflow tracking server</strong></h2><h3 id=configuration-steps><strong>Configuration steps:</strong></h3><ol><li>In the <strong>SageMaker Studio UI</strong>, open the <strong>Applications</strong> panel, choose <strong>MLflow</strong>, then select <strong>Create</strong>.</li></ol><h2 id=images3-blogstranslated31-blog1image1png><img src=../../images/3-BlogsTranslated/3.1-Blog1/image1.png></h2><ol start=2><li><p>Enter a unique name for the <strong>tracking server</strong> and specify the <a href=https://aws.amazon.com/s3/><strong>Amazon S3 URI</strong></a> where experiment artifacts will be stored. Choose <strong>Create</strong>. (SageMaker defaults to <strong>MLflow v3.0</strong>.)</p></li><li><p>Optional: choose <strong>Update</strong> to adjust settings such as <strong>server size, tags, and <a href=https://aws.amazon.com/iam/>IAM</a> role</strong>.</p></li></ol><p>The server is provisioned and started automatically and typically takes about 25 minutes. After setup completes, you can launch the MLflow UI from SageMaker Studio to begin tracking ML and Generative AI experiments. For more details on tracking server configuration, see Machine learning experiments using Amazon SageMaker AI with MLflow in the SageMaker Developer Guide: <a href=https://docs.aws.amazon.com/sagemaker/latest/dg/mlflow.html>https://docs.aws.amazon.com/sagemaker/latest/dg/mlflow.html</a></p><p>To start logging experiments to the SageMaker managed MLflow tracking server you created, install both MLflow and the SageMaker MLflow Python package in your environment. You can use <a href=https://docs.aws.amazon.com/sagemaker/latest/dg/studio-updated-jl-user-guide-create-space.html>SageMaker Studio managed Jupyter Lab</a>, <a href=https://docs.aws.amazon.com/sagemaker/latest/dg/code-editor-use-studio.html>SageMaker Studio Code Editor</a>, a local IDE, or any environment that supports AI workloads to connect to the SageMaker managed MLflow tracking server.</p><p>To install both Python packages with pip:
<code>pip install mlflow==3.0 sagemaker-mlflow==0.1.0</code></p><p>To connect and start logging your AI experiments, parameters, and models directly to the managed MLflow on SageMaker, replace the Amazon Resource Name (ARN) of your SageMaker MLflow tracking server:</p><pre tabindex=0><code>import mlflow

# SageMaker MLflow ARN
tracking_server_arn = &#34;arn:aws:sagemaker:&lt;Region&gt;:&lt;Account_id&gt;:mlflow-tracking-server/&lt;Name&gt;&#34;

# Enter ARN
mlflow.set_tracking_uri(tracking_server_arn)
mlflow.set_experiment(&#34;customer_support_genai_app&#34;)
</code></pre><p>Your environment is now configured and ready to track experiments with the SageMaker managed MLflow tracking server.</p><h2 id=implement-tracing-and-version-tracking-for-generative-ai-applications><strong>Implement tracing and version tracking for Generative AI applications</strong></h2><p>Generative AI applications have many components — code, configuration, and data — which can become hard to manage without systematic versioning. A <strong>LoggedModel</strong> entity in managed MLflow 3.0 represents your AI model, agent, or Generative AI application within an experiment. It provides unified tracking of model artifacts, execution traces, evaluation metrics, and metadata across the development lifecycle. A trace is a recorded log of inputs, outputs, and intermediate steps from a single application execution. Traces offer deep visibility into application performance, execution flow, and response quality, aiding debugging and evaluation. With LoggedModel, you can track and compare different versions of an application, making it easy to identify issues, deploy the best version, and maintain a clear record of what was deployed and when.</p><p>To implement version tracking and tracing with managed MLflow 3.0 on SageMaker, you can establish a model identity with a version using the <strong>Git commit hash</strong>, set it as the <strong>active model context</strong> so subsequent traces automatically link to that specific version, enable automatic logging for interactions with <a href=https://aws.amazon.com/bedrock/><strong>Amazon Bedrock</strong></a>, and then make an API call to Anthropic’s <strong>Claude 3.5 Sonnet</strong> — that call will be fully traced, with inputs, outputs, and metadata automatically recorded in the established model context. Managed MLflow 3.0 tracing integrates with a number of Generative AI libraries and provides one-line automatic tracing for all supported libraries. For details on supported libraries, see <a href=https://mlflow.org/docs/latest/genai/tracing/app-instrumentation/automatic/#supported-integrations><strong>Supported Integrations</strong></a> in the MLflow documentation.</p><pre tabindex=0><code># 1. Define your application version using the git commit
logged_model= &#34;customer_support_agent&#34;
logged_model_name = f&#34;{logged_model}-{git_commit}&#34;

# 2.Set the active model context - traces will be linked to this
mlflow.set_active_model(name=logged_model_name)

# 3.Set auto logging for your model provider
mlflow.bedrock.autolog()

# 4. Chat with your LLM provider
# Ensure that your boto3 client has the necessary auth information
bedrock = boto3.client(
 service_name=&#34;bedrock-runtime&#34;,
 region_name=&#34;&lt;REPLACE_WITH_YOUR_AWS_REGION&gt;&#34;,
)
model = &#34;anthropic.claude-3-5-sonnet-20241022-v2:0&#34;
messages = [{ &#34;role&#34;: &#34;user&#34;, &#34;content&#34;: [{&#34;text&#34;: &#34;Hello!&#34;}]}]
# All intermediate executions within the chat session will be logged
bedrock.converse(modelId=model, messages=messages)
</code></pre><p>After recording this information you can view Generative AI experiments and the <strong>LoggedModel</strong> for the agent in the <strong>Managed MLflow 3.0 tracking server UI</strong>, as shown in the screenshot below.</p><h2 id=images3-blogstranslated31-blog1image2png><img src=../../images/3-BlogsTranslated/3.1-Blog1/image2.png></h2><p>In addition to one-line auto tracing, <strong>MLflow</strong> provides a <strong>Python SDK</strong> so you can <a href=https://mlflow.org/docs/latest/genai/tracing/app-instrumentation/manual-tracing/>manually instrument</a> your code and work with traces. See the sample notebook sagemaker_mlflow_strands.ipynb in the <a href=https://github.com/aws-samples/genai-ml-platform-examples/tree/main/operations/sagemaker-mlflow-trace-evaluate-langgraph-agent><strong>aws-samples GitHub repository</strong></a>, where we use <strong>MLflow manual instrumentation</strong> to trace <a href=https://strandsagents.com/><strong>Strands Agents</strong></a>. With tracing in fully managed MLflow 3.0 you can capture <strong>inputs, outputs, and metadata</strong> for each intermediate step of a request to help identify the root cause of errors and unexpected behavior.</p><p>These capabilities provide <strong>observability</strong> for your AI workloads by collecting detailed information about the execution of <strong>workload services, nodes, and tools</strong>, and you can inspect them under the <strong>Traces</strong> tab.</p><h2 id=images3-blogstranslated31-blog1image3png><img src=../../images/3-BlogsTranslated/3.1-Blog1/image3.png></h2><p>You can inspect an individual <strong>trace</strong>, as illustrated below, by selecting the <strong>request ID</strong> for the trace you want to view in the Traces tab.</p><h2 id=images3-blogstranslated31-blog1image4png><img src=../../images/3-BlogsTranslated/3.1-Blog1/image4.png></h2><p><strong>Fully managed MLflow 3.0 on Amazon SageMaker</strong> also introduces tagging for traces. Tags are mutable key–value pairs you can attach to traces to add metadata and contextual information. Trace tags make it easy to organize, search, and filter traces by criteria such as user session, environment, model version, or performance characteristics. You can add, update, or remove tags at any time — while a trace is executing using mlflow.update_current_trace() or after a trace has been logged using the MLflow APIs or UI.</p><p>Managed MLflow 3.0 makes searching and analyzing traces seamless, helping teams quickly identify issues, compare agent behavior, and optimize performance. Both the tracing UI and the Python API support powerful filtering, so you can dive into traces based on attributes such as status, tags, user, environment, or execution time, as shown in the screenshot below.</p><p>For example, you can immediately find all traces with errors, filter by production environment, or find traces for a specific request. This capability is important for debugging, cost analysis, and continuous improvement of Generative AI applications.</p><p>The screenshot below shows the traces returned when searching for the tag &lsquo;Production&rsquo;.</p><h2 id=images3-blogstranslated31-blog1image5png><img src=../../images/3-BlogsTranslated/3.1-Blog1/image5.png></h2><p>The following code shows how you can search for all traces in the production environment with a successful status:</p><p># Search for traces in production environment with successful status<br>traces = mlflow.search_traces(filter_string=&ldquo;attributes.status = &lsquo;OK&rsquo; AND tags.environment = &lsquo;production&rsquo;&rdquo;)</p><h2 id=using-mlflow-tracing-for-generative-ai><strong>Using MLflow tracing for Generative AI</strong></h2><p>Building and deploying generative AI agents — such as chat-based assistants, code generators, or customer support assistants — requires deep observability into how those agents interact with <a href=https://aws.amazon.com/what-is/large-language-model/>large language models</a> (LLMs) and external tools. In a typical agentic workflow, the agent iterates through reasoning steps, calls LLMs, and uses tools or subsystems like search APIs or <a href=https://modelcontextprotocol.io/introduction>Model Context Protocol (MCP)</a> servers until the user task is completed. These complex, multi-step interactions make <strong>debugging, optimization, and cost tracking</strong> particularly challenging.</p><p>Traditional observability tools fall short for generative AI because agent decisions, tool calls, and LLM responses are dynamic and context-dependent. <strong>Managed MLflow 3.0 tracing</strong> provides comprehensive observability by recording every LLM call, tool invocation, and decision point in the agent workflow. You can use this end-to-end trace data to:</p><ul><li><p><strong>Debug agent behavior</strong> — pinpoint where an agent’s reasoning went off track or why it produced an unexpected output.</p></li><li><p><strong>Monitor tool usage</strong> — discover when and how external tools are invoked and analyze their impact on quality and cost.</p></li><li><p><strong>Track performance and cost</strong> — measure latency, token usage, and API cost at each step of the agentic loop.</p></li><li><p><strong>Audit and govern</strong> — maintain detailed logs for compliance and analysis.</p></li></ul><p>Imagine a practical scenario using the <strong>managed MLflow 3.0 tracing UI</strong> for a sample finance customer support agent equipped with a tool for retrieving financial data from a datastore. While developing a generative AI customer support agent or analyzing agent behavior in production, you can observe whether the agent’s response and execution invoke the product database tool to provide more accurate recommendations.</p><p>Example: the first trace (shown below) captures the agent handling a user query without calling any tools. The trace records the prompt, agent response, and decision points. The agent’s response lacks product-specific detail. The trace clearly shows that no external tool was invoked, which helps you quickly identify this behavior in the agent’s reasoning chain.</p><h2 id=images3-blogstranslated31-blog1image6png><img src=../../images/3-BlogsTranslated/3.1-Blog1/image6.png></h2><p>The second trace (shown below) records the same agent but this time the agent decides to call the <strong>product database tool</strong>. This trace logs the <strong>tool invocation</strong>, the returned product data, and how the agent integrates that information into the final response. Here, you can observe improved answer quality, slightly increased <strong>latency</strong>, and additional API cost due to higher <strong>token</strong> usage.</p><h2 id=images3-blogstranslated31-blog1image7png><img src=../../images/3-BlogsTranslated/3.1-Blog1/image7.png></h2><p>By comparing these traces side-by-side you can <strong>debug</strong> why the agent sometimes skips using the tool, optimize when and how tools are called, and balance quality with <strong>latency</strong> and cost. MLflow’s Tracing UI makes agentic loops transparent, actionable, and straightforward to analyze at scale. The sample agent used in this post and the full source code are available in the <a href=https://github.com/aws-samples/genai-ml-platform-examples/tree/main/operations/sagemaker-mlflow-trace-evaluate-langgraph-agent><strong>aws-samples GitHub repository</strong></a> so you can reproduce and adapt it for your own applications.</p><h2 id=clean-up-resources><strong>Clean up resources</strong></h2><p>After creation, a <strong>SageMaker managed MLflow tracking server</strong> incurs charges until you stop or delete it. Tracking server charges are based on server uptime, selected size, and the amount of data logged to the tracking server. You can stop the tracking server when not in use to save costs, or delete it via the <strong>API</strong> or the <strong>SageMaker Studio UI</strong>. For pricing details, see <a href="https://aws.amazon.com/sagemaker/pricing?p=pm&c=sm&z=4"><strong>Amazon SageMaker pricing</strong></a>.</p><h2 id=conclusion><strong>Conclusion</strong></h2><p><strong>Fully managed MLflow 3.0 on Amazon SageMaker AI</strong> is now available. Get started with the <strong>sample code</strong> in the <a href=https://github.com/aws-samples/genai-ml-platform-examples/tree/main/operations/sagemaker-mlflow-trace-evaluate-langgraph-agent><strong>aws-samples GitHub repository</strong></a>. We invite you to explore the new features and experience the increased productivity and control they provide for your ML projects. To learn more, visit <a href=https://aws.amazon.com/sagemaker-ai/experiments/><strong>Machine Learning Experiments using Amazon SageMaker with MLflow</strong></a>.</p><p>For more information, see the <a href=https://docs.aws.amazon.com/sagemaker/latest/dg/mlflow.html><strong>SageMaker Developer Guide</strong></a> and send feedback to <a href=https://repost.aws/tags/TAT80swPyVRPKPcA0rsJYPuA><strong>AWS re:Post for SageMaker</strong></a> or through your usual AWS Support channels.</p><h2 id=about-the-authors><strong>About the authors</strong></h2><div style=display:flex;flex-direction:column;gap:1rem><div style=display:flex;align-items:flex-start;gap:1rem><img src=../../images/3-BlogsTranslated/3.1-Blog1/image8.png alt="Ram Vittal" style=width:120px;height:120px;object-fit:cover;border-radius:8px><div><strong>Ram Vittal</strong><br>Ram Vittal is a <strong>Principal ML Solutions Architect</strong> at AWS. He has over three decades of experience in architecting and building distributed, hybrid, and cloud-native applications. He is passionate about creating secure, scalable, and reliable <strong>AI/ML</strong> and <strong>big data</strong> solutions that help enterprise customers accelerate their cloud adoption and optimization journey to improve business outcomes. In his spare time, he enjoys motorcycle riding and walking his three-year-old sheep-a-doodle dog.</div></div><div style=display:flex;align-items:flex-start;gap:1rem><img src=../../images/3-BlogsTranslated/3.1-Blog1/image9.png alt="Sandeep Raveesh" style=width:120px;height:120px;object-fit:cover;border-radius:8px><div><strong>Sandeep Raveesh</strong><br>Sandeep Raveesh is a <strong>GenAI Specialist Solutions Architect</strong> at AWS. He works with customers throughout their <strong>AIOps</strong> journey, including model training, <strong>Retrieval-Augmented Generation (RAG)</strong>, <strong>GenAI Agents</strong>, and scaling <strong>Generative AI</strong> use cases. He also focuses on <strong>Go-To-Market</strong> strategies to help AWS design and tailor offerings that address industry challenges in the <strong>Generative AI</strong> domain. You can find Sandeep on <a href=https://www.linkedin.com/in/sandeep-raveesh-750aa630 target=_blank>LinkedIn</a>.</div></div><div style=display:flex;align-items:flex-start;gap:1rem><img src=../../images/3-BlogsTranslated/3.1-Blog1/image10.png alt="Amit Modi" style=width:120px;height:120px;object-fit:cover;border-radius:8px><div><strong>Amit Modi</strong><br>Amit Modi is the <strong>Head of Product</strong> for <strong>SageMaker AIOps and Governance</strong>, as well as <strong>Responsible AI</strong> at AWS. With over a decade of B2B experience, he has built scalable products and teams that drive innovation and deliver customer value globally.</div></div><div style=display:flex;align-items:flex-start;gap:1rem><img src=../../images/3-BlogsTranslated/3.1-Blog1/image11.png alt="Rahul Easwar" style=width:120px;height:120px;object-fit:cover;border-radius:8px><div><strong>Rahul Easwar</strong><br>Rahul Easwar is a <strong>Senior Product Manager</strong> at AWS, leading <strong>Managed MLflow</strong> and <strong>Partner AI Apps</strong> within the <strong>SageMaker AIOps</strong> group. With over 15 years of experience spanning startups to enterprise technology, he leverages his entrepreneurial background and an <strong>MBA</strong> from <strong>Chicago Booth</strong> to build scalable <strong>ML</strong> platforms that simplify <strong>AI</strong> adoption for organizations worldwide. Connect with Rahul on <a href=https://www.linkedin.com/in/rahul-easwar/ target=_blank>LinkedIn</a> to learn more about his work in <strong>ML</strong> platforms and enterprise <strong>AI</strong> solutions.</div></div></div><footer class=footline></footer></div></div><div id=navigation><a class="nav nav-prev" href=../../3-blogstranslated/ title="Translated Blogs"><i class="fa fa-chevron-left"></i></a>
<a class="nav nav-next" href=../../3-blogstranslated/3.2-blog2/ title="Blog 2" style=margin-right:0><i class="fa fa-chevron-right"></i></a></div></section><div style=left:-1000px;overflow:scroll;position:absolute;top:-1000px;border:none;box-sizing:content-box;height:200px;margin:0;padding:0;width:200px><div style=border:none;box-sizing:content-box;height:200px;margin:0;padding:0;width:200px></div></div><script src=../../js/clipboard.min.js?1765243145></script><script src=../../js/perfect-scrollbar.min.js?1765243145></script><script src=../../js/perfect-scrollbar.jquery.min.js?1765243145></script><script src=../../js/jquery.sticky.js?1765243145></script><script src=../../js/featherlight.min.js?1765243145></script><script src=../../js/highlight.pack.js?1765243145></script><script>hljs.initHighlightingOnLoad()</script><script src=../../js/modernizr.custom-3.6.0.js?1765243145></script><script src=../../js/learn.js?1765243145></script><script src=../../js/hugo-learn.js?1765243145></script><link href=../../mermaid/mermaid.css?1765243145 rel=stylesheet><script src=../../mermaid/mermaid.js?1765243145></script><script>mermaid.initialize({startOnLoad:!0})</script><script>(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,(e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date),(i=t.createElement(n),a=t.getElementsByTagName(n)[0]),i.async=1,i.src=s,a.parentNode.insertBefore(i,a)})(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-158079754-2","auto"),ga("send","pageview")</script></body></html>